from app.connectAPI.service.preprocessing.wav_to_pcm import convert_wav_to_pcm
from app.connectAPI.service.preprocessing.pcm_to_numpy import convert_pcm_to_numpy
from app.connectAPI.service.preprocessing.processing import convert_preprocessing,convert_preprocessing_for_microphone_stable,convert_preprocessing_for_microphone_advanced,convert_preprocessing_for_microphone_chunked,convert_preprocessing_simple
import numpy as np
from app.connectAPI.service.model.models import get_stt_model
from typing import Union, Dict, Any
from fastapi import UploadFile


async def control_all(wav_data: Union[bytes, UploadFile]) -> Dict[str, Any]:
    model = get_stt_model()

    # ğŸ” ì›ë³¸ WAV íŒŒì¼ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸
    try:
        import wave
        import io
        import librosa

        if isinstance(wav_data, UploadFile):
            wav_content = await wav_data.read()
            await wav_data.seek(0)
        else:
            wav_content = wav_data

        with wave.open(io.BytesIO(wav_content), 'rb') as wav_file:
            original_sample_rate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            duration = wav_file.getnframes() / original_sample_rate

        print(f"ğŸ“Š ì›ë³¸ WAV ì •ë³´:")
        print(f"  - ìƒ˜í”Œë§ ë ˆì´íŠ¸: {original_sample_rate} Hz")
        print(f"  - ì±„ë„ ìˆ˜: {channels}")
        print(f"  - ì¬ìƒ ì‹œê°„: {duration:.2f}ì´ˆ")

        # ğŸ¯ 24kHz ì˜¤ë””ì˜¤ ì²˜ë¦¬
        if original_sample_rate != 16000:
            print(f"ğŸ”§ ë¦¬ìƒ˜í”Œë§ í•„ìš”: {original_sample_rate}Hz â†’ 16000Hz")

            # librosaë¡œ ì§ì ‘ 16kHzë¡œ ë¡œë“œ
            audio_data, _ = librosa.load(io.BytesIO(wav_content), sr=16000)

            # ì •ê·œí™”
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))

            print(f"âœ… ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {len(audio_data)} samples, {len(audio_data) / 16000:.2f}ì´ˆ")

            # ğŸ¯ ì „ì²˜ë¦¬ ìŠ¤í‚µí•˜ê³  ë°”ë¡œ ì‚¬ìš©
            text = model.transcribe(audio_data)
            return {"text": text}

    except Exception as e:
        print(f"âš ï¸ WAV ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")

    # ê¸°ì¡´ ì²˜ë¦¬ (16kHzì¸ ê²½ìš°)
    pcm_data, sample_width = await convert_wav_to_pcm(wav_data)
    numpy_data = await convert_pcm_to_numpy(pcm_data, sample_width)

    audio_duration = len(numpy_data) / 16000
    audio_max = np.max(np.abs(numpy_data))
    print(f"ğŸ” ì „ì²˜ë¦¬ í›„ ë¶„ì„: ê¸¸ì´ {audio_duration:.1f}ì´ˆ, ìµœëŒ€ê°’ {audio_max:.4f}")

    pre_pcm = await convert_preprocessing_simple(numpy_data)
    text = model.transcribe(pre_pcm)
    return {"text": text}