{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b7eb87-df3f-4512-ae23-4d8461721845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71f068c3-2570-4314-bb19-8099c29b3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb2c688-45a0-41ab-9f24-a912f157d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"TrainData\"\n",
    "train_x,train_y,test_x,test_y,valid_x,valid_y = [],[],[],[],[],[]\n",
    "data_rate = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b55933-0374-4953-a06f-75dbc315f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤í–‰ì—¬ë¶€ í™•ì¸\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "# cuda(gpu) ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° gpu ì‚¬ìš© í•˜ê³  else ì¸ ê²½ìš° cpu ì‚¬ìš©\n",
    "print(\"ì‹¤í–‰ì—¬ë¶€ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f44b38-3ab3-4b6f-ace9-01095e4effcb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f935cc75c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  p7zip\n",
      "Suggested packages:\n",
      "  p7zip-rar\n",
      "The following NEW packages will be installed:\n",
      "  p7zip p7zip-full\n",
      "0 upgraded, 2 newly installed, 0 to remove and 68 not upgraded.\n",
      "Need to get 1545 kB of archives.\n",
      "After this operation, 5896 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 p7zip amd64 16.02+dfsg-7build1 [358 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 p7zip-full amd64 16.02+dfsg-7build1 [1187 kB]\n",
      "Fetched 1545 kB in 2s (774 kB/s)    \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package p7zip.\n",
      "(Reading database ... 16670 files and directories currently installed.)\n",
      "Preparing to unpack .../p7zip_16.02+dfsg-7build1_amd64.deb ...\n",
      "Unpacking p7zip (16.02+dfsg-7build1) ...\n",
      "Selecting previously unselected package p7zip-full.\n",
      "Preparing to unpack .../p7zip-full_16.02+dfsg-7build1_amd64.deb ...\n",
      "Unpacking p7zip-full (16.02+dfsg-7build1) ...\n",
      "Setting up p7zip (16.02+dfsg-7build1) ...\n",
      "Setting up p7zip-full (16.02+dfsg-7build1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y p7zip-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f357a4e-2100-4c10-8075-5e403c94d07b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-7build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 68 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y p7zip-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b19248dc-2c79-431c-b598-9fd10856b52a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,48 CPUs Intel(R) Xeon(R) Silver 4310 CPU @ 2.10GHz (606A6),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "1 file, 15301122689 bytes (15 GiB)\n",
      "\n",
      "Extracting archive: KsponSpeech_01.zip\n",
      "\n",
      "ERRORS:\n",
      "Headers Error\n",
      "Unconfirmed start of archive\n",
      "\n",
      "\n",
      "WARNINGS:\n",
      "There are data after the end of archive\n",
      "\n",
      "--\n",
      "Path = KsponSpeech_01.zip\n",
      "Type = zip\n",
      "ERRORS:\n",
      "Headers Error\n",
      "Unconfirmed start of archive\n",
      "WARNINGS:\n",
      "There are data after the end of archive\n",
      "Physical Size = 2147585904\n",
      "Tail Size = 13153536785\n",
      "\n",
      "ERROR: Data Error : KsponSpeech_01/KsponSpeech_0018/KsponSpeech_017485.pcm\n",
      "\n",
      "Sub items Errors: 1\n",
      "\n",
      "Archives with Errors: 1\n",
      "\n",
      "Warnings: 1\n",
      "\n",
      "Open Errors: 1\n",
      "\n",
      "Sub items Errors: 1\n"
     ]
    }
   ],
   "source": [
    "!7z x KsponSpeech_01.zip -o\"unzipped_Speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2413486-b9e9-4482-86fc-93408423aca4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66f2632-f136-44e1-8ad6-fc45fe2d96a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "\n",
    "def read_npz(file_path, sr=16000):\n",
    "    \"\"\"\n",
    "    NPZ íŒŒì¼ì„ ì½ì–´ numpy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # npz íŒŒì¼ ë¡œë“œ\n",
    "    with np.load(file_path) as data:\n",
    "        # npz íŒŒì¼ì— ì €ì¥ëœ ì²« ë²ˆì§¸ ë°°ì—´ ê°€ì ¸ì˜¤ê¸°\n",
    "        # ì¼ë°˜ì ìœ¼ë¡œ npz íŒŒì¼ì—ëŠ” 'arr_0'ì´ë¼ëŠ” í‚¤ë¡œ ë°ì´í„°ê°€ ì €ì¥ë©ë‹ˆë‹¤\n",
    "        if 'arr_0' in data:\n",
    "            audio_data = data['arr_0']\n",
    "        # ë˜ëŠ” íŠ¹ì • í‚¤ê°€ ìˆëŠ” ê²½ìš° ê·¸ í‚¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "        # ì˜ˆ: audio_data = data['audio']\n",
    "        else:\n",
    "            # ì²« ë²ˆì§¸ í‚¤ ì‚¬ìš©\n",
    "            key = list(data.keys())[0]\n",
    "            audio_data = data[key]\n",
    "\n",
    "    # ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì •ê·œí™”\n",
    "    if audio_data.dtype in [np.int16, np.int8]:\n",
    "        max_value = float(2 ** (15 if audio_data.dtype == np.int16 else 7))\n",
    "        audio_data = audio_data.astype(np.float32) / max_value\n",
    "\n",
    "    return audio_data, sr\n",
    "def load_text(file_path):\n",
    "    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "def get_file_paths_npz(base_directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ PCM íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    base = []\n",
    "\n",
    "    for i in range(1, 19):\n",
    "        if i > 10 :\n",
    "            base.append(base_directory + f\"/KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base.append(base_directory + f\"/KsponSpeech_000{i}\")\n",
    "\n",
    "    npz_files = []\n",
    "\n",
    "    for base_path in base:\n",
    "        for root, _, files in os.walk(base_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.npz'):\n",
    "                    npz_path = os.path.join(root, file)\n",
    "                    if os.path.exists(npz_path):\n",
    "                        npz_files.append(npz_path)\n",
    "                        print(\"ì„±ê³µ\")\n",
    "                    else:\n",
    "                        print(\"ì‹¤íŒ¨\")\n",
    "        return npz_files\n",
    "\n",
    "def get_file_paths_txt(npz_files):\n",
    "    txt_files = []\n",
    "    # ëª¨ë“  íŒŒì¼ì„ ê²€ìƒ‰\n",
    "    for path in npz_files:\n",
    "        temp = path.split(\".\")\n",
    "        temp_p = temp[1] + \"_g2p\"\n",
    "        temp_path = temp[0] + temp_p\n",
    "        txt_files.append(temp_path)\n",
    "\n",
    "    return txt_files\n",
    "\n",
    "def create_dataset(npz_files, txt_files, max_samples=None):\n",
    "    \"\"\"\n",
    "    PCM íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    if max_samples is not None:\n",
    "        npz_files = npz_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npz_file, txt_file in zip(npz_files, txt_files):\n",
    "        data[\"audio\"].append(npz_file)\n",
    "        data[\"text\"].append(load_text(txt_file))\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "def train_whisper_model():\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    output_dir = \"whisper_finetuned\"\n",
    "    pcm_files = get_file_paths_npz(base_directory)\n",
    "    txt_files = get_file_paths_txt(pcm_files)\n",
    "    print(f\"ì´ {len(pcm_files)}ê°œì˜ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    dataset = create_dataset(pcm_files, txt_files)\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            audio_array, sampling_rate = read_npz(audio_path)\n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— Audio í˜•ì‹ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # Whisper ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        # ì˜¤ë””ì˜¤ ì²˜ë¦¬\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "\n",
    "        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜ í›„ ë°ì´í„° íƒ€ì… ì¡°ì •\n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "\n",
    "        # ì´ì œ í…ì„œê°€ ë˜ì—ˆìœ¼ë¯€ë¡œ ë°ì´í„° íƒ€ì… ë³€í™˜ ê°€ëŠ¥\n",
    "        if hasattr(model, \"dtype\"):\n",
    "            input_features = input_features.to(model.dtype)\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "        labels = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "\n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš© (ë¹„ë°°ì¹˜ í•¨ìˆ˜)\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    # ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        # pred_idsê°€ íŠœí”Œì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì˜ˆì¸¡ê°’)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "\n",
    "        # ì´ì œ pred_idsê°€ í…ì„œ/ë°°ì—´ì¸ì§€ í™•ì¸í•˜ê³  3ì°¨ì›ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "        if hasattr(pred_ids, 'shape') and len(pred_ids.shape) > 2:\n",
    "            pred_ids = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "        # íŒ¨ë”© í† í° ë¬´ì‹œ\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        # ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # WER ê³„ì‚° \n",
    "        # ì°¸ê³ : jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„í¬íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        import jiwer  # ì´ ë¼ì¸ ì¶”ê°€\n",
    "        wer = jiwer.wer(label_str, pred_str)\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    # í›ˆë ¨ ì¸ì ì„¤ì •\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=1e-5,\n",
    "        warmup_steps=500,\n",
    "        max_steps=4000,\n",
    "        gradient_checkpointing=True,\n",
    "        # fp16=True,\n",
    "        fp16_full_eval=False,\n",
    "        evaluation_strategy=\"steps\",  # ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„°ëª… ì‚¬ìš©\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        logging_steps=25,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"wer\",\n",
    "        greater_is_better=False,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    # í›ˆë ¨ê¸° ì„¤ì •\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        eval_dataset=processed_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,  # processing_class ëŒ€ì‹  tokenizer ì‚¬ìš©\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    trainer.train()\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "    test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  í•¨ìˆ˜\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # PCM íŒŒì¼ ë¡œë“œ\n",
    "    audio_array, sr = read_npz(audio_file)\n",
    "\n",
    "    # íŠ¹ì„± ì¶”ì¶œ\n",
    "    input_features = processor.feature_extractor(\n",
    "        audio_array,\n",
    "        sampling_rate=sr,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "\n",
    "    # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "    transcription = processor.tokenizer.batch_decode(\n",
    "        predicted_ids,\n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a374fd-a55a-420c-b0a5-43af3560e4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 0ê°œì˜ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_628/2787886146.py:252: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No columns in the dataset match the model's forward method signature. The following columns have been ignored: []. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# ëª¨ë¸ í›ˆë ¨\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     model, processor \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_whisper_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     test_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessData/KsponSpeech_01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 263\u001b[0m, in \u001b[0;36mtrain_whisper_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m    253\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    254\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    260\u001b[0m )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í›ˆë ¨\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ ì €ì¥\u001b[39;00m\n\u001b[1;32m    266\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(output_dir)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2152\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2150\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 2152\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   2154\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:958\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_collator\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, datasets\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[0;32m--> 958\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_unused_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m     data_collator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collator_with_removed_columns(data_collator, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:884\u001b[0m, in \u001b[0;36mTrainer._remove_unused_columns\u001b[0;34m(self, dataset, description)\u001b[0m\n\u001b[1;32m    882\u001b[0m columns \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature_columns \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumn_names]\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 884\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo columns in the dataset match the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms forward method signature. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following columns have been ignored: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ignored_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(datasets\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    891\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mset_format(\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mformat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m], columns\u001b[38;5;241m=\u001b[39mcolumns, format_kwargs\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mformat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    893\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No columns in the dataset match the model's forward method signature. The following columns have been ignored: []. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    model, processor = train_whisper_model()\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    pcm_files, txt_files = get_file_paths(test_directory)\n",
    "    print(f\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼: {len(pcm_files)}ê°œ\")\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸ (ë˜ëŠ” ì›í•˜ëŠ” ë§Œí¼ ì œí•œ)\n",
    "    for i in range(len(pcm_files)):\n",
    "        test_audio = pcm_files[i]\n",
    "        reference_text = load_text(txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7c2d7a-c92a-469e-beec-3961df711dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: /data\n",
      "\n",
      "PreprocessData ë””ë ‰í† ë¦¬ êµ¬ì¡°:\n",
      "ğŸ“ .ipynb_checkpoints\n",
      "ğŸ“ KsponSpeech_01\n",
      "  ğŸ“ .ipynb_checkpoints\n",
      "  ğŸ“ KsponSpeech_0001\n",
      "    ğŸ“„ íŒŒì¼ 997ê°œ:\n",
      "      KsponSpeech_000001_combined_features.npy\n",
      "      KsponSpeech_000002_combined_features.npy\n",
      "      KsponSpeech_000003_combined_features.npy\n",
      "      KsponSpeech_000004_combined_features.npy\n",
      "      KsponSpeech_000005_combined_features.npy\n",
      "      ... ì™¸ 992ê°œ\n",
      "  ğŸ“ KsponSpeech_0001_g2p\n",
      "    ğŸ“ .ipynb_checkpoints\n",
      "      ğŸ“„ íŒŒì¼ 10ê°œ:\n",
      "        KsponSpeech_000001-checkpoint.txt\n",
      "        KsponSpeech_000002-checkpoint.txt\n",
      "        KsponSpeech_000003-checkpoint.txt\n",
      "        KsponSpeech_000004-checkpoint.txt\n",
      "        KsponSpeech_000009-checkpoint.txt\n",
      "        ... ì™¸ 5ê°œ\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_000001.txt\n",
      "      KsponSpeech_000002.txt\n",
      "      KsponSpeech_000003.txt\n",
      "      KsponSpeech_000004.txt\n",
      "      KsponSpeech_000005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0002\n",
      "    ğŸ“„ íŒŒì¼ 160ê°œ:\n",
      "      KsponSpeech_001001_combined_features.npy\n",
      "      KsponSpeech_001003_combined_features.npy\n",
      "      KsponSpeech_001009_combined_features.npy\n",
      "      KsponSpeech_001014_combined_features.npy\n",
      "      KsponSpeech_001039_combined_features.npy\n",
      "      ... ì™¸ 155ê°œ\n",
      "  ğŸ“ KsponSpeech_0002_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_001001.txt\n",
      "      KsponSpeech_001002.txt\n",
      "      KsponSpeech_001003.txt\n",
      "      KsponSpeech_001004.txt\n",
      "      KsponSpeech_001005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0003\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_002001_combined_features.npy\n",
      "      KsponSpeech_002002_combined_features.npy\n",
      "      KsponSpeech_002003_combined_features.npy\n",
      "      KsponSpeech_002004_combined_features.npy\n",
      "      KsponSpeech_002005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0003_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_002001.txt\n",
      "      KsponSpeech_002002.txt\n",
      "      KsponSpeech_002003.txt\n",
      "      KsponSpeech_002004.txt\n",
      "      KsponSpeech_002005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0004\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_003001_combined_features.npy\n",
      "      KsponSpeech_003002_combined_features.npy\n",
      "      KsponSpeech_003003_combined_features.npy\n",
      "      KsponSpeech_003004_combined_features.npy\n",
      "      KsponSpeech_003005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0004_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_003001.txt\n",
      "      KsponSpeech_003002.txt\n",
      "      KsponSpeech_003003.txt\n",
      "      KsponSpeech_003004.txt\n",
      "      KsponSpeech_003005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0005\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_004001_combined_features.npy\n",
      "      KsponSpeech_004002_combined_features.npy\n",
      "      KsponSpeech_004003_combined_features.npy\n",
      "      KsponSpeech_004004_combined_features.npy\n",
      "      KsponSpeech_004005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0005_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_004001.txt\n",
      "      KsponSpeech_004002.txt\n",
      "      KsponSpeech_004003.txt\n",
      "      KsponSpeech_004004.txt\n",
      "      KsponSpeech_004005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0006\n",
      "    ğŸ“„ íŒŒì¼ 37ê°œ:\n",
      "      KsponSpeech_005038_combined_features.npy\n",
      "      KsponSpeech_005075_combined_features.npy\n",
      "      KsponSpeech_005093_combined_features.npy\n",
      "      KsponSpeech_005113_combined_features.npy\n",
      "      KsponSpeech_005120_combined_features.npy\n",
      "      ... ì™¸ 32ê°œ\n",
      "  ğŸ“ KsponSpeech_0006_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_005001.txt\n",
      "      KsponSpeech_005002.txt\n",
      "      KsponSpeech_005003.txt\n",
      "      KsponSpeech_005004.txt\n",
      "      KsponSpeech_005005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0007\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_006001_combined_features.npy\n",
      "      KsponSpeech_006002_combined_features.npy\n",
      "      KsponSpeech_006003_combined_features.npy\n",
      "      KsponSpeech_006004_combined_features.npy\n",
      "      KsponSpeech_006005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0007_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_006001.txt\n",
      "      KsponSpeech_006002.txt\n",
      "      KsponSpeech_006003.txt\n",
      "      KsponSpeech_006004.txt\n",
      "      KsponSpeech_006005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0008\n",
      "    ğŸ“„ íŒŒì¼ 937ê°œ:\n",
      "      KsponSpeech_007002_combined_features.npy\n",
      "      KsponSpeech_007003_combined_features.npy\n",
      "      KsponSpeech_007004_combined_features.npy\n",
      "      KsponSpeech_007007_combined_features.npy\n",
      "      KsponSpeech_007008_combined_features.npy\n",
      "      ... ì™¸ 932ê°œ\n",
      "  ğŸ“ KsponSpeech_0008_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_007001.txt\n",
      "      KsponSpeech_007002.txt\n",
      "      KsponSpeech_007003.txt\n",
      "      KsponSpeech_007004.txt\n",
      "      KsponSpeech_007005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0009\n",
      "    ğŸ“„ íŒŒì¼ 834ê°œ:\n",
      "      KsponSpeech_008002_combined_features.npy\n",
      "      KsponSpeech_008003_combined_features.npy\n",
      "      KsponSpeech_008004_combined_features.npy\n",
      "      KsponSpeech_008005_combined_features.npy\n",
      "      KsponSpeech_008006_combined_features.npy\n",
      "      ... ì™¸ 829ê°œ\n",
      "  ğŸ“ KsponSpeech_0009_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_008001.txt\n",
      "      KsponSpeech_008002.txt\n",
      "      KsponSpeech_008003.txt\n",
      "      KsponSpeech_008004.txt\n",
      "      KsponSpeech_008005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0010\n",
      "    ğŸ“„ íŒŒì¼ 376ê°œ:\n",
      "      KsponSpeech_009002_combined_features.npy\n",
      "      KsponSpeech_009005_combined_features.npy\n",
      "      KsponSpeech_009007_combined_features.npy\n",
      "      KsponSpeech_009008_combined_features.npy\n",
      "      KsponSpeech_009010_combined_features.npy\n",
      "      ... ì™¸ 371ê°œ\n",
      "  ğŸ“ KsponSpeech_0010_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_009001.txt\n",
      "      KsponSpeech_009002.txt\n",
      "      KsponSpeech_009003.txt\n",
      "      KsponSpeech_009004.txt\n",
      "      KsponSpeech_009005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0011\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_010001_combined_features.npy\n",
      "      KsponSpeech_010002_combined_features.npy\n",
      "      KsponSpeech_010003_combined_features.npy\n",
      "      KsponSpeech_010004_combined_features.npy\n",
      "      KsponSpeech_010005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0011_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_010001.txt\n",
      "      KsponSpeech_010002.txt\n",
      "      KsponSpeech_010003.txt\n",
      "      KsponSpeech_010004.txt\n",
      "      KsponSpeech_010005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0012\n",
      "    ğŸ“„ íŒŒì¼ 961ê°œ:\n",
      "      KsponSpeech_011001_combined_features.npy\n",
      "      KsponSpeech_011002_combined_features.npy\n",
      "      KsponSpeech_011003_combined_features.npy\n",
      "      KsponSpeech_011004_combined_features.npy\n",
      "      KsponSpeech_011005_combined_features.npy\n",
      "      ... ì™¸ 956ê°œ\n",
      "  ğŸ“ KsponSpeech_0012_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_011001.txt\n",
      "      KsponSpeech_011002.txt\n",
      "      KsponSpeech_011003.txt\n",
      "      KsponSpeech_011004.txt\n",
      "      KsponSpeech_011005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0013\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_012001_combined_features.npy\n",
      "      KsponSpeech_012002_combined_features.npy\n",
      "      KsponSpeech_012003_combined_features.npy\n",
      "      KsponSpeech_012004_combined_features.npy\n",
      "      KsponSpeech_012005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0013_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_012001.txt\n",
      "      KsponSpeech_012002.txt\n",
      "      KsponSpeech_012003.txt\n",
      "      KsponSpeech_012004.txt\n",
      "      KsponSpeech_012005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0014\n",
      "    ğŸ“„ íŒŒì¼ 861ê°œ:\n",
      "      KsponSpeech_013001_combined_features.npy\n",
      "      KsponSpeech_013002_combined_features.npy\n",
      "      KsponSpeech_013003_combined_features.npy\n",
      "      KsponSpeech_013004_combined_features.npy\n",
      "      KsponSpeech_013005_combined_features.npy\n",
      "      ... ì™¸ 856ê°œ\n",
      "  ğŸ“ KsponSpeech_0014_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_013001.txt\n",
      "      KsponSpeech_013002.txt\n",
      "      KsponSpeech_013003.txt\n",
      "      KsponSpeech_013004.txt\n",
      "      KsponSpeech_013005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0015\n",
      "    ğŸ“„ íŒŒì¼ 65ê°œ:\n",
      "      KsponSpeech_014019_combined_features.npy\n",
      "      KsponSpeech_014054_combined_features.npy\n",
      "      KsponSpeech_014056_combined_features.npy\n",
      "      KsponSpeech_014057_combined_features.npy\n",
      "      KsponSpeech_014074_combined_features.npy\n",
      "      ... ì™¸ 60ê°œ\n",
      "  ğŸ“ KsponSpeech_0015_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_014001.txt\n",
      "      KsponSpeech_014002.txt\n",
      "      KsponSpeech_014003.txt\n",
      "      KsponSpeech_014004.txt\n",
      "      KsponSpeech_014005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0016\n",
      "    ğŸ“„ íŒŒì¼ 1ê°œ:\n",
      "      KsponSpeech_015872_combined_features.npy\n",
      "  ğŸ“ KsponSpeech_0016_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_015001.txt\n",
      "      KsponSpeech_015002.txt\n",
      "      KsponSpeech_015003.txt\n",
      "      KsponSpeech_015004.txt\n",
      "      KsponSpeech_015005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0017\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_016001_combined_features.npy\n",
      "      KsponSpeech_016002_combined_features.npy\n",
      "      KsponSpeech_016003_combined_features.npy\n",
      "      KsponSpeech_016004_combined_features.npy\n",
      "      KsponSpeech_016005_combined_features.npy\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0017_g2p\n",
      "    ğŸ“„ íŒŒì¼ 1000ê°œ:\n",
      "      KsponSpeech_016001.txt\n",
      "      KsponSpeech_016002.txt\n",
      "      KsponSpeech_016003.txt\n",
      "      KsponSpeech_016004.txt\n",
      "      KsponSpeech_016005.txt\n",
      "      ... ì™¸ 995ê°œ\n",
      "  ğŸ“ KsponSpeech_0018\n",
      "    ğŸ“„ íŒŒì¼ 485ê°œ:\n",
      "      KsponSpeech_017001_combined_features.npy\n",
      "      KsponSpeech_017002_combined_features.npy\n",
      "      KsponSpeech_017003_combined_features.npy\n",
      "      KsponSpeech_017004_combined_features.npy\n",
      "      KsponSpeech_017005_combined_features.npy\n",
      "      ... ì™¸ 480ê°œ\n",
      "  ğŸ“ KsponSpeech_0018_g2p\n",
      "    ğŸ“„ íŒŒì¼ 484ê°œ:\n",
      "      KsponSpeech_017001.txt\n",
      "      KsponSpeech_017002.txt\n",
      "      KsponSpeech_017003.txt\n",
      "      KsponSpeech_017004.txt\n",
      "      KsponSpeech_017005.txt\n",
      "      ... ì™¸ 479ê°œ\n",
      "\n",
      "âŒ PreprocessData_Speech/KsponSpeech_01ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "import os\n",
    "print(\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "\n",
    "# íŠ¹ì • ë””ë ‰í† ë¦¬ì˜ êµ¬ì¡° í™•ì¸\n",
    "def print_directory_structure(directory, level=0, max_depth=3, max_files=5):\n",
    "    if level > max_depth:\n",
    "        print(\"  \" * level + \"...\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = os.listdir(directory)\n",
    "        dirs = []\n",
    "        files = []\n",
    "        \n",
    "        for item in items:\n",
    "            item_path = os.path.join(directory, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                dirs.append(item)\n",
    "            else:\n",
    "                files.append(item)\n",
    "        \n",
    "        for d in sorted(dirs):\n",
    "            print(\"  \" * level + \"ğŸ“ \" + d)\n",
    "            print_directory_structure(os.path.join(directory, d), level + 1, max_depth, max_files)\n",
    "        \n",
    "        if files:\n",
    "            print(\"  \" * level + f\"ğŸ“„ íŒŒì¼ {len(files)}ê°œ:\")\n",
    "            for i, f in enumerate(sorted(files)):\n",
    "                if i >= max_files:\n",
    "                    print(\"  \" * (level + 1) + f\"... ì™¸ {len(files) - max_files}ê°œ\")\n",
    "                    break\n",
    "                print(\"  \" * (level + 1) + f)\n",
    "    except PermissionError:\n",
    "        print(\"  \" * level + \"âŒ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ\")\n",
    "    except Exception as e:\n",
    "        print(\"  \" * level + f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# í™•ì¸í•˜ê³  ì‹¶ì€ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì›í•˜ëŠ” ê²½ë¡œë¡œ ìˆ˜ì •)\n",
    "# ì˜ˆ: data_directory = \"unzipped_Speech\"\n",
    "# ë˜ëŠ” base_directoryì— ì§€ì •ëœ ê²½ë¡œë¥¼ ì‚¬ìš©\n",
    "data_directory = \"PreprocessData\"\n",
    "print(f\"\\n{data_directory} ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
    "print_directory_structure(data_directory)\n",
    "\n",
    "# KsponSpeech_01 ë””ë ‰í† ë¦¬ê°€ ìˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ í™•ì¸\n",
    "target_dir = \"PreprocessData_Speech/KsponSpeech_01\"\n",
    "if os.path.exists(target_dir):\n",
    "    print(f\"\\n{target_dir}ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "    print(f\"{target_dir} ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
    "    print_directory_structure(target_dir)\n",
    "else:\n",
    "    print(f\"\\nâŒ {target_dir}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c67ef062-e996-4e47-8c10-16686046936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"whisper_finetuned/saved_whisper_model.pt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b61f6cf9-c406-46d0-bfc6-e71f1c92bb9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.8/dist-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (0.30.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: torch; extra == \"torch\" in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (2.4.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0; extra == \"torch\" in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.8.89)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.8.86)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.7.5.86)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.8.89)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (11.11.3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch; extra == \"torch\"->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0; extra == \"torch\"->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch; extra == \"torch\"->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch; extra == \"torch\"->transformers[torch]) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b509ffa-797c-46c3-a999-987b0af778ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-25 01:10:28.596516: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-25 01:10:28.645096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-25 01:10:29.371019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "ì´ 12714ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜(12714)ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜(12713)ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12713/12713 [00:06<00:00, 2054.02 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10170/10170 [35:13<00:00,  4.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [04:23<00:00,  4.84 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1271/1271 [04:24<00:00,  4.80 examples/s]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_18222/1156997083.py:292: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 5:42:01, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>10.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>7.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>4.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>4.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>4.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>4.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>3.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.620100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>3.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>3.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.402400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.394400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>3.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>3.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>3.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>3.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>3.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>3.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>3.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>3.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>3.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>3.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>3.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>3.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>3.064100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.902200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.911700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.884200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.888300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.918700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.909800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.887200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.844500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.844300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>2.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>2.689900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.747300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>2.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>2.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>2.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>2.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>2.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>2.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>2.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>2.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>2.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>2.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>2.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>2.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>2.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>2.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>2.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>2.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>2.535700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>2.552500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2.565600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.537400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>2.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>2.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>2.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>2.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>2.550300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>2.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>2.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>2.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>2.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>2.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>2.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>2.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>2.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>2.460100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>2.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>2.462100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>2.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>2.427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>2.481700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>2.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>2.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>2.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.410300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>2.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>2.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>2.343500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>2.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>2.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>2.333700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>2.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.365500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1272' max='1272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1272/1272 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'eval_loss': 3.0094687938690186, 'eval_runtime': 165.0981, 'eval_samples_per_second': 7.705, 'eval_steps_per_second': 7.705, 'epoch': 6.289308176100629}\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "í…ŒìŠ¤íŠ¸í•  íŒŒì¼: 12714ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (float) and bias type (c10::Half) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 381\u001b[0m\n\u001b[1;32m    378\u001b[0m test_audio \u001b[38;5;241m=\u001b[39m test_npy_files[i]\n\u001b[1;32m    379\u001b[0m reference_text \u001b[38;5;241m=\u001b[39m load_text(test_txt_files[i])\n\u001b[0;32m--> 381\u001b[0m transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_audio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124míŒŒì¼: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(test_audio)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì›ë³¸ í…ìŠ¤íŠ¸: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 343\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[0;34m(model, processor, audio_file)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 343\u001b[0m     predicted_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\u001b[39;00m\n\u001b[1;32m    346\u001b[0m transcription \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m    347\u001b[0m     predicted_ids,\n\u001b[1;32m    348\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    349\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/generation_whisper.py:555\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[0;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_prompt_condition_type(\n\u001b[1;32m    550\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    551\u001b[0m     prompt_condition_type\u001b[38;5;241m=\u001b[39mprompt_condition_type,\n\u001b[1;32m    552\u001b[0m )\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# pass self.config for backward compatibility\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m init_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_init_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# passing `decoder_input_ids` is deprecated - the only exception is for assisted generation\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# where the input ids are handled explicitly by the generate method\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_decoder_input_ids(kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/generation_whisper.py:1370\u001b[0m, in \u001b[0;36mWhisperGenerationMixin._retrieve_init_tokens\u001b[0;34m(self, input_features, batch_size, generation_config, config, num_segment_frames, kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     lang_ids \u001b[38;5;241m=\u001b[39m [language_to_id(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m languages]\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang_to_id\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_lang_id_undefined:\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;66;03m# language is not defined or intentially set to `None` to trigger language detection\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m     lang_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;66;03m# append or replace lang_ids to init_tokens\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(init_tokens)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/generation_whisper.py:1474\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.detect_language\u001b[0;34m(self, input_features, encoder_outputs, generation_config, num_segment_frames)\u001b[0m\n\u001b[1;32m   1468\u001b[0m decoder_input_ids \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1469\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;241m*\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1471\u001b[0m )\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1474\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1476\u001b[0m non_lang_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(logits[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m   1477\u001b[0m non_lang_mask[\u001b[38;5;28mlist\u001b[39m(generation_config\u001b[38;5;241m.\u001b[39mlang_to_id\u001b[38;5;241m.\u001b[39mvalues())] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/modeling_whisper.py:1767\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, decoder_position_ids, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1763\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1764\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1765\u001b[0m         )\n\u001b[0;32m-> 1767\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_position_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_position_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1787\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/modeling_whisper.py:1618\u001b[0m, in \u001b[0;36mWhisperModel.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, decoder_position_ids, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_input_features(input_features, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m-> 1618\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/whisper/modeling_whisper.py:1027\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[0;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1023\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1024\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1025\u001b[0m )\n\u001b[1;32m   1026\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1027\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1028\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(inputs_embeds))\n\u001b[1;32m   1030\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (float) and bias type (c10::Half) should be the same"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "def load_text(file_path):\n",
    "    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def get_file_paths_npy(base_directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ NP íŒŒì¼(combined_features.npy)ì˜ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    npy_files = []\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ í´ë” ëª©ë¡ ìƒì„±\n",
    "    base_folders = []\n",
    "    for i in range(1, 19):\n",
    "        if i > 9:\n",
    "            base_folders.append(f\"KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base_folders.append(f\"KsponSpeech_000{i}\")\n",
    "\n",
    "    # ëª¨ë“  í´ë” ìˆœíšŒ\n",
    "    for folder in base_folders:\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        \n",
    "        # í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}\")\n",
    "            \n",
    "            # í´ë” ë‚´ì˜ íŒŒì¼ ê²€ìƒ‰\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('_combined_features.npy'):\n",
    "                        npy_path = os.path.join(root, file)\n",
    "                        npy_files.append(npy_path)\n",
    "                        if len(npy_files) % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "                            print(f\"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(npy_files)}\")\n",
    "        else:\n",
    "            print(f\"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return npy_files\n",
    "\n",
    "\n",
    "def get_file_paths_txt(npy_files):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ ê²½ë¡œë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    txt_files = []\n",
    "    \n",
    "    for npy_path in npy_files:\n",
    "        # íŒŒì¼ëª… ì¶”ì¶œ (ê²½ë¡œì™€ í™•ì¥ì ì œê±°)\n",
    "        file_name = os.path.basename(npy_path).replace('_combined_features.npy', '')\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„\n",
    "        dir_path = os.path.dirname(npy_path)\n",
    "        parent_dir = os.path.basename(dir_path)\n",
    "        \n",
    "        # í•´ë‹¹ G2P í´ë” ê²½ë¡œ ìƒì„±\n",
    "        g2p_dir = parent_dir + \"_g2p\"\n",
    "        g2p_dir_path = os.path.join(os.path.dirname(dir_path), g2p_dir)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±\n",
    "        txt_path = os.path.join(g2p_dir_path, file_name + \".txt\")\n",
    "        \n",
    "        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì„ íƒì )\n",
    "        if os.path.exists(txt_path):\n",
    "            txt_files.append(txt_path)\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {txt_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return txt_files\n",
    "\n",
    "\n",
    "def create_dataset(npy_files, txt_files, max_samples=None):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    if max_samples is not None:\n",
    "        npy_files = npy_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npy_file, txt_file in zip(npy_files, txt_files):\n",
    "        data[\"audio\"].append(npy_file)\n",
    "        data[\"text\"].append(load_text(txt_file))\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "def train_whisper_model():\n",
    "    # ê²½ë¡œ ìˆ˜ì •\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"  # unzipped_Speechì—ì„œ PreprocessDataë¡œ ë³€ê²½\n",
    "    output_dir = \"whisper_finetuned\"\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ ì´ë¦„ ë³€ê²½\n",
    "    npy_files = get_file_paths_npy(base_directory)\n",
    "    \n",
    "    if len(npy_files) == 0:\n",
    "        print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return None, None\n",
    "    \n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³ \n",
    "    if len(npy_files) != len(txt_files):\n",
    "        print(f\"ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜({len(npy_files)})ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜({len(txt_files)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ë§Œ ì‚¬ìš©\n",
    "        if len(npy_files) > len(txt_files):\n",
    "            npy_files = npy_files[:len(txt_files)]\n",
    "        else:\n",
    "            txt_files = txt_files[:len(npy_files)]\n",
    "    \n",
    "    dataset = create_dataset(npy_files, txt_files)\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            # npy íŒŒì¼ ë¡œë“œ\n",
    "            audio_array = np.load(audio_path)\n",
    "            # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "            if audio_array.dtype in [np.int16, np.int8]:\n",
    "                max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "                audio_array = audio_array.astype(np.float32) / max_value\n",
    "            elif audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            \n",
    "            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "            sampling_rate = 16000\n",
    "            \n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— Audio í˜•ì‹ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # Whisper ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    \"openai/whisper-small\", \n",
    "    use_cache=False,\n",
    "    low_cpu_mem_usage=True\n",
    "    # torch_dtype=torch.float16 ì œê±°\n",
    "    )\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        # ì˜¤ë””ì˜¤ ì²˜ë¦¬\n",
    "        audio = batch[\"audio\"]\n",
    "    \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "    \n",
    "        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "    \n",
    "        # í…ì„œ íƒ€ì… ë³€í™˜ (ì¤‘ìš”: íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ float16ìœ¼ë¡œ ì„¤ì •í•˜ì§€ ì•ŠìŒ)\n",
    "        # input_features = input_features.to(model.dtype)  # ì´ ì¤„ì„ ì œê±°í•˜ê±°ë‚˜ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •\n",
    "    \n",
    "        # í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "        labels = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš© (ë¹„ë°°ì¹˜ í•¨ìˆ˜)\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    # ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        # pred_idsê°€ íŠœí”Œì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì˜ˆì¸¡ê°’)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "\n",
    "        # ì´ì œ pred_idsê°€ í…ì„œ/ë°°ì—´ì¸ì§€ í™•ì¸í•˜ê³  3ì°¨ì›ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "        if hasattr(pred_ids, 'shape') and len(pred_ids.shape) > 2:\n",
    "            pred_ids = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "        # íŒ¨ë”© í† í° ë¬´ì‹œ\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        # ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # WER ê³„ì‚° \n",
    "        # ì°¸ê³ : jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„í¬íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        import jiwer  # ì´ ë¼ì¸ ì¶”ê°€\n",
    "        wer = jiwer.wer(label_str, pred_str)\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    # í›ˆë ¨ ì¸ì ì„¤ì •\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=1e-5,\n",
    "        warmup_steps=500,\n",
    "        max_steps=4000,\n",
    "        gradient_checkpointing=True,\n",
    "        fp16=True,  # í˜¼í•© ì •ë°€ë„ëŠ” ì—¬ì „íˆ í™œì„±í™”\n",
    "        # fp16_full_eval=True ì œê±° (í‰ê°€ë¥¼ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”)\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_steps=500,\n",
    "        logging_steps=25,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        push_to_hub=False,\n",
    "        # í•„ìš”í•˜ì§€ ì•Šì€ ì˜µì…˜ë“¤ ì œê±°\n",
    "    )\n",
    "\n",
    "    # í›ˆë ¨ê¸° ì„¤ì •\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        # eval_dataset=processed_datasets[\"validation\"],  # ì´ ì¤„ ì œê±° ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        # compute_metrics=compute_metrics,  # ì´ ì¤„ ì œê±° ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    trainer.train()\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "    test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  í•¨ìˆ˜\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # NP íŒŒì¼ ë¡œë“œ\n",
    "    audio_array = np.load(audio_file)\n",
    "    \n",
    "    # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "    if audio_array.dtype in [np.int16, np.int8]:\n",
    "        max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "        audio_array = audio_array.astype(np.float32) / max_value\n",
    "    elif audio_array.dtype != np.float32:\n",
    "        audio_array = audio_array.astype(np.float32)\n",
    "    \n",
    "    # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "    sr = 16000\n",
    "\n",
    "    # íŠ¹ì„± ì¶”ì¶œ\n",
    "    input_features = processor.feature_extractor(\n",
    "        audio_array,\n",
    "        sampling_rate=sr,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "\n",
    "    # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "    transcription = processor.tokenizer.batch_decode(\n",
    "        predicted_ids,\n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    return transcription\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    model, processor = train_whisper_model()\n",
    "    \n",
    "    if model is None or processor is None:\n",
    "        print(\"ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸° - í•¨ìˆ˜ ì´ë¦„ ë³€ê²½\n",
    "    npy_files = get_file_paths_npy(test_directory)\n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼: {len(npy_files)}ê°œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ìˆ˜ ì œí•œ (ì„ íƒì )\n",
    "    max_test_files = 10\n",
    "    test_npy_files = npy_files[:max_test_files]\n",
    "    test_txt_files = txt_files[:max_test_files]\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "    for i in range(len(test_npy_files)):\n",
    "        test_audio = test_npy_files[i]\n",
    "        reference_text = load_text(test_txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f75050-8e21-465e-8d1f-0a4f54faefef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def load_text(file_path):\n",
    "    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def get_file_paths_npy(base_directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ NP íŒŒì¼(combined_features.npy)ì˜ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    npy_files = []\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ í´ë” ëª©ë¡ ìƒì„±\n",
    "    base_folders = []\n",
    "    for i in range(1, 19):\n",
    "        if i > 9:\n",
    "            base_folders.append(f\"KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base_folders.append(f\"KsponSpeech_000{i}\")\n",
    "\n",
    "    # ëª¨ë“  í´ë” ìˆœíšŒ\n",
    "    for folder in base_folders:\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        \n",
    "        # í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}\")\n",
    "            \n",
    "            # í´ë” ë‚´ì˜ íŒŒì¼ ê²€ìƒ‰\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('_combined_features.npy'):\n",
    "                        npy_path = os.path.join(root, file)\n",
    "                        npy_files.append(npy_path)\n",
    "                        if len(npy_files) % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "                            print(f\"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(npy_files)}\")\n",
    "        else:\n",
    "            print(f\"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return npy_files\n",
    "\n",
    "\n",
    "def get_file_paths_txt(npy_files):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ ê²½ë¡œë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    txt_files = []\n",
    "    \n",
    "    for npy_path in npy_files:\n",
    "        # íŒŒì¼ëª… ì¶”ì¶œ (ê²½ë¡œì™€ í™•ì¥ì ì œê±°)\n",
    "        file_name = os.path.basename(npy_path).replace('_combined_features.npy', '')\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„\n",
    "        dir_path = os.path.dirname(npy_path)\n",
    "        parent_dir = os.path.basename(dir_path)\n",
    "        \n",
    "        # í•´ë‹¹ G2P í´ë” ê²½ë¡œ ìƒì„±\n",
    "        g2p_dir = parent_dir + \"_g2p\"\n",
    "        g2p_dir_path = os.path.join(os.path.dirname(dir_path), g2p_dir)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±\n",
    "        txt_path = os.path.join(g2p_dir_path, file_name + \".txt\")\n",
    "        \n",
    "        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì„ íƒì )\n",
    "        if os.path.exists(txt_path):\n",
    "            txt_files.append(txt_path)\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {txt_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return txt_files\n",
    "\n",
    "\n",
    "def create_dataset(npy_files, txt_files, max_samples=None):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    \n",
    "    # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    if max_samples is not None:\n",
    "        npy_files = npy_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npy_file, txt_file in zip(npy_files, txt_files):\n",
    "        try:\n",
    "            # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            if os.path.exists(npy_file) and os.path.exists(txt_file):\n",
    "                # npy íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "                test_array = np.load(npy_file)\n",
    "                if len(test_array) > 0:  # ë¹ˆ ë°°ì—´ ì²´í¬\n",
    "                    data[\"audio\"].append(npy_file)\n",
    "                    data[\"text\"].append(load_text(txt_file))\n",
    "                else:\n",
    "                    print(f\"ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼ ê±´ë„ˆëœ€: {npy_file}\")\n",
    "            else:\n",
    "                print(f\"íŒŒì¼ ì—†ìŒ: {npy_file} ë˜ëŠ” {txt_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {npy_file}, ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "def train_whisper_model():\n",
    "    # ê²½ë¡œ ìˆ˜ì •\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    output_dir = \"whisper_finetuned\"\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(base_directory)\n",
    "    \n",
    "    if len(npy_files) == 0:\n",
    "        print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return None, None\n",
    "    \n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³ \n",
    "    if len(npy_files) != len(txt_files):\n",
    "        print(f\"ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜({len(npy_files)})ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜({len(txt_files)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ë§Œ ì‚¬ìš©\n",
    "        if len(npy_files) > len(txt_files):\n",
    "            npy_files = npy_files[:len(txt_files)]\n",
    "        else:\n",
    "            txt_files = txt_files[:len(npy_files)]\n",
    "    \n",
    "    dataset = create_dataset(npy_files, txt_files)\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            # npy íŒŒì¼ ë¡œë“œ\n",
    "            audio_array = np.load(audio_path)\n",
    "            # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "            if audio_array.dtype in [np.int16, np.int8]:\n",
    "                max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "                audio_array = audio_array.astype(np.float32) / max_value\n",
    "            elif audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            \n",
    "            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "            sampling_rate = 16000\n",
    "            \n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— Audio í˜•ì‹ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # Whisper ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (fp16 ì‚¬ìš©)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\n",
    "        \"openai/whisper-small\", \n",
    "        use_cache=False,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16  # fp16 ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        # ì˜¤ë””ì˜¤ ì²˜ë¦¬\n",
    "        audio = batch[\"audio\"]\n",
    "    \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "    \n",
    "        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "    \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´ (fp16)\n",
    "        input_features = input_features.to(model.dtype)\n",
    "    \n",
    "        # í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "        labels = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš©\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    # ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        # pred_idsê°€ íŠœí”Œì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì˜ˆì¸¡ê°’)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "\n",
    "        # ì´ì œ pred_idsê°€ í…ì„œ/ë°°ì—´ì¸ì§€ í™•ì¸í•˜ê³  3ì°¨ì›ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "        if hasattr(pred_ids, 'shape') and len(pred_ids.shape) > 2:\n",
    "            pred_ids = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "        # íŒ¨ë”© í† í° ë¬´ì‹œ\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        # ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # WER ê³„ì‚°\n",
    "        try:\n",
    "            import jiwer\n",
    "            wer = jiwer.wer(label_str, pred_str)\n",
    "        except ImportError:\n",
    "            print(\"jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WER ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            wer = 0.0\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    # í›ˆë ¨ ì¸ì ì„¤ì • (ì•ˆì •ì ì¸ fp16 ì„¤ì •)\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=5e-6,  # í•™ìŠµë¥  ë‚®ì¶¤ (ì›ë˜ 1e-5ì—ì„œ)\n",
    "        warmup_steps=500,\n",
    "        max_steps=4000,\n",
    "        gradient_checkpointing=True,\n",
    "        fp16=True,\n",
    "        max_grad_norm=1.0,  # gradient clipping ì ë‹¹íˆ ì„¤ì •\n",
    "        dataloader_pin_memory=False,\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_steps=500,\n",
    "        logging_steps=25,\n",
    "        report_to=[\"tensorboard\"],\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    # í›ˆë ¨ê¸° ì„¤ì •\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    print(\"ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "    print(\"í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\")\n",
    "    try:\n",
    "        test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "        sr = 16000\n",
    "\n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                language=\"korean\",  # í•œêµ­ì–´ ëª…ì‹œ\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "\n",
    "        # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Whisper í•œêµ­ì–´ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    model, processor = train_whisper_model()\n",
    "    \n",
    "    if model is None or processor is None:\n",
    "        print(\"ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(test_directory)\n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼: {len(npy_files)}ê°œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ìˆ˜ ì œí•œ (ì„ íƒì )\n",
    "    max_test_files = 10\n",
    "    test_npy_files = npy_files[:max_test_files]\n",
    "    test_txt_files = txt_files[:max_test_files]\n",
    "    \n",
    "    print(\"í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "    for i in range(len(test_npy_files)):\n",
    "        test_audio = test_npy_files[i]\n",
    "        reference_text = load_text(test_txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74e3319-90a9-403f-bb29-70539811a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-26 15:06:10.895768: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-26 15:06:10.943293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-26 15:06:11.655394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper í•œêµ­ì–´ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "ì´ 12714ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜(12714)ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜(12713)ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12713/12713 [00:05<00:00, 2151.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10170/10170 [35:18<00:00,  4.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [04:27<00:00,  4.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1271/1271 [04:27<00:00,  4.76 examples/s]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ëŠ¥ë ¥: (8, 6), BF16 ì§€ì›: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24804/282252810.py:339: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 4:53:34, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>6.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>4.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>4.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>4.248900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>3.970200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>3.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.607500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>3.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.500900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>3.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>3.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>3.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>3.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>3.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>3.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>3.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>3.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>3.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>3.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>3.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>3.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>3.079500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>3.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.869200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.869900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.886100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.894300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.880500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.899100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.725400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.724200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>2.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>2.680600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.745700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>2.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.730800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>2.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.721100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>2.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>2.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>2.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>2.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>2.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>2.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.697700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>2.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>2.662900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>2.516100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>2.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>2.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>2.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>2.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>2.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>2.641600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>2.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.538200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>2.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>2.568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>2.576100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>2.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>2.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>2.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>2.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.537400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>2.569400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>2.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>2.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>2.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>2.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>2.458900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>2.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>2.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>2.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>2.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>2.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>2.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>2.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>2.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.469200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>2.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>2.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.395800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>2.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>2.354300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>2.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>2.341500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>2.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>2.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.337800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\n",
      "í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1272' max='1272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1272/1272 02:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'eval_loss': 3.03531551361084, 'eval_runtime': 163.0837, 'eval_samples_per_second': 7.8, 'eval_steps_per_second': 7.8, 'epoch': 6.289308176100629}\n",
      "ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "í…ŒìŠ¤íŠ¸í•  íŒŒì¼: 12714ê°œ\n",
      "í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì¼: KsponSpeech_000455_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì˜¤/ ê·¼ë° ë§ˆ ëˆ¤ì§œë¦¬ ë¼ë©´ ëˆ„ ë‚˜íŒŒê°€ì§€ê³ . ë¹„/\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ëŸ¬ë¬´í•œ ì‚¬ëŒí•œí…ŒëŠ” ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒ. ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœì„ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœï¿½ë¥¼ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë¥¼ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë¥¼ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ï¿½ë§Œ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ï¿½ë§Œ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœë§ˆë‹ˆë¥´ ëŸ¬ë¬´í•œì§€ ëŸ¬ë¬´í•œì§€ ëŸ¬ë¬´í•œì§€ ëŸ¬ë¬´í•œì§€ ëŸ¬ë¬´í•œì§€ ëŸ¬ë¬´í•œì§€ ëŸ¬ë§ˆë‚˜ ëŸ¬ë§„ë§ˆë‚˜ ëŸ¬ë§ˆë‚˜ ëŸ¬ë§ˆë‚˜ ëŸ¬ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜ ë§ˆë‚˜\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000336_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì˜¤/ í•˜, ê·¼ë°, ê·¸ëŸ¬ì¼€ í•˜ë©´ ë˜, ë³´ê³ ì‹œí”ˆ ê³µì—¬ë‹ˆë‚˜ ì˜í™”ì´ì“°ë©´ ëª¯ ë½€ê³  ì´ëŸ¬ë‹ˆê¹Œ,\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë˜ê°€ ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€?ì§€?ì§€?ì§€? ë­ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000639_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì—”/ ì•„íŒŒíŠ¸ ë³„ë¡œë¼ê³  í•˜ì§€ ì•„ë‚˜ì¨? ì—”/\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë¡¤ëŸ¬ìŠ¤ì—ë‹¤ê°€ ë­ì§€? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000961_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì•„ë‹ˆ. í”„ë¼í•˜ê°€ ê°€ê³  ì‹­ë”°ë©´ì„œ ê°‘ì§œê¸° ê°€ê³  ì‹­ ì‚/ ì—”/\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë¡¤ëŸ¬ìŠ¤ì—ë‹¤ê°€ ë­ì§€? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤ì ¤\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000124_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ê¸ˆ ê·¸ ë’¤ìª¼ê¸¸êº¼ ë¼ ê±” ì´ë²ˆ ì£¼ ëª¨êµ+ ëª¨êµì¼ ë„ í•™ê¾œ ê°„ë‹¤ ê·¸ëœëŠ”ë°.\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ëŸ¬ë¬´í•œ ì‚¬ëŒí•œí…ŒëŠ” ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ ë¹„ìŠ¤íƒœìŠ¤ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë ˆì„œëŠ” ë¹„ìŠ¤íƒœì„ ëŸ¬ë¬´í•œ ì‚¬ëŒë“œë¦¬ì— ëŒ€í•´ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë ˆì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœï¿½ë˜ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœï¿½ë˜ì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœï¿½ë˜ìš”. ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœë ˆì„œëŠ” ë¹„ìŠ¤íƒœë ˆ ì¸ì œë‹ˆë¥´ ëŸ´ï¿½ë¦¬ë‹ˆë¥´ ëŸ´ï¿½ë¦¬ë‹ˆë¥´ ëŸ³ï¿½ï¿½ï¿½ï¿½ ëŸ¼ï¿½ë¥´ ëŸ³ï¿½\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000139_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì˜¬ë¼ë„ íƒˆ ì‚¬ëŒ ë‹¤ íƒ€. ë§¨ë‚  ë‹¤ë“¤ ë¹„/ ì–´/ ì´ì œ ëª¯ íƒ„ë‹¤, ëª¯ íƒ€ê²“ë”° ê·¸ëŸ¬ëŠ”ë° ë¹„/ ë‹´ë°°ë§Œ í•´ë„ ë´ë´. ë‹´ë°° ë¹„/ ì–´ (ì´ë°°)/(ë‘ ë°°)ê°€ ì˜¬ë€ëŠ”ë°\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë˜ê°€ ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€?ì§€?ì§€? ë­ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000753_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì•„ë‹ˆì•¼. ë‚˜ ê·¸ë•Œ ê±°ì˜ ì‹¤ì„¸+ ì‹¤ì„¸ì—¬ì¨.\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë¡¤ëŸ¬ìŠ¤ì—ë‹¤ê°€ ë­ì§€? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤ì ¤? ì—”ì ¤ì ¤ì ¤\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000212_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ë„ˆ ì†Œì•„ê³¼ ê°€ë©´ ì§„ì§œ ì• ë“¤ ë•Œë¦¬ê³  ë‚ ë¦¬ë„ ì•„ë‹ˆê²“ë”°.\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë¡¤ëŸ¬ìŠ¤ì—ë‹¤ê°€ ë­ì§€? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤? ì—”ì ¤ì ¤ì ¤? ì—”ì ¤ì ¤ì ¤\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000238_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ì˜¤/ ì¹œí•´ì§ˆ ë­/ ë…¸ë ¥ë˜ í•˜ì§€ ì•ˆëŠ”ë‹¤ ì´ë”´ ì‹œê·¸ë¡œ ì–˜ê¸°í•´ì„œ ë¹„/ ì•„/ ê±” ë³¼ ë•Œë§ˆë‹¤ ì •ë§ ëŸ¬ë¬´ ë¯¼ë§í•˜ë”ë¼ê³ , ìŒ/ ê·¸ë˜ì¨.\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë˜ê°€ ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€? ë­ì§€?ì§€? ë­ì§€?ì§€? ë­ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€?ì§€\n",
      "--------------------------------------------------\n",
      "íŒŒì¼: KsponSpeech_000233_combined_features.npy\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: ê·¸/ ì•½ê¹ ë­ë¼ í•´ì•¼ ë˜ì§€? ë‹¤ ë§ˆìì•¼ ëœë‹¤ëŠ” ê·¸ëŸ° ê´€ë…?\n",
      "ë³€í™˜ ê²°ê³¼: ì˜¤ëŠ˜ ë¡¤ëŸ¬ìŠ¤ ëŸ¬ë– ì¼€ ì–˜ê¸°í•˜ìê³ ? ì—˜, ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ê¸°ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ë‹ˆê¹Œ. ë¹„í–‰ï¿½ê¹ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›ŒëŠ” ê°€ì›Œ\n",
      "--------------------------------------------------\n",
      "ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "# ì˜¤ì „ 12ì‹œ 6ë¶„ ë°¤ì— ëŒë¦°ê±°\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def load_text(file_path):\n",
    "    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def get_file_paths_npy(base_directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ NP íŒŒì¼(combined_features.npy)ì˜ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    npy_files = []\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ í´ë” ëª©ë¡ ìƒì„±\n",
    "    base_folders = []\n",
    "    for i in range(1, 19):\n",
    "        if i > 9:\n",
    "            base_folders.append(f\"KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base_folders.append(f\"KsponSpeech_000{i}\")\n",
    "\n",
    "    # ëª¨ë“  í´ë” ìˆœíšŒ\n",
    "    for folder in base_folders:\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        \n",
    "        # í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}\")\n",
    "            \n",
    "            # í´ë” ë‚´ì˜ íŒŒì¼ ê²€ìƒ‰\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('_combined_features.npy'):\n",
    "                        npy_path = os.path.join(root, file)\n",
    "                        npy_files.append(npy_path)\n",
    "                        if len(npy_files) % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "                            print(f\"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(npy_files)}\")\n",
    "        else:\n",
    "            print(f\"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return npy_files\n",
    "\n",
    "\n",
    "def get_file_paths_txt(npy_files):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ ê²½ë¡œë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    txt_files = []\n",
    "    \n",
    "    for npy_path in npy_files:\n",
    "        # íŒŒì¼ëª… ì¶”ì¶œ (ê²½ë¡œì™€ í™•ì¥ì ì œê±°)\n",
    "        file_name = os.path.basename(npy_path).replace('_combined_features.npy', '')\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„\n",
    "        dir_path = os.path.dirname(npy_path)\n",
    "        parent_dir = os.path.basename(dir_path)\n",
    "        \n",
    "        # í•´ë‹¹ G2P í´ë” ê²½ë¡œ ìƒì„±\n",
    "        g2p_dir = parent_dir + \"_g2p\"\n",
    "        g2p_dir_path = os.path.join(os.path.dirname(dir_path), g2p_dir)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±\n",
    "        txt_path = os.path.join(g2p_dir_path, file_name + \".txt\")\n",
    "        \n",
    "        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì„ íƒì )\n",
    "        if os.path.exists(txt_path):\n",
    "            txt_files.append(txt_path)\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {txt_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return txt_files\n",
    "\n",
    "\n",
    "def create_dataset(npy_files, txt_files, max_samples=None):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    \n",
    "    # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    if max_samples is not None:\n",
    "        npy_files = npy_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npy_file, txt_file in zip(npy_files, txt_files):\n",
    "        try:\n",
    "            # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            if os.path.exists(npy_file) and os.path.exists(txt_file):\n",
    "                # npy íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "                test_array = np.load(npy_file)\n",
    "                if len(test_array) > 0:  # ë¹ˆ ë°°ì—´ ì²´í¬\n",
    "                    data[\"audio\"].append(npy_file)\n",
    "                    data[\"text\"].append(load_text(txt_file))\n",
    "                else:\n",
    "                    print(f\"ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼ ê±´ë„ˆëœ€: {npy_file}\")\n",
    "            else:\n",
    "                print(f\"íŒŒì¼ ì—†ìŒ: {npy_file} ë˜ëŠ” {txt_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {npy_file}, ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "def train_whisper_model():\n",
    "    # ê²½ë¡œ ìˆ˜ì •\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    output_dir = \"whisper_finetuned\"\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(base_directory)\n",
    "    \n",
    "    if len(npy_files) == 0:\n",
    "        print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return None, None\n",
    "    \n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³ \n",
    "    if len(npy_files) != len(txt_files):\n",
    "        print(f\"ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜({len(npy_files)})ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜({len(txt_files)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ë§Œ ì‚¬ìš©\n",
    "        if len(npy_files) > len(txt_files):\n",
    "            npy_files = npy_files[:len(txt_files)]\n",
    "        else:\n",
    "            txt_files = txt_files[:len(npy_files)]\n",
    "    \n",
    "    dataset = create_dataset(npy_files, txt_files)\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            # npy íŒŒì¼ ë¡œë“œ\n",
    "            audio_array = np.load(audio_path)\n",
    "            # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "            if audio_array.dtype in [np.int16, np.int8]:\n",
    "                max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "                audio_array = audio_array.astype(np.float32) / max_value\n",
    "            elif audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            \n",
    "            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "            sampling_rate = 16000\n",
    "            \n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— Audio í˜•ì‹ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # Whisper ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\n",
    "        \"openai/whisper-small\", \n",
    "        use_cache=False,\n",
    "        low_cpu_mem_usage=True\n",
    "        # torch_dtypeëŠ” ìë™ìœ¼ë¡œ ê²°ì •ë˜ë„ë¡ í•¨\n",
    "    )\n",
    "    \n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        # ì˜¤ë””ì˜¤ ì²˜ë¦¬\n",
    "        audio = batch[\"audio\"]\n",
    "    \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "    \n",
    "        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "    \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´ (fp16)\n",
    "        input_features = input_features.to(model.dtype)\n",
    "    \n",
    "        # í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "        labels = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš©\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    # ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        # pred_idsê°€ íŠœí”Œì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì˜ˆì¸¡ê°’)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "\n",
    "        # ì´ì œ pred_idsê°€ í…ì„œ/ë°°ì—´ì¸ì§€ í™•ì¸í•˜ê³  3ì°¨ì›ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "        if hasattr(pred_ids, 'shape') and len(pred_ids.shape) > 2:\n",
    "            pred_ids = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "        # íŒ¨ë”© í† í° ë¬´ì‹œ\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        # ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # WER ê³„ì‚°\n",
    "        try:\n",
    "            import jiwer\n",
    "            wer = jiwer.wer(label_str, pred_str)\n",
    "        except ImportError:\n",
    "            print(\"jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WER ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            wer = 0.0\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    # GPU ëŠ¥ë ¥ í™•ì¸í•˜ì—¬ ìµœì  ì„¤ì • ì„ íƒ\n",
    "    device_capability = torch.cuda.get_device_capability() if torch.cuda.is_available() else (0, 0)\n",
    "    supports_bf16 = device_capability >= (8, 0)  # Ampere ì´ìƒ\n",
    "    \n",
    "    print(f\"GPU ëŠ¥ë ¥: {device_capability}, BF16 ì§€ì›: {supports_bf16}\")\n",
    "    \n",
    "    # í›ˆë ¨ ì¸ì ì„¤ì • (GPUì— ë”°ë¼ ìë™ ì„ íƒ)\n",
    "    if supports_bf16:\n",
    "        # BF16 ì‚¬ìš© (Ampere GPU)\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=2,\n",
    "            learning_rate=1e-5,\n",
    "            warmup_steps=500,\n",
    "            max_steps=4000,\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=True,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "    else:\n",
    "        # Float32 ì‚¬ìš© (ì•ˆì •ì ì´ì§€ë§Œ ëŠë¦¼)\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=4,  # ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=4,  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ëŠ˜ë¦¼\n",
    "            learning_rate=1e-5,\n",
    "            warmup_steps=500,\n",
    "            max_steps=4000,\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=False,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "\n",
    "    # í›ˆë ¨ê¸° ì„¤ì •\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    print(\"ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "    print(\"í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\")\n",
    "    try:\n",
    "        test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "        sr = 16000\n",
    "\n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                language=\"korean\",  # í•œêµ­ì–´ ëª…ì‹œ\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "\n",
    "        # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Whisper í•œêµ­ì–´ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    model, processor = train_whisper_model()\n",
    "    \n",
    "    if model is None or processor is None:\n",
    "        print(\"ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(test_directory)\n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼: {len(npy_files)}ê°œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ìˆ˜ ì œí•œ (ì„ íƒì )\n",
    "    max_test_files = 10\n",
    "    test_npy_files = npy_files[:max_test_files]\n",
    "    test_txt_files = txt_files[:max_test_files]\n",
    "    \n",
    "    print(\"í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "    for i in range(len(test_npy_files)):\n",
    "        test_audio = test_npy_files[i]\n",
    "        reference_text = load_text(test_txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca83402-3b4d-4204-bdb6-95416da4ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ê¸°ë³¸ ë²„ì „ ===\n",
      "ì›ë³¸ ì˜¤ë””ì˜¤ shape: (129280,)\n",
      "ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ shape: (129280,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì¢… ì…ë ¥ features shape: torch.Size([1, 80, 3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ í† í° ìˆ˜: 58\n",
      "Raw tokens (ì²˜ìŒ 20ê°œ): [50258, 50264, 50359, 50363, 8880, 24915, 36265, 14173, 18016, 4673, 1955, 1098, 48735, 5905, 24902, 12092, 5963, 117, 19041, 4130]\n",
      "\n",
      "=== ê°„ë‹¨ ë²„ì „ ===\n",
      "ê²°ê³¼:  ì˜¤ëŠ˜ êµìœ¡ëŒ€í† ë¡œëŠ” íŠ¹ë³„íˆ ì²­ë…„íŠ¹ì§‘ìœ¼ë¡œ ê³„íšë˜ëŠ” ê±°ìë‚˜ ì²­ë…„ë“¤ì˜ ê²½í—˜ì„ ì˜ ë“£ê³  ì—¬ê¸°ì—ì„œ ê³µê°í•  ìˆ˜ ìˆëŠ” ìë¦¬ê°€ ë§ˆë ¨ë˜ì—ˆìœ¼ë©´ í•©ë‹ˆë‹¤.\n",
      "\n",
      "=== ê³ ê¸‰ ë²„ì „ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ê³¼:  ì˜¤ëŠ˜ êµìœ¡ëŒ€í† ë¡œëŠ” íŠ¹ë³„ë¦¬ ì²­ë…„íŠ¹ì§‘ìœ¼ë¡œ ê³„íšë˜ëŠ” ê±°ìë‚˜ìš”. ì²­ë…„ë“¤ì˜ ê²½ì—…ì„ ì˜ ë“£ê³  ì—¬ê¸°ì—ì„œ ê³µê°í•  ìˆ˜ ìˆëŠ” ìë¦¬ê°€ ë§ˆë ¨ë˜ ì—ˆìœ¼ë©´ í•©ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    ë°˜ë³µ ìƒì„± ë¬¸ì œ í•´ê²° ë²„ì „\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # ë°ì´í„° ì°¨ì› í™•ì¸ ë° ì²˜ë¦¬\n",
    "        print(f\"ì›ë³¸ ì˜¤ë””ì˜¤ shape: {audio_array.shape}\")\n",
    "        \n",
    "        # 2D ë°°ì—´ì¸ ê²½ìš° 1Dë¡œ ë³€í™˜ (ì‹œê°„ì¶•ë§Œ ë‚¨ê¸°ê¸°)\n",
    "        if len(audio_array.shape) == 2:\n",
    "            # ë³´í†µ (time, features) ë˜ëŠ” (features, time) í˜•íƒœ\n",
    "            if audio_array.shape[0] < audio_array.shape[1]:\n",
    "                audio_array = audio_array.flatten()  # ë˜ëŠ” ì ì ˆí•œ ì¶• ì„ íƒ\n",
    "            else:\n",
    "                audio_array = audio_array.flatten()  # ë˜ëŠ” ì ì ˆí•œ ì¶• ì„ íƒ\n",
    "        \n",
    "        print(f\"ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ shape: {audio_array.shape}\")\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "        sr = 16000\n",
    "\n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ìµœì¢… ì…ë ¥ features shape: {input_features.shape}\")\n",
    "\n",
    "        # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡ (ê²½ê³  í•´ê²°)\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=448,\n",
    "                num_beams=1,              # beam search ë„ê¸°\n",
    "                do_sample=False,          # ìƒ˜í”Œë§ ë„ê¸°  \n",
    "                early_stopping=False,     # num_beams=1ì¼ ë•Œ Falseë¡œ ì„¤ì •\n",
    "                repetition_penalty=2.0,   # ë°˜ë³µ íŒ¨ë„í‹° ê°•í™”\n",
    "                no_repeat_ngram_size=3,   # 3-gram ë°˜ë³µ ë°©ì§€\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=processor.tokenizer.eos_token_id,\n",
    "                language=\"ko\",            # í•œêµ­ì–´ ëª…ì‹œ (ì–¸ì–´ ê°ì§€ ê²½ê³  í•´ê²°)\n",
    "                task=\"transcribe\",        # ëª…ì‹œì ìœ¼ë¡œ ì „ì‚¬ ì‘ì—… ì§€ì •\n",
    "            )\n",
    "\n",
    "        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ìƒì„±ëœ í† í° ìˆ˜: {len(predicted_ids[0])}\")\n",
    "        print(f\"Raw tokens (ì²˜ìŒ 20ê°œ): {predicted_ids[0][:20].tolist()}\")\n",
    "\n",
    "        # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def transcribe_audio_simple(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    ê°€ì¥ ê°„ë‹¨í•œ ë²„ì „ - ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì… ë§ì¶”ê¸°\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ê°€ì¥ ê¸°ë³¸ì ì¸ ìƒì„±\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(input_features)\n",
    "\n",
    "        # ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def transcribe_audio_advanced(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    ê³ ê¸‰ ì„¤ì • ë²„ì „ - ë” ì„¸ë°€í•œ ì œì–´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì… ë§ì¶”ê¸°\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ê³ ê¸‰ ì„¤ì •ìœ¼ë¡œ ìƒì„±\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=224,           # ê¸¸ì´ ë” ì œí•œ\n",
    "                min_length=1,             # ìµœì†Œ ê¸¸ì´\n",
    "                num_beams=2,              # beam search í™œì„±í™”\n",
    "                do_sample=True,           # ìƒ˜í”Œë§ í™œì„±í™”\n",
    "                temperature=0.7,          # ì˜¨ë„ ë‚®ì¶¤\n",
    "                top_p=0.9,               # nucleus sampling\n",
    "                repetition_penalty=1.5,   # ë°˜ë³µ íŒ¨ë„í‹°\n",
    "                no_repeat_ngram_size=4,   # 4-gram ë°˜ë³µ ë°©ì§€\n",
    "                early_stopping=True,\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "        # ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ëª¨ë¸ ë¡œë“œ (ì´ë¯¸ í›ˆë ¨ëœ ëª¨ë¸)\n",
    "    from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "    \n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"whisper_finetuned\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"whisper_finetuned\")\n",
    "\n",
    "\n",
    "        # NPZì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ\n",
    "    npz_data = np.load(\"output_npz/example_data.npz\")\n",
    "    audio_data = npz_data['audio_data']  # ì›ë³¸ ì˜¤ë””ì˜¤\n",
    "    np.save(\"temp_audio.npy\", audio_data)\n",
    "    \n",
    "    # ì´ì œ NPY íŒŒì¼ ì‚¬ìš©\n",
    "    test_audio = \"temp_audio.npy\"\n",
    "    \n",
    "    # 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "    print(\"=== ê¸°ë³¸ ë²„ì „ ===\")\n",
    "    result1 = transcribe_audio(model, processor, test_audio)\n",
    "\n",
    "    '''\n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼\n",
    "    test_audio = \"output_npz/example_data.wav\"\n",
    "    # 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "    print(\"=== ê¸°ë³¸ ë²„ì „ ===\")\n",
    "    result1 = transcribe_audio(model, processor, test_audio)\n",
    "    print(f\"ê²°ê³¼: {result1}\")\n",
    "    '''\n",
    "    print(\"\\n=== ê°„ë‹¨ ë²„ì „ ===\")\n",
    "    result2 = transcribe_audio_simple(model, processor, test_audio)\n",
    "    print(f\"ê²°ê³¼: {result2}\")\n",
    "    \n",
    "    print(\"\\n=== ê³ ê¸‰ ë²„ì „ ===\")\n",
    "    result3 = transcribe_audio_advanced(model, processor, test_audio)\n",
    "    print(f\"ê²°ê³¼: {result3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a85493-6fb5-4084-8a9d-c2e7ba24cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mExampleData\u001b[0m/            example.txt       preprocessing_delete_noise.ipynb\n",
      "GPUí…ŒìŠ¤íŠ¸_ìœ ì €03.ipynb  example_data.pcm  preprocessing_g2p.ipynb\n",
      "\u001b[01;34mPreprocessData\u001b[0m/         \u001b[00;36mexample_data.wav\u001b[0m  preprocessing_mfcc.ipynb\n",
      "\u001b[01;34mTrainData\u001b[0m/              \u001b[00;36mnews_data.mp3\u001b[0m     \u001b[01;34mwhisper_finetuned\u001b[0m/\n",
      "data.ipynb              news_data.pcm\n",
      "\u001b[01;34mdependency_library\u001b[0m/     \u001b[00;36mnews_data.wav\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c93fc-a9b0-4565-9852-9ccc8cc0ac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-27 03:00:55.360279: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-27 03:00:55.407883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-27 03:00:56.128477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper í•œêµ­ì–´ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "ì´ 12714ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜(12714)ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜(12713)ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 2071.84 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [02:47<00:00,  4.77 examples/s]\n",
      "Map:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 58/100 [00:12<00:08,  4.71 examples/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "# 5ì›” 27ì¼ (í™”) ì˜¤í›„ 12ì‹œ ì‹œë„\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def load_text(file_path):\n",
    "    # ì¼ë°˜ì ì¸ í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "def get_file_paths_npy(base_directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ NP íŒŒì¼(combined_features.npy)ì˜ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    npy_files = []\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ í´ë” ëª©ë¡ ìƒì„±\n",
    "    base_folders = []\n",
    "    for i in range(1, 19):\n",
    "        if i > 9:\n",
    "            base_folders.append(f\"KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base_folders.append(f\"KsponSpeech_000{i}\")\n",
    "\n",
    "    # ëª¨ë“  í´ë” ìˆœíšŒ\n",
    "    for folder in base_folders:\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        \n",
    "        # í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}\")\n",
    "            \n",
    "            # í´ë” ë‚´ì˜ íŒŒì¼ ê²€ìƒ‰\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('_combined_features.npy'):\n",
    "                        npy_path = os.path.join(root, file)\n",
    "                        npy_files.append(npy_path)\n",
    "                        if len(npy_files) % 100 == 0:  # 100ê°œë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "                            print(f\"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(npy_files)}\")\n",
    "        else:\n",
    "            print(f\"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return npy_files\n",
    "\n",
    "\n",
    "def get_file_paths_txt(npy_files):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ ê²½ë¡œë¡œë¶€í„° í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    txt_files = []\n",
    "    \n",
    "    for npy_path in npy_files:\n",
    "        # íŒŒì¼ëª… ì¶”ì¶œ (ê²½ë¡œì™€ í™•ì¥ì ì œê±°)\n",
    "        file_name = os.path.basename(npy_path).replace('_combined_features.npy', '')\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„\n",
    "        dir_path = os.path.dirname(npy_path)\n",
    "        parent_dir = os.path.basename(dir_path)\n",
    "        \n",
    "        # í•´ë‹¹ G2P í´ë” ê²½ë¡œ ìƒì„±\n",
    "        g2p_dir = parent_dir + \"_g2p\"\n",
    "        g2p_dir_path = os.path.join(os.path.dirname(dir_path), g2p_dir)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±\n",
    "        txt_path = os.path.join(g2p_dir_path, file_name + \".txt\")\n",
    "        \n",
    "        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì„ íƒì )\n",
    "        if os.path.exists(txt_path):\n",
    "            txt_files.append(txt_path)\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {txt_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return txt_files\n",
    "\n",
    "\n",
    "def create_dataset(npy_files, txt_files, max_samples=None):\n",
    "    \"\"\"\n",
    "    NP íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    \n",
    "    # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    if max_samples is not None:\n",
    "        npy_files = npy_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npy_file, txt_file in zip(npy_files, txt_files):\n",
    "        try:\n",
    "            # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            if os.path.exists(npy_file) and os.path.exists(txt_file):\n",
    "                # npy íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "                test_array = np.load(npy_file)\n",
    "                if len(test_array) > 0:  # ë¹ˆ ë°°ì—´ ì²´í¬\n",
    "                    data[\"audio\"].append(npy_file)\n",
    "                    data[\"text\"].append(load_text(txt_file))\n",
    "                else:\n",
    "                    print(f\"ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼ ê±´ë„ˆëœ€: {npy_file}\")\n",
    "            else:\n",
    "                print(f\"íŒŒì¼ ì—†ìŒ: {npy_file} ë˜ëŠ” {txt_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {npy_file}, ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "def train_whisper_model():\n",
    "    # ê²½ë¡œ ìˆ˜ì •\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    output_dir = \"whisper_finetuned\"\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(base_directory)\n",
    "    \n",
    "    if len(npy_files) == 0:\n",
    "        print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return None, None\n",
    "    \n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³ \n",
    "    if len(npy_files) != len(txt_files):\n",
    "        print(f\"ê²½ê³ : ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜({len(npy_files)})ì™€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜({len(txt_files)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ë§Œ ì‚¬ìš©\n",
    "        if len(npy_files) > len(txt_files):\n",
    "            npy_files = npy_files[:len(txt_files)]\n",
    "        else:\n",
    "            txt_files = txt_files[:len(npy_files)]\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "    max_samples = 1000  # ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸\n",
    "    dataset = create_dataset(npy_files[:max_samples], txt_files[:max_samples])\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            # npy íŒŒì¼ ë¡œë“œ\n",
    "            audio_array = np.load(audio_path)\n",
    "            # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "            if audio_array.dtype in [np.int16, np.int8]:\n",
    "                max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "                audio_array = audio_array.astype(np.float32) / max_value\n",
    "            elif audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            \n",
    "            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "            sampling_rate = 16000\n",
    "            \n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— Audio í˜•ì‹ ì ìš© (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # Whisper ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\n",
    "        \"openai/whisper-small\", \n",
    "        use_cache=False,\n",
    "        low_cpu_mem_usage=True\n",
    "        # torch_dtypeëŠ” ìë™ìœ¼ë¡œ ê²°ì •ë˜ë„ë¡ í•¨\n",
    "    )\n",
    "    \n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        # ì˜¤ë””ì˜¤ ì²˜ë¦¬\n",
    "        audio = batch[\"audio\"]\n",
    "    \n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "    \n",
    "        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "    \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´ (fp16)\n",
    "        input_features = input_features.to(model.dtype)\n",
    "    \n",
    "        # í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "        labels = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    \n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì ìš©\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    # ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        pred_ids = pred.predictions\n",
    "        label_ids = pred.label_ids\n",
    "\n",
    "        # pred_idsê°€ íŠœí”Œì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì˜ˆì¸¡ê°’)\n",
    "        if isinstance(pred_ids, tuple):\n",
    "            pred_ids = pred_ids[0]\n",
    "\n",
    "        # ì´ì œ pred_idsê°€ í…ì„œ/ë°°ì—´ì¸ì§€ í™•ì¸í•˜ê³  3ì°¨ì›ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "        if hasattr(pred_ids, 'shape') and len(pred_ids.shape) > 2:\n",
    "            pred_ids = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "        # íŒ¨ë”© í† í° ë¬´ì‹œ\n",
    "        label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        # ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # WER ê³„ì‚°\n",
    "        try:\n",
    "            import jiwer\n",
    "            wer = jiwer.wer(label_str, pred_str)\n",
    "        except ImportError:\n",
    "            print(\"jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WER ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            wer = 0.0\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    # GPU ëŠ¥ë ¥ í™•ì¸í•˜ì—¬ ìµœì  ì„¤ì • ì„ íƒ\n",
    "    device_capability = torch.cuda.get_device_capability() if torch.cuda.is_available() else (0, 0)\n",
    "    supports_bf16 = device_capability >= (8, 0)  # Ampere ì´ìƒ\n",
    "    \n",
    "    print(f\"GPU ëŠ¥ë ¥: {device_capability}, BF16 ì§€ì›: {supports_bf16}\")\n",
    "    \n",
    "    # í›ˆë ¨ ì¸ì ì„¤ì • (GPUì— ë”°ë¼ ìë™ ì„ íƒ)\n",
    "    if supports_bf16:\n",
    "        # BF16 ì‚¬ìš© (Ampere GPU)\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=2,\n",
    "            learning_rate=5e-6,  # í•™ìŠµë¥ ì„ ë” ë‚®ì¶¤\n",
    "            warmup_steps=100,   # warmup ë‹¨ê³„ ì¤„ì„\n",
    "            max_steps=1000,     # ì´ ìŠ¤í… ì¤„ì„ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=True,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "    else:\n",
    "        # Float32 ì‚¬ìš© (ì•ˆì •ì ì´ì§€ë§Œ ëŠë¦¼)\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=4,  # ë°°ì¹˜ í¬ê¸° ì¤„ì„\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=4,  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ëŠ˜ë¦¼\n",
    "            learning_rate=1e-5,\n",
    "            warmup_steps=500,\n",
    "            max_steps=4000,\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=False,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "\n",
    "    # í›ˆë ¨ê¸° ì„¤ì •\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    print(\"ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "    print(\"í…ŒìŠ¤íŠ¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...\")\n",
    "    try:\n",
    "        test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def transcribe_audio(model, processor, audio_file):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # NP íŒŒì¼ ë¡œë“œ\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        # float32ë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (í•„ìš”í•œ ê²½ìš°)\n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        # ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” ê³ ì • (KsponSpeechëŠ” 16kHz)\n",
    "        sr = 16000\n",
    "\n",
    "        # íŠ¹ì„± ì¶”ì¶œ\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        # íƒ€ì…ì„ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚´\n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # GPU ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡ (ë°˜ë³µ ë°©ì§€ ì„¤ì • ì¶”ê°€)\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                language=\"korean\",  # í•œêµ­ì–´ ëª…ì‹œ\n",
    "                task=\"transcribe\",\n",
    "                max_length=448,  # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
    "                num_beams=1,  # beam search ë¹„í™œì„±í™” (ë¹ ë¥¸ ìƒì„±)\n",
    "                do_sample=False,  # ìƒ˜í”Œë§ ë¹„í™œì„±í™”\n",
    "                temperature=1.0,\n",
    "                repetition_penalty=1.2,  # ë°˜ë³µ íŒ¨ë„í‹° ì¶”ê°€\n",
    "                no_repeat_ngram_size=3,  # 3-gram ë°˜ë³µ ë°©ì§€\n",
    "                early_stopping=True,\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "        # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Whisper í•œêµ­ì–´ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    model, processor = train_whisper_model()\n",
    "    \n",
    "    if model is None or processor is None:\n",
    "        print(\"ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    print(\"ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(test_directory)\n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼: {len(npy_files)}ê°œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ìˆ˜ ì œí•œ (ì„ íƒì )\n",
    "    max_test_files = 10\n",
    "    test_npy_files = npy_files[:max_test_files]\n",
    "    test_txt_files = txt_files[:max_test_files]\n",
    "    \n",
    "    print(\"í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "    for i in range(len(test_npy_files)):\n",
    "        test_audio = test_npy_files[i]\n",
    "        reference_text = load_text(test_txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42208bcf-e2a4-435d-b39f-177fe3f433f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ë””ë ‰í† ë¦¬: /data/TrainData\n",
      "ìƒìœ„ ë””ë ‰í† ë¦¬: /data\n",
      "ìƒìœ„ ë””ë ‰í† ë¦¬ ë‚´ìš©: ['.Trash-0', 'GPUí…ŒìŠ¤íŠ¸_ìœ ì €03.ipynb', 'TrainData', 'data.ipynb', '.ipynb_checkpoints']\n",
      "TrainData ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: False\n",
      "\n",
      "ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ íƒìƒ‰:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "walk() got an unexpected keyword argument 'maxdepth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ ëª©ë¡ ì¶œë ¥\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ íƒìƒ‰:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopdown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dir_name \u001b[38;5;129;01min\u001b[39;00m dirs:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKspon\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dir_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeech\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dir_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dir_name:\n",
      "\u001b[0;31mTypeError\u001b[0m: walk() got an unexpected keyword argument 'maxdepth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "current_dir = os.getcwd()\n",
    "print(f\"í˜„ì¬ ë””ë ‰í† ë¦¬: {current_dir}\")\n",
    "\n",
    "# ìƒìœ„ ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "print(f\"ìƒìœ„ ë””ë ‰í† ë¦¬: {parent_dir}\")\n",
    "if os.path.exists(parent_dir):\n",
    "    print(f\"ìƒìœ„ ë””ë ‰í† ë¦¬ ë‚´ìš©: {os.listdir(parent_dir)[:10]}\")  # ì²˜ìŒ 10ê°œë§Œ\n",
    "\n",
    "# TrainData ë””ë ‰í† ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "train_data_dir = os.path.join(current_dir, \"TrainData\")\n",
    "print(f\"TrainData ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(train_data_dir)}\")\n",
    "\n",
    "# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ ëª©ë¡ ì¶œë ¥\n",
    "print(\"\\nì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ íƒìƒ‰:\")\n",
    "for root, dirs, files in os.walk(current_dir, topdown=True, maxdepth=3):\n",
    "    for dir_name in dirs:\n",
    "        if \"Kspon\" in dir_name or \"Speech\" in dir_name or \"Train\" in dir_name:\n",
    "            full_path = os.path.join(root, dir_name)\n",
    "            print(f\"ë°œê²¬: {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92b001b4-8871-47c9-a441-10fe6badd877",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (0.30.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (2.4.1+cu118)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (1.24.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.11.3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.3.0.86)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.4.1.48)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "accelerate                   1.0.1         \n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip list | grep accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21351be-a61d-4955-bfbd-09b19baaf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í• ë‹¹ëœ ë©”ëª¨ë¦¬: 10.88 GB\n",
      "ìºì‹œëœ ë©”ëª¨ë¦¬: 16.41 GB\n",
      "ìµœëŒ€ í• ë‹¹ëœ ë©”ëª¨ë¦¬: 18.72 GB\n",
      "GPU 0: NVIDIA GeForce RTX 3090\n",
      "  ë©”ëª¨ë¦¬ í• ë‹¹: 10.88 GB\n",
      "  ë©”ëª¨ë¦¬ ì˜ˆì•½: 16.41 GB\n"
     ]
    }
   ],
   "source": [
    "# PyTorchë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "import torch\n",
    "\n",
    "# í˜„ì¬ í• ë‹¹ëœ ë©”ëª¨ë¦¬ í™•ì¸\n",
    "print(f\"í• ë‹¹ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"ìºì‹œëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "print(f\"ìµœëŒ€ í• ë‹¹ëœ ë©”ëª¨ë¦¬: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# GPUë³„ ë©”ëª¨ë¦¬ í†µê³„ ìì„¸íˆ ë³´ê¸° (ì—¬ëŸ¬ GPUê°€ ìˆëŠ” ê²½ìš°)\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"  ë©”ëª¨ë¦¬ í• ë‹¹: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "    print(f\"  ë©”ëª¨ë¦¬ ì˜ˆì•½: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79123090-fb9b-4687-934d-dc9a4af74ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "/tmp/ipykernel_628/1513626050.py:8: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4, 50]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([200, 1500, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4, 1500, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4, 50, 51865]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([200, 138, 51865]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([204]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([200, 138]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([8, 80, 3000]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([8, 55]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4, 80, 3000]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([4, 50]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([8, 80, 3000]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([8, 124]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([8, 80, 3000]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([8, 72]) cpu\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([51865, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 80, 3]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768, 3]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([448, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 80, 3]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 80, 3]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768, 3]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768, 3]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([51865, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([51865, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([448, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([448, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([3072]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([]) cpu\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.Tensor'> torch.Size([768]) cuda:0\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1500, 768]) cuda:0\n",
      "ì •ë¦¬ í›„ í• ë‹¹ëœ ë©”ëª¨ë¦¬: 8.98 GB\n",
      "ì •ë¦¬ í›„ ìºì‹œëœ ë©”ëª¨ë¦¬: 12.48 GB\n"
     ]
    }
   ],
   "source": [
    "# ëª…ì‹œì ìœ¼ë¡œ ëª¨ë“  ëŒ€í˜• ê°ì²´ ì œê±°\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# ëª¨ë“  ë³€ìˆ˜ í™•ì¸ (ì˜µì…˜)\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size(), obj.device)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ê° ë³€ìˆ˜ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‚­ì œ\n",
    "try:\n",
    "    del model, processor, trainer, training_args, datasets, processed_datasets\n",
    "    del dataset, train_test_valid, test_valid\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ê°•ì œ GC ë° ìºì‹œ ì •ë¦¬\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ë‹¤ì‹œ í™•ì¸\n",
    "print(f\"ì •ë¦¬ í›„ í• ë‹¹ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"ì •ë¦¬ í›„ ìºì‹œëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d265ec47-3383-49b6-bea6-e7ccb92bf423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== example1.pcm íŒŒì¼ í…ŒìŠ¤íŠ¸ ===\n",
      "ì˜¤ë¥˜: example1.pcm íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# PCM íŒŒì¼ ë¡œë“œ í•¨ìˆ˜\n",
    "def read_pcm(file_path, sr=16000, bit_depth=16):\n",
    "    \"\"\"\n",
    "    PCM íŒŒì¼ì„ ì½ì–´ numpy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # PCM íŒŒì¼ ì½ê¸° (16ë¹„íŠ¸ ë˜ëŠ” 8ë¹„íŠ¸ ë¶€í˜¸ ìˆëŠ” ì •ìˆ˜ ê°€ì •)\n",
    "    if bit_depth == 16:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int16)\n",
    "    elif bit_depth == 8:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int8)\n",
    "    else:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int16)  # ê¸°ë³¸ê°’\n",
    "\n",
    "    # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "    max_value = float(2 ** (bit_depth - 1))\n",
    "    normalized_data = raw_data.astype(np.float32) / max_value\n",
    "\n",
    "    return normalized_data, sr\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  í•¨ìˆ˜\n",
    "def transcribe_audio(model, processor, audio_file, device):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # PCM íŒŒì¼ ë¡œë“œ\n",
    "    audio_array, sr = read_pcm(audio_file)\n",
    "\n",
    "    # íŠ¹ì„± ì¶”ì¶œ\n",
    "    input_features = processor.feature_extractor(\n",
    "        audio_array,\n",
    "        sampling_rate=sr,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    # ì…ë ¥ íŠ¹ì„±ì„ ëª¨ë¸ê³¼ ë™ì¼í•œ ì¥ì¹˜ë¡œ ì´ë™\n",
    "    input_features = input_features.to(device)\n",
    "\n",
    "    # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "    transcription = processor.tokenizer.batch_decode(\n",
    "        predicted_ids,\n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def main():\n",
    "    print(\"=== example1.pcm íŒŒì¼ í…ŒìŠ¤íŠ¸ ===\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ê²½ë¡œ\n",
    "    test_file = \"example1.pcm\"  # ì´ë¯¸ ì°¾ì€ ê²½ë¡œ ì‚¬ìš©\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"ì˜¤ë¥˜: {test_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file}\")\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ìˆëŠ” ê²½ìš°)\n",
    "    txt_file = test_file.replace('.pcm', '.txt')\n",
    "    if os.path.exists(txt_file):\n",
    "        with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "            reference_text = f.read().strip()\n",
    "        print(f\"ì°¸ì¡° í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "    else:\n",
    "        print(\"ì°¸ì¡° í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ê¸°ê¸° ì„¤ì • - CUDA ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë°©ë²•\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"CUDA ì‚¬ìš© ê°€ëŠ¥ - GPU ì‚¬ìš©\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ì‚¬ìš©\")\n",
    "    \n",
    "    # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"ê¸°ë³¸ Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "    \n",
    "    # ëª¨ë¸ì„ ì¥ì¹˜ë¡œ ëª…ì‹œì  ì´ë™\n",
    "    model = model.to(device)\n",
    "    print(f\"ëª¨ë¸ì„ {device}ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œ ì‹œë„\n",
    "    model_dir = \"saved_whisper_model\"\n",
    "    \n",
    "    # PT íŒŒì¼ ì°¾ê¸°\n",
    "    pt_files = []\n",
    "    \n",
    "    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°\n",
    "    if os.path.exists(model_dir):\n",
    "        for root, _, files in os.walk(model_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.pt'):\n",
    "                    pt_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # ë‹¤ë¥¸ ì¼ë°˜ì ì¸ ìœ„ì¹˜ë„ í™•ì¸\n",
    "    for location in [\".\", \"./saved_model\", \"./models\"]:\n",
    "        if os.path.exists(location):\n",
    "            for file in os.listdir(location):\n",
    "                if file.endswith('.pt'):\n",
    "                    pt_files.append(os.path.join(location, file))\n",
    "    \n",
    "    # pt íŒŒì¼ ì°¾ì•˜ë‹¤ë©´ ë¡œë“œ ì‹œë„\n",
    "    if pt_files:\n",
    "        print(f\"{len(pt_files)}ê°œì˜ PT íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\")\n",
    "        for i, pt_file in enumerate(pt_files):\n",
    "            print(f\"  {i+1}. {pt_file}\")\n",
    "            \n",
    "        try:\n",
    "            # ì²« ë²ˆì§¸ íŒŒì¼ ë¡œë“œ ì‹œë„\n",
    "            model_file = pt_files[0]\n",
    "            print(f\"ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹œë„: {model_file}\")\n",
    "            \n",
    "            # PT íŒŒì¼ì„ ì¥ì¹˜ì— ë§ê²Œ ë¡œë“œ\n",
    "            state_dict = torch.load(model_file, map_location=device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ!\")\n",
    "        except Exception as e:\n",
    "            print(f\"ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "            print(\"ê¸°ë³¸ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"ì €ì¥ëœ PT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    model.eval()\n",
    "    \n",
    "    # ìŒì„± ì¸ì‹ ìˆ˜í–‰\n",
    "    print(\"\\nìŒì„± ì¸ì‹ ì¤‘...\")\n",
    "    try:\n",
    "        # ì¥ì¹˜ ì •ë³´ë¥¼ transcribe_audio í•¨ìˆ˜ì— ì „ë‹¬\n",
    "        transcription = transcribe_audio(model, processor, test_file, device)\n",
    "        print(\"\\n=== ì¸ì‹ ê²°ê³¼ ===\")\n",
    "        print(transcription)\n",
    "        \n",
    "        # ì°¸ì¡° í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° WER ê³„ì‚°\n",
    "        if os.path.exists(txt_file) and 'reference_text' in locals():\n",
    "            try:\n",
    "                import jiwer\n",
    "                wer = jiwer.wer(reference_text, transcription)\n",
    "                print(f\"\\nWER (Word Error Rate): {wer:.4f}\")\n",
    "            except ImportError:\n",
    "                print(\"\\nWER ê³„ì‚°ì„ ìœ„í•´ jiwer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "                print(\"pip install jiwer ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()  # ë” ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac0ae34-4e09-4e71-a0a9-1d544630ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mExampleData\u001b[0m/            \u001b[01;34mTrainData\u001b[0m/  \u001b[01;34mwhisper_finetuned\u001b[0m/\n",
      "GPUí…ŒìŠ¤íŠ¸_ìœ ì €03.ipynb  data.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de4dd876-be9e-4f29-b6ae-58b44532d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/whisper_finetuned\n"
     ]
    }
   ],
   "source": [
    "cd /data/whisper_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e763aaf-8f41-4d7a-b447-616e2897bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /data/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cf69ec9-54d5-4591-8dcd-51e5537de084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== example1.pcm íŒŒì¼ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ëª¨ë“œ) ===\n",
      "í…ŒìŠ¤íŠ¸ íŒŒì¼: example1.pcm\n",
      "ì¥ì¹˜: cpu (ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ CPUë§Œ ì‚¬ìš©)\n",
      "ê¸°ë³¸ Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\n",
      "\n",
      "----- ì–¸ì–´ ìë™ ê°ì§€ ëª¨ë“œ -----\n",
      "ìŒì„± ì¸ì‹ ì¤‘...\n",
      "PCM íŒŒì¼ ì •ë³´:\n",
      "- ìƒ˜í”Œ ìˆ˜: 4605952\n",
      "- ìƒ˜í”Œë§ ë ˆì´íŠ¸: 16000Hz\n",
      "- ì˜¤ë””ì˜¤ ê¸¸ì´: 287.87ì´ˆ\n",
      "- ìµœì†Œê°’: -0.2336\n",
      "- ìµœëŒ€ê°’: 0.2339\n",
      "- í‰ê· ê°’: 0.0000\n",
      "- í‘œì¤€í¸ì°¨: 0.0556\n",
      "\n",
      "=== ìë™ ì–¸ì–´ ê°ì§€ ê²°ê³¼ ===\n",
      " You\n",
      "\n",
      "----- í•œêµ­ì–´ ê°•ì œ ëª¨ë“œ -----\n",
      "ìŒì„± ì¸ì‹ ì¤‘...\n",
      "PCM íŒŒì¼ ì •ë³´:\n",
      "- ìƒ˜í”Œ ìˆ˜: 4605952\n",
      "- ìƒ˜í”Œë§ ë ˆì´íŠ¸: 16000Hz\n",
      "- ì˜¤ë””ì˜¤ ê¸¸ì´: 287.87ì´ˆ\n",
      "- ìµœì†Œê°’: -0.2336\n",
      "- ìµœëŒ€ê°’: 0.2339\n",
      "- í‰ê· ê°’: 0.0000\n",
      "- í‘œì¤€í¸ì°¨: 0.0556\n",
      "ì–¸ì–´ë¥¼ koë¡œ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "=== í•œêµ­ì–´ ê°•ì œ ëª¨ë“œ ê²°ê³¼ ===\n",
      " ì´ê³³ì€ ì´ê³³ì—ì„œ ê°€ì¥ í° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# PCM íŒŒì¼ ë¡œë“œ í•¨ìˆ˜\n",
    "def read_pcm(file_path, sr=16000, bit_depth=16):\n",
    "    \"\"\"\n",
    "    PCM íŒŒì¼ì„ ì½ì–´ numpy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # PCM íŒŒì¼ ì½ê¸° (16ë¹„íŠ¸ ë˜ëŠ” 8ë¹„íŠ¸ ë¶€í˜¸ ìˆëŠ” ì •ìˆ˜ ê°€ì •)\n",
    "    if bit_depth == 16:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int16)\n",
    "    elif bit_depth == 8:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int8)\n",
    "    else:\n",
    "        raw_data = np.fromfile(file_path, dtype=np.int16)  # ê¸°ë³¸ê°’\n",
    "\n",
    "    # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "    max_value = float(2 ** (bit_depth - 1))\n",
    "    normalized_data = raw_data.astype(np.float32) / max_value\n",
    "\n",
    "    # ì§§ì€ ìŒì„± ìƒ˜í”Œ ì¶œë ¥\n",
    "    print(f\"PCM íŒŒì¼ ì •ë³´:\")\n",
    "    print(f\"- ìƒ˜í”Œ ìˆ˜: {len(normalized_data)}\")\n",
    "    print(f\"- ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr}Hz\")\n",
    "    print(f\"- ì˜¤ë””ì˜¤ ê¸¸ì´: {len(normalized_data)/sr:.2f}ì´ˆ\")\n",
    "    \n",
    "    # ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ê±°ë‚˜ ê¸´ ê²½ìš° ê²½ê³ \n",
    "    if len(normalized_data)/sr < 0.1:\n",
    "        print(\"ê²½ê³ : ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (0.1ì´ˆ ë¯¸ë§Œ)\")\n",
    "    elif len(normalized_data)/sr > 100000:\n",
    "        print(\"ê²½ê³ : ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ì´ˆê³¼)\")\n",
    "    \n",
    "    # ì˜¤ë””ì˜¤ ì‹ í˜¸ í†µê³„ ì¶œë ¥\n",
    "    print(f\"- ìµœì†Œê°’: {normalized_data.min():.4f}\")\n",
    "    print(f\"- ìµœëŒ€ê°’: {normalized_data.max():.4f}\")\n",
    "    print(f\"- í‰ê· ê°’: {normalized_data.mean():.4f}\")\n",
    "    print(f\"- í‘œì¤€í¸ì°¨: {normalized_data.std():.4f}\")\n",
    "    \n",
    "    # ëª¨ë‘ 0ì´ê±°ë‚˜ ì¼ì •í•œ ê°’ì¸ì§€ í™•ì¸\n",
    "    if np.all(normalized_data == 0):\n",
    "        print(\"ê²½ê³ : ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ëª¨ë‘ 0ì…ë‹ˆë‹¤!\")\n",
    "    elif np.std(normalized_data) < 0.001:\n",
    "        print(\"ê²½ê³ : ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ë³€ë™ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    return normalized_data, sr\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  í•¨ìˆ˜\n",
    "def transcribe_audio(model, processor, audio_file, device, forced_language=None):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # PCM íŒŒì¼ ë¡œë“œ\n",
    "    audio_array, sr = read_pcm(audio_file)\n",
    "\n",
    "    # íŠ¹ì„± ì¶”ì¶œ\n",
    "    input_features = processor.feature_extractor(\n",
    "        audio_array,\n",
    "        sampling_rate=sr,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    # ì…ë ¥ íŠ¹ì„±ì„ ëª¨ë¸ê³¼ ë™ì¼í•œ ì¥ì¹˜ë¡œ ì´ë™\n",
    "    input_features = input_features.to(device)\n",
    "\n",
    "    # ìƒì„± ì˜µì…˜ ì„¤ì • (í•œêµ­ì–´ ê°•ì œ ì„¤ì •)\n",
    "    generation_kwargs = {}\n",
    "    \n",
    "    if forced_language:\n",
    "        # ê°•ì œ ì–¸ì–´ ì„¤ì •\n",
    "        forced_decoder_ids = processor.get_decoder_prompt_ids(language=forced_language, task=\"transcribe\")\n",
    "        generation_kwargs[\"forced_decoder_ids\"] = forced_decoder_ids\n",
    "        print(f\"ì–¸ì–´ë¥¼ {forced_language}ë¡œ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features, **generation_kwargs)\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "    transcription = processor.tokenizer.batch_decode(\n",
    "        predicted_ids, \n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def main():\n",
    "    print(\"=== example1.pcm íŒŒì¼ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ëª¨ë“œ) ===\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ê²½ë¡œ\n",
    "    test_file = \"example1.pcm\"  # ì´ë¯¸ ì°¾ì€ ê²½ë¡œ ì‚¬ìš©\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"ì˜¤ë¥˜: {test_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file}\")\n",
    "    \n",
    "    # CPU ì¥ì¹˜ ê°•ì œ ì„¤ì • (CUDA ë¬¸ì œ íšŒí”¼)\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"ì¥ì¹˜: {device} (ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ CPUë§Œ ì‚¬ìš©)\")\n",
    "    \n",
    "    # ê¸°ë³¸ Whisper ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"ê¸°ë³¸ Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "    \n",
    "    # ëª¨ë¸ ì¶”ë¡ \n",
    "    print(\"\\n----- ì–¸ì–´ ìë™ ê°ì§€ ëª¨ë“œ -----\")\n",
    "    print(\"ìŒì„± ì¸ì‹ ì¤‘...\")\n",
    "    try:\n",
    "        auto_transcription = transcribe_audio(model, processor, test_file, device)\n",
    "        print(\"\\n=== ìë™ ì–¸ì–´ ê°ì§€ ê²°ê³¼ ===\")\n",
    "        print(auto_transcription)\n",
    "    except Exception as e:\n",
    "        print(f\"ìë™ ì–¸ì–´ ëª¨ë“œ ì˜¤ë¥˜: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n----- í•œêµ­ì–´ ê°•ì œ ëª¨ë“œ -----\")\n",
    "    print(\"ìŒì„± ì¸ì‹ ì¤‘...\")\n",
    "    try:\n",
    "        # ì–¸ì–´ë¥¼ í•œêµ­ì–´(ko)ë¡œ ê°•ì œ ì§€ì •\n",
    "        korean_transcription = transcribe_audio(model, processor, test_file, device, forced_language=\"ko\")\n",
    "        print(\"\\n=== í•œêµ­ì–´ ê°•ì œ ëª¨ë“œ ê²°ê³¼ ===\")\n",
    "        print(korean_transcription)\n",
    "    except Exception as e:\n",
    "        print(f\"í•œêµ­ì–´ ê°•ì œ ëª¨ë“œ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9380691-9570-43bf-8e7b-34062db5757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper_finetuned ë‚´ìš©:\n",
      "  example1.pcm\n",
      "  preprocessor_config.json\n",
      "  checkpoint-2000\n",
      "  whisper_finetuned\n",
      "  checkpoint-3500\n",
      "  tokenizer_config.json\n",
      "  training_args.bin\n",
      "  model.safetensors\n",
      "  merges.txt\n",
      "  checkpoint-3000\n",
      "  .ipynb_checkpoints\n",
      "  checkpoint-500\n",
      "  added_tokens.json\n",
      "  checkpoint-1000\n",
      "  special_tokens_map.json\n",
      "  checkpoint-1500\n",
      "  saved_whisper_model.pt\n",
      "  KsponSpeech_128001.pcm\n",
      "  runs\n",
      "  config.json\n",
      "  normalizer.json\n",
      "  checkpoint-2500\n",
      "  vocab.json\n",
      "  generation_config.json\n",
      "  checkpoint-4000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"whisper_finetuned ë‚´ìš©:\")\n",
    "for file in os.listdir(\"whisper_finetuned\"):\n",
    "    print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eff679-3150-4ac3-ad2a-85f181a76c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-27 15:15:46.117660: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-27 15:15:46.165587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-27 15:15:46.959438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°œìŒ ê¸°ì¤€ Whisper íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "ì´ 12714ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : íŒŒì¼ ìˆ˜ ë¶ˆì¼ì¹˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12713/12713 [00:05<00:00, 2169.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í† í¬ë‚˜ì´ì € ì–´íœ˜ í™•ì¥ ì¤‘...\n",
      "ê¸°ì¡´ ì–´íœ˜ í¬ê¸°: 51865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10170/10170 [35:41<00:00,  4.75 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [04:29<00:00,  4.73 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1271/1271 [04:27<00:00,  4.75 examples/s]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ëŠ¥ë ¥: (8, 6), BF16 ì§€ì›: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29713/3254085371.py:300: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°œìŒ ê¸°ì¤€ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 7:16:52, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.331400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>7.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>5.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>4.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>4.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>4.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>4.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>4.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>3.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>3.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>3.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.373400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>3.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>3.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>3.310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>3.250700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>3.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.238200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>3.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>3.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>3.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>3.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>3.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.232400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>3.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>3.208300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>3.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>3.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>3.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>3.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>3.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>3.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>3.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>3.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>3.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>3.120200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>3.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>3.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>3.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>3.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.999100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.937900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>2.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>2.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.889100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>2.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>2.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>2.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>2.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>2.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>2.917800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>2.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>2.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>2.879600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>2.869500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>2.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>2.766500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>2.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.792700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>2.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>2.876300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>2.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.804600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>2.840900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>2.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.771900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>2.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>2.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>2.825700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>2.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>2.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>2.856600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.849500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>2.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>2.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>2.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>2.740400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.719200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>2.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>2.659100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>2.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>2.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>2.797900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>2.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>2.720700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>2.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>2.747900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>2.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>2.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.699400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>2.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.735600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>2.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.764900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>2.653200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>2.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>2.621400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.622600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>2.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>2.639700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>2.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4025</td>\n",
       "      <td>2.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>2.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4075</td>\n",
       "      <td>2.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4125</td>\n",
       "      <td>2.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>2.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4175</td>\n",
       "      <td>2.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4225</td>\n",
       "      <td>2.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>2.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4275</td>\n",
       "      <td>2.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4325</td>\n",
       "      <td>2.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>2.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4375</td>\n",
       "      <td>2.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.662900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4425</td>\n",
       "      <td>2.619200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>2.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4475</td>\n",
       "      <td>2.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4525</td>\n",
       "      <td>2.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>2.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4575</td>\n",
       "      <td>2.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>2.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>2.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4675</td>\n",
       "      <td>2.576100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>2.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4725</td>\n",
       "      <td>2.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>2.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4775</td>\n",
       "      <td>2.583400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>2.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>2.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4875</td>\n",
       "      <td>2.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>2.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4925</td>\n",
       "      <td>2.554300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>2.530300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4975</td>\n",
       "      <td>2.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>2.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>2.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5075</td>\n",
       "      <td>2.566600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>2.589100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5125</td>\n",
       "      <td>2.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>2.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5175</td>\n",
       "      <td>2.570800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5225</td>\n",
       "      <td>2.465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>2.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5275</td>\n",
       "      <td>2.472300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>2.494800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5325</td>\n",
       "      <td>2.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>2.494800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5375</td>\n",
       "      <td>2.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5425</td>\n",
       "      <td>2.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>2.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5475</td>\n",
       "      <td>2.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5525</td>\n",
       "      <td>2.529300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>2.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5575</td>\n",
       "      <td>2.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5625</td>\n",
       "      <td>2.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>2.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5675</td>\n",
       "      <td>2.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>2.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5725</td>\n",
       "      <td>2.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>2.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5775</td>\n",
       "      <td>2.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5825</td>\n",
       "      <td>2.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>2.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5875</td>\n",
       "      <td>2.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>2.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5925</td>\n",
       "      <td>2.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>2.485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5975</td>\n",
       "      <td>2.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.471500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\n",
      "ë°œìŒ ê¸°ì¤€ ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0001\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0002\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0003\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 1900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0004\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 2900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0005\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 3900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0006\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0007\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 4900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0008\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 5900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0009\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 6900\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0010\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0011\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 7900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0012\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 8900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0013\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 9900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10200\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10300\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0014\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 10900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11100\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0015\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0016\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0017\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11700\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11800\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 11900\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12000\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12100\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12200\n",
      "í´ë” ê²€ìƒ‰ ì¤‘: PreprocessData/KsponSpeech_01/KsponSpeech_0018\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12300\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12400\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12500\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12600\n",
      "ì°¾ì€ íŒŒì¼ ìˆ˜: 12700\n",
      "ì´ 12714ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: PreprocessData/KsponSpeech_01/KsponSpeech_0018_g2p/KsponSpeech_017485.txt\n",
      "ì´ 12713ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\n",
      "ë°œìŒ ê¸°ì¤€ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import json\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def load_text(file_path):\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                text = f.read().strip()\n",
    "            return text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return \"í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "def get_file_paths_npy(base_directory):\n",
    "    npy_files = []\n",
    "    base_folders = []\n",
    "    for i in range(1, 19):\n",
    "        if i > 9:\n",
    "            base_folders.append(f\"KsponSpeech_00{i}\")\n",
    "        else:\n",
    "            base_folders.append(f\"KsponSpeech_000{i}\")\n",
    "\n",
    "    for folder in base_folders:\n",
    "        folder_path = os.path.join(base_directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}\")\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('_combined_features.npy'):\n",
    "                        npy_path = os.path.join(root, file)\n",
    "                        npy_files.append(npy_path)\n",
    "                        if len(npy_files) % 100 == 0:\n",
    "                            print(f\"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(npy_files)}\")\n",
    "        else:\n",
    "            print(f\"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ NP íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return npy_files\n",
    "\n",
    "def get_file_paths_txt(npy_files):\n",
    "    txt_files = []\n",
    "    for npy_path in npy_files:\n",
    "        file_name = os.path.basename(npy_path).replace('_combined_features.npy', '')\n",
    "        dir_path = os.path.dirname(npy_path)\n",
    "        parent_dir = os.path.basename(dir_path)\n",
    "        g2p_dir = parent_dir + \"_g2p\"\n",
    "        g2p_dir_path = os.path.join(os.path.dirname(dir_path), g2p_dir)\n",
    "        txt_path = os.path.join(g2p_dir_path, file_name + \".txt\")\n",
    "        \n",
    "        if os.path.exists(txt_path):\n",
    "            txt_files.append(txt_path)\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {txt_path}\")\n",
    "    \n",
    "    print(f\"ì´ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return txt_files\n",
    "\n",
    "def create_dataset(npy_files, txt_files, max_samples=None):\n",
    "    data = {\"audio\": [], \"text\": []}\n",
    "    \n",
    "    if max_samples is not None:\n",
    "        npy_files = npy_files[:max_samples]\n",
    "        txt_files = txt_files[:max_samples]\n",
    "\n",
    "    for npy_file, txt_file in zip(npy_files, txt_files):\n",
    "        try:\n",
    "            if os.path.exists(npy_file) and os.path.exists(txt_file):\n",
    "                test_array = np.load(npy_file)\n",
    "                if len(test_array) > 0:\n",
    "                    data[\"audio\"].append(npy_file)\n",
    "                    # ë°œìŒ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥ (ì •ê·œí™” X)\n",
    "                    original_text = load_text(txt_file)\n",
    "                    data[\"text\"].append(original_text)\n",
    "                else:\n",
    "                    print(f\"ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼ ê±´ë„ˆëœ€: {npy_file}\")\n",
    "            else:\n",
    "                print(f\"íŒŒì¼ ì—†ìŒ: {npy_file} ë˜ëŠ” {txt_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {npy_file}, ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "def extend_tokenizer_vocabulary(processor, texts):\n",
    "    \"\"\"\n",
    "    ë°œìŒ ê¸°ì¤€ í…ìŠ¤íŠ¸ì— ë§ì¶° í† í¬ë‚˜ì´ì € ì–´íœ˜ í™•ì¥\n",
    "    \"\"\"\n",
    "    print(\"í† í¬ë‚˜ì´ì € ì–´íœ˜ í™•ì¥ ì¤‘...\")\n",
    "    \n",
    "    # ê¸°ì¡´ ì–´íœ˜ í¬ê¸°\n",
    "    original_vocab_size = len(processor.tokenizer)\n",
    "    print(f\"ê¸°ì¡´ ì–´íœ˜ í¬ê¸°: {original_vocab_size}\")\n",
    "    \n",
    "    # ë°œìŒ í…ìŠ¤íŠ¸ì—ì„œ ìƒˆë¡œìš´ í† í° ì¶”ì¶œ\n",
    "    new_tokens = set()\n",
    "    for text in texts[:1000]:  # ìƒ˜í”Œë§í•´ì„œ í™•ì¸\n",
    "        # ë°œìŒ ê¸°í˜¸ë“¤ ì¶”ì¶œ\n",
    "        if \"/\" in text:\n",
    "            new_tokens.update([\"/\"])\n",
    "        if \"+\" in text:\n",
    "            new_tokens.update([\"+\"])\n",
    "        # ê¸°íƒ€ íŠ¹ìˆ˜ ê¸°í˜¸ë“¤...\n",
    "    \n",
    "    # ìƒˆ í† í° ì¶”ê°€\n",
    "    new_tokens = list(new_tokens - set(processor.tokenizer.get_vocab().keys()))\n",
    "    if new_tokens:\n",
    "        print(f\"ìƒˆë¡œ ì¶”ê°€í•  í† í°: {new_tokens}\")\n",
    "        processor.tokenizer.add_tokens(new_tokens)\n",
    "        print(f\"í™•ì¥ëœ ì–´íœ˜ í¬ê¸°: {len(processor.tokenizer)}\")\n",
    "    \n",
    "    return processor\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: WhisperProcessor\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            {\"input_features\": [feature[\"input_features\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            {\"input_ids\": [feature[\"labels\"] for feature in features]},\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id,\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "def train_whisper_pronunciation_model():\n",
    "    base_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    output_dir = \"whisper_pronunciation_finetuned\"\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "    npy_files = get_file_paths_npy(base_directory)\n",
    "    \n",
    "    if len(npy_files) == 0:\n",
    "        print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None, None\n",
    "    \n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    print(f\"ì´ {len(npy_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ {len(txt_files)}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # íŒŒì¼ ìˆ˜ ë§ì¶”ê¸°\n",
    "    if len(npy_files) != len(txt_files):\n",
    "        print(f\"ê²½ê³ : íŒŒì¼ ìˆ˜ ë¶ˆì¼ì¹˜\")\n",
    "        min_len = min(len(npy_files), len(txt_files))\n",
    "        npy_files = npy_files[:min_len]\n",
    "        txt_files = txt_files[:min_len]\n",
    "    \n",
    "    dataset = create_dataset(npy_files, txt_files)\n",
    "\n",
    "    def map_to_array(batch):\n",
    "        arrays = []\n",
    "        rates = []\n",
    "\n",
    "        for audio_path in batch[\"audio\"]:\n",
    "            audio_array = np.load(audio_path)\n",
    "            if audio_array.dtype in [np.int16, np.int8]:\n",
    "                max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "                audio_array = audio_array.astype(np.float32) / max_value\n",
    "            elif audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            \n",
    "            sampling_rate = 16000\n",
    "            arrays.append(audio_array)\n",
    "            rates.append(sampling_rate)\n",
    "\n",
    "        batch[\"audio\"] = [{\"array\": arr, \"sampling_rate\": sr} for arr, sr in zip(arrays, rates)]\n",
    "        return batch\n",
    "\n",
    "    dataset = dataset.map(map_to_array, batched=True, batch_size=8)\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ë¶„í• \n",
    "    train_test_valid = dataset.train_test_split(test_size=0.2)\n",
    "    test_valid = train_test_valid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": train_test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"validation\": test_valid[\"train\"]\n",
    "    })\n",
    "\n",
    "    # ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\n",
    "        \"openai/whisper-small\", \n",
    "        use_cache=False,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "    \n",
    "    # ğŸ¯ í•µì‹¬: í† í¬ë‚˜ì´ì € ì–´íœ˜ í™•ì¥\n",
    "    all_texts = [item[\"text\"] for item in dataset]\n",
    "    processor = extend_tokenizer_vocabulary(processor, all_texts)\n",
    "    \n",
    "    # ëª¨ë¸ ì„ë² ë”© í¬ê¸° ì¡°ì • (ìƒˆ í† í° ì¶”ê°€ ì‹œ)\n",
    "    if len(processor.tokenizer) > model.config.vocab_size:\n",
    "        print(\"ëª¨ë¸ ì„ë² ë”© í¬ê¸° ì¡°ì • ì¤‘...\")\n",
    "        model.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        audio = batch[\"audio\"]\n",
    "        \n",
    "        input_features = processor.feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"]\n",
    "        ).input_features[0]\n",
    "        \n",
    "        if isinstance(input_features, np.ndarray):\n",
    "            input_features = torch.from_numpy(input_features)\n",
    "        \n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        # ğŸ¯ í•µì‹¬: ë°œìŒ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ í† í¬ë‚˜ì´ì§• (ì •ê·œí™” ì—†ìŒ)\n",
    "        labels = processor.tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=448,\n",
    "            padding=False\n",
    "        ).input_ids\n",
    "        \n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "    processed_datasets = DatasetDict({\n",
    "        split: dataset.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        for split, dataset in datasets.items()\n",
    "    })\n",
    "\n",
    "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "    # GPU ëŠ¥ë ¥ í™•ì¸\n",
    "    device_capability = torch.cuda.get_device_capability() if torch.cuda.is_available() else (0, 0)\n",
    "    supports_bf16 = device_capability >= (8, 0)\n",
    "    \n",
    "    print(f\"GPU ëŠ¥ë ¥: {device_capability}, BF16 ì§€ì›: {supports_bf16}\")\n",
    "    \n",
    "    # í›ˆë ¨ ì„¤ì •\n",
    "    if supports_bf16:\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=2,\n",
    "            learning_rate=5e-6,  # ë” ë‚®ì€ í•™ìŠµë¥  (ë°œìŒ í•™ìŠµìš©)\n",
    "            warmup_steps=500,\n",
    "            max_steps=6000,      # ë” ë§ì€ ìŠ¤í…\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=True,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "    else:\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=1,\n",
    "            gradient_accumulation_steps=4,\n",
    "            learning_rate=5e-6,\n",
    "            warmup_steps=500,\n",
    "            max_steps=6000,\n",
    "            gradient_checkpointing=True,\n",
    "            bf16=False,\n",
    "            fp16=False,\n",
    "            dataloader_pin_memory=False,\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_steps=500,\n",
    "            logging_steps=25,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=processor.tokenizer,\n",
    "    )\n",
    "\n",
    "    print(\"ë°œìŒ ê¸°ì¤€ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "\n",
    "    # í† í¬ë‚˜ì´ì € ì„¤ì •ë„ ë³„ë„ ì €ì¥\n",
    "    with open(os.path.join(output_dir, \"pronunciation_config.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            \"original_vocab_size\": model.config.vocab_size,\n",
    "            \"extended_vocab_size\": len(processor.tokenizer),\n",
    "            \"training_type\": \"pronunciation_based\"\n",
    "        }, f, indent=2)\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "# ğŸ¯ ë°œìŒ ê¸°ì¤€ ì¶”ë¡  í•¨ìˆ˜\n",
    "def transcribe_audio_pronunciation(model, processor, audio_file):\n",
    "    try:\n",
    "        audio_array = np.load(audio_file)\n",
    "        \n",
    "        if audio_array.dtype in [np.int16, np.int8]:\n",
    "            max_value = float(2 ** (15 if audio_array.dtype == np.int16 else 7))\n",
    "            audio_array = audio_array.astype(np.float32) / max_value\n",
    "        elif audio_array.dtype != np.float32:\n",
    "            audio_array = audio_array.astype(np.float32)\n",
    "        \n",
    "        sr = 16000\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        input_features = input_features.to(model.dtype)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "            model = model.cuda()\n",
    "\n",
    "        # ğŸ¯ ë°œìŒ ê¸°ì¤€ ìƒì„± (ìµœì†Œí•œì˜ ì œì•½)\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=448,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                # language, task íŒŒë¼ë¯¸í„° ì œê±° (ë°œìŒ ì¶œë ¥ ìœ ë„)\n",
    "            )\n",
    "\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ìŒì„± ì¸ì‹ ì‹¤íŒ¨\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ë°œìŒ ê¸°ì¤€ Whisper íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    model, processor = train_whisper_pronunciation_model()\n",
    "    \n",
    "    if model is None or processor is None:\n",
    "        print(\"ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "    \n",
    "    print(\"ë°œìŒ ê¸°ì¤€ ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸\n",
    "    test_directory = \"PreprocessData/KsponSpeech_01\"\n",
    "    npy_files = get_file_paths_npy(test_directory)\n",
    "    txt_files = get_file_paths_txt(npy_files)\n",
    "    \n",
    "    max_test_files = 5\n",
    "    test_npy_files = npy_files[:max_test_files]\n",
    "    test_txt_files = txt_files[:max_test_files]\n",
    "    \n",
    "    print(\"ë°œìŒ ê¸°ì¤€ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    for i in range(len(test_npy_files)):\n",
    "        test_audio = test_npy_files[i]\n",
    "        reference_text = load_text(test_txt_files[i])\n",
    "        \n",
    "        transcription = transcribe_audio_pronunciation(model, processor, test_audio)\n",
    "        \n",
    "        print(f\"íŒŒì¼: {os.path.basename(test_audio)}\")\n",
    "        print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {reference_text}\")\n",
    "        print(f\"ë°œìŒ ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f21d89-e83a-4bff-b07c-03e399fbe23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ PCM íŒŒì¼ ë°œìŒ ë³€í™˜ í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: whisper_pronunciation_finetuned\n",
      "ğŸ”¥ GPU ì‚¬ìš© ì¤‘\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: 000025.wav\n",
      "\n",
      "ğŸµ PCM íŒŒì¼ ì²˜ë¦¬ ì¤‘: 000025.wav\n",
      "   ğŸ“Š ì›ë³¸ PCM ë°ì´í„° ê¸¸ì´: 193515 ìƒ˜í”Œ\n",
      "   ğŸ“Š ì›ë³¸ ë°ì´í„° ë²”ìœ„: [-7886, 32000]\n",
      "   ğŸ“Š ì •ê·œí™” í›„ ë²”ìœ„: [-0.246, 1.000]\n",
      "   ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: 12.09ì´ˆ\n",
      "   ğŸ“Š ì…ë ¥ íŠ¹ì§• í¬ê¸°: torch.Size([1, 80, 3000])\n",
      "   ğŸ¤– ë°œìŒ ë³€í™˜ ê²°ê³¼:  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¤ë§¨ë“¤ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¤ë§¨ë“¤ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¨ë“¤ í•˜ì£ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë§¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ï¿½\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ PCM -> ë°œìŒ ë³€í™˜ ì„±ê³µ!\n",
      "ğŸ“ ìµœì¢… ê²°ê³¼:  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë‚  ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¤ë§¨ë“¤ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¤ë§¨ë“¤ í•˜ì£ . ê·¸ë˜ì„œ ë¶€ëª¨í•œí…Œ ë§¨ë“¤ ì‘¨ë“¤ í•˜ì£ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë§¨ï¿½ë¼ê³ . ë¶€ëª¨ë‹ˆê¹¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ë§¨ï¿½ï¿½\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "def load_trained_model(model_path=\"whisper_pronunciation_finetuned\"):\n",
    "    \"\"\"ì €ì¥ëœ ë°œìŒ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "    print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "        processor = WhisperProcessor.from_pretrained(model_path)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            print(\"ğŸ”¥ GPU ì‚¬ìš© ì¤‘\")\n",
    "        else:\n",
    "            print(\"ğŸ’» CPU ì‚¬ìš© ì¤‘\")\n",
    "            \n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        return model, processor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def transcribe_real_audio(model, processor, audio_file_path):\n",
    "    \"\"\"ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼(.wav, .mp3 ë“±)ì„ ë°œìŒìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    print(f\"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {os.path.basename(audio_file_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ (Whisperê°€ í•˜ëŠ” ë°©ì‹ ê·¸ëŒ€ë¡œ)\n",
    "        audio, sr = librosa.load(audio_file_path, sr=16000)  # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§\n",
    "        print(f\"   ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {len(audio)/sr:.2f}ì´ˆ\")\n",
    "        print(f\"   ğŸ“Š ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr}Hz\")\n",
    "        print(f\"   ğŸ“Š ì˜¤ë””ì˜¤ ë²”ìœ„: [{audio.min():.3f}, {audio.max():.3f}]\")\n",
    "        \n",
    "        # 2. Whisper íŠ¹ì§• ì¶”ì¶œ (ì¼ë°˜ ì¶”ë¡ ê³¼ ë™ì¼)\n",
    "        input_features = processor(\n",
    "            audio, \n",
    "            sampling_rate=sr, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        print(f\"   ğŸ“Š ì…ë ¥ íŠ¹ì§• í¬ê¸°: {input_features.shape}\")\n",
    "        \n",
    "        # 3. GPUë¡œ ì´ë™\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "        \n",
    "        # 4. ë°œìŒ ê¸°ì¤€ ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=448,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                # language=\"ko\"  # í•„ìš”ì‹œ ì¶”ê°€\n",
    "            )\n",
    "        \n",
    "        # 5. í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids, \n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        print(f\"   ğŸ¤– ë°œìŒ ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_with_sample_audio():\n",
    "    \"\"\"ìƒ˜í”Œ ì˜¤ë””ì˜¤ë¡œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¯ ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ -> ë°œìŒ ë³€í™˜ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_trained_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ ì°¾ê¸°\n",
    "    audio_extensions = ['.wav', '.mp3', '.flac', '.m4a']\n",
    "    test_files = []\n",
    "    \n",
    "    # í˜„ì¬ ë””ë ‰í† ë¦¬ì™€ í•˜ìœ„ í´ë”ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in audio_extensions):\n",
    "                audio_path = os.path.join(root, file)\n",
    "                test_files.append(audio_path)\n",
    "                if len(test_files) >= 5:  # ìµœëŒ€ 5ê°œ\n",
    "                    break\n",
    "        if len(test_files) >= 5:\n",
    "            break\n",
    "    \n",
    "    if not test_files:\n",
    "        print(\"âŒ í…ŒìŠ¤íŠ¸í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ë‹¤ìŒ í˜•ì‹ì˜ íŒŒì¼ì„ í˜„ì¬ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”: .wav, .mp3, .flac, .m4a\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŒì„± ìƒì„± (ì„ íƒì‚¬í•­)\n",
    "        create_test_audio = input(\"í…ŒìŠ¤íŠ¸ìš© ìŒì„± íŒŒì¼ì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "        if create_test_audio.lower() == 'y':\n",
    "            create_sample_audio()\n",
    "            return\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    print(f\"ğŸ“ {len(test_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ë°œê²¬\")\n",
    "    print()\n",
    "    \n",
    "    # ê° íŒŒì¼ì— ëŒ€í•´ ì¶”ë¡  ì‹¤í–‰\n",
    "    for i, audio_file in enumerate(test_files, 1):\n",
    "        print(f\"ğŸ” í…ŒìŠ¤íŠ¸ {i}/{len(test_files)}\")\n",
    "        result = transcribe_real_audio(model, processor, audio_file)\n",
    "        \n",
    "        if result:\n",
    "            print(\"   âœ… ì„±ê³µ!\")\n",
    "        else:\n",
    "            print(\"   âŒ ì‹¤íŒ¨!\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def create_sample_audio():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì˜¤ë””ì˜¤ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        import numpy as np\n",
    "        \n",
    "        print(\"ğŸ”Š í…ŒìŠ¤íŠ¸ìš© ìŒì„± íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ì‚¬ì¸íŒŒ ìƒì„± (440Hz, 2ì´ˆ)\n",
    "        sr = 16000\n",
    "        duration = 2.0\n",
    "        t = np.linspace(0, duration, int(sr * duration))\n",
    "        \n",
    "        # 440Hz í†¤ (A4 ìŒ)\n",
    "        audio = 0.3 * np.sin(2 * np.pi * 440 * t)\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        output_file = \"test_audio.wav\"\n",
    "        sf.write(output_file, audio, sr)\n",
    "        \n",
    "        print(f\"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}\")\n",
    "        print(\"ì´ì œ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âŒ soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install soundfile\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def test_single_file():\n",
    "    \"\"\"ë‹¨ì¼ íŒŒì¼ ì§ì ‘ ì§€ì •í•´ì„œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‚ ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸\")\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ì§ì ‘ ì…ë ¥\n",
    "    audio_file = input(\"ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "    \n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {audio_file}\")\n",
    "        return\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_trained_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # ì¶”ë¡  ì‹¤í–‰\n",
    "    print()\n",
    "    result = transcribe_real_audio(model, processor, audio_file)\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\nğŸ‰ ì¶”ë¡  ì„±ê³µ!\")\n",
    "        print(f\"ê²°ê³¼: {result}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ì¶”ë¡  ì‹¤íŒ¨!\")\n",
    "\n",
    "def load_pcm_file(pcm_file_path, sample_rate=16000):\n",
    "    \"\"\"PCM íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ numpy ë°°ì—´ë¡œ ë³€í™˜ (ì‚¬ìš©ì ì „ì²˜ë¦¬ ë°©ì‹ ì ìš©)\"\"\"\n",
    "    try:\n",
    "        # PCM íŒŒì¼ì„ 16ë¹„íŠ¸ ì •ìˆ˜ë¡œ ì½ê¸°\n",
    "        with open(pcm_file_path, 'rb') as f:\n",
    "            pcm_data = f.read()\n",
    "        \n",
    "        # bytesë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (16ë¹„íŠ¸ ì •ìˆ˜ ê°€ì •)\n",
    "        np_pcm = np.frombuffer(pcm_data, dtype=np.int16)\n",
    "        \n",
    "        print(f\"   ğŸ“Š ì›ë³¸ PCM ë°ì´í„° ê¸¸ì´: {len(np_pcm)} ìƒ˜í”Œ\")\n",
    "        print(f\"   ğŸ“Š ì›ë³¸ ë°ì´í„° ë²”ìœ„: [{np_pcm.min()}, {np_pcm.max()}]\")\n",
    "        \n",
    "        # ğŸ¯ ì‚¬ìš©ì ì „ì²˜ë¦¬ ë°©ì‹ ì ìš©\n",
    "        normalized = np_pcm / np.max(np.abs(np_pcm))\n",
    "        \n",
    "        print(f\"   ğŸ“Š ì •ê·œí™” í›„ ë²”ìœ„: [{normalized.min():.3f}, {normalized.max():.3f}]\")\n",
    "        print(f\"   ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {len(normalized)/sample_rate:.2f}ì´ˆ\")\n",
    "        \n",
    "        return normalized.astype(np.float32)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PCM íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_pcm_file(model, processor, pcm_file_path):\n",
    "    \"\"\"PCM íŒŒì¼ì„ ë°œìŒìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    print(f\"ğŸµ PCM íŒŒì¼ ì²˜ë¦¬ ì¤‘: {os.path.basename(pcm_file_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. PCM íŒŒì¼ ë¡œë“œ\n",
    "        audio = load_pcm_file(pcm_file_path)\n",
    "        if audio is None:\n",
    "            return None\n",
    "        \n",
    "        # 2. Whisper íŠ¹ì§• ì¶”ì¶œ\n",
    "        input_features = processor(\n",
    "            audio, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        print(f\"   ğŸ“Š ì…ë ¥ íŠ¹ì§• í¬ê¸°: {input_features.shape}\")\n",
    "        \n",
    "        # 3. GPUë¡œ ì´ë™\n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "        \n",
    "        # 4. ë°œìŒ ê¸°ì¤€ ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=448,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "            )\n",
    "        \n",
    "        # 5. í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
    "        transcription = processor.tokenizer.batch_decode(\n",
    "            predicted_ids, \n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        print(f\"   ğŸ¤– ë°œìŒ ë³€í™˜ ê²°ê³¼: {transcription}\")\n",
    "        return transcription\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ í•¨ìˆ˜ - example_data.pcm íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤ PCM íŒŒì¼ ë°œìŒ ë³€í™˜ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # PCM íŒŒì¼ ê²½ë¡œ\n",
    "    pcm_file = \"000025.wav\"\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(pcm_file):\n",
    "        print(f\"âŒ PCM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pcm_file}\")\n",
    "        print(\"example_data.pcm íŒŒì¼ì„ í˜„ì¬ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”!\")\n",
    "        return\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_trained_model()\n",
    "    if model is None:\n",
    "        print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {pcm_file}\")\n",
    "    print()\n",
    "    \n",
    "    # PCM íŒŒì¼ ì¶”ë¡  ì‹¤í–‰\n",
    "    result = transcribe_pcm_file(model, processor, pcm_file)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    if result:\n",
    "        print(\"ğŸ‰ PCM -> ë°œìŒ ë³€í™˜ ì„±ê³µ!\")\n",
    "        print(f\"ğŸ“ ìµœì¢… ê²°ê³¼: {result}\")\n",
    "    else:\n",
    "        print(\"âŒ PCM -> ë°œìŒ ë³€í™˜ ì‹¤íŒ¨!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a02ddb-31bc-459c-9e21-2b4e5d4e50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Whisper ëª¨ë¸ .pt ë³€í™˜ ë„êµ¬\n",
      "================================================================================\n",
      "ğŸ”„ Transformers ëª¨ë¸ì„ .pt íŒŒì¼ë¡œ ë³€í™˜\n",
      "============================================================\n",
      "ğŸ“‹ í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸:\n",
      "   âœ… config.json\n",
      "   âœ… model.safetensors\n",
      "\n",
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸ“Š ëª¨ë¸ ì •ë³´:\n",
      "   - ëª¨ë¸ íƒ€ì…: WhisperForConditionalGeneration\n",
      "   - ì–´íœ˜ í¬ê¸°: 51865\n",
      "   - ëª¨ë¸ í¬ê¸°: 241,734,912 parameters\n",
      "\n",
      "ğŸ’¾ .pt íŒŒì¼ë¡œ ì €ì¥ ì¤‘: whisper_pronunciation_model.pt\n",
      "âœ… ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“Š íŒŒì¼ í¬ê¸°: 926.0 MB\n",
      "\n",
      "ğŸ” ì €ì¥ëœ íŒŒì¼ ê²€ì¦ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29713/3837886129.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(output_pt_file, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²€ì¦ ì™„ë£Œ! í¬í•¨ëœ ë°ì´í„°:\n",
      "   - model_state_dict\n",
      "   - model_config\n",
      "   - tokenizer\n",
      "   - feature_extractor\n",
      "   - processor_config\n",
      "   - training_info\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª ë³€í™˜ëœ .pt ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "ğŸ”„ .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë”©: whisper_pronunciation_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29713/3837886129.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pt_file_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸ”¥ GPUë¡œ ëª¨ë¸ ì´ë™ ì™„ë£Œ\n",
      "ğŸ” ë”ë¯¸ ë°ì´í„°ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸...\n",
      "âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ!\n",
      "ğŸ“ ë”ë¯¸ ê²°ê³¼:  (static)\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³€í™˜ ì™„ë£Œ!\n",
      "ğŸ“ ì‚¬ìš©í•  íŒŒì¼: whisper_pronunciation_model.pt\n",
      "ğŸ’¡ ì´ì œ ë¡œì»¬ì—ì„œ ì´ .pt íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "def convert_transformers_to_pt():\n",
    "    \"\"\"Transformers ëª¨ë¸ì„ .pt íŒŒì¼ë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ Transformers ëª¨ë¸ì„ .pt íŒŒì¼ë¡œ ë³€í™˜\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì…ë ¥ í´ë” (Transformers ëª¨ë¸ì´ ì €ì¥ëœ ê³³)\n",
    "    input_model_path = \"whisper_pronunciation_finetuned\"\n",
    "    \n",
    "    # ì¶œë ¥ íŒŒì¼ëª…\n",
    "    output_pt_file = \"whisper_pronunciation_model.pt\"\n",
    "    \n",
    "    # ëª¨ë¸ í´ë” í™•ì¸\n",
    "    if not os.path.exists(input_model_path):\n",
    "        print(f\"âŒ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_model_path}\")\n",
    "        return\n",
    "    \n",
    "    # í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸\n",
    "    required_files = [\"config.json\"]\n",
    "    model_file = None\n",
    "    \n",
    "    # ëª¨ë¸ íŒŒì¼ ì°¾ê¸° (safetensors ë˜ëŠ” bin)\n",
    "    if os.path.exists(os.path.join(input_model_path, \"model.safetensors\")):\n",
    "        model_file = \"model.safetensors\"\n",
    "    elif os.path.exists(os.path.join(input_model_path, \"pytorch_model.bin\")):\n",
    "        model_file = \"pytorch_model.bin\"\n",
    "    \n",
    "    if model_file:\n",
    "        required_files.append(model_file)\n",
    "    \n",
    "    print(f\"ğŸ“‹ í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸:\")\n",
    "    for file in required_files:\n",
    "        file_path = os.path.join(input_model_path, file)\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"   âœ… {file}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {file} - ì—†ìŒ\")\n",
    "            return\n",
    "    \n",
    "    try:\n",
    "        # 1. ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "        print(\"\\nğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(input_model_path)\n",
    "        processor = WhisperProcessor.from_pretrained(input_model_path)\n",
    "        \n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        \n",
    "        # 2. ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "        print(f\"   - ëª¨ë¸ íƒ€ì…: {type(model).__name__}\")\n",
    "        print(f\"   - ì–´íœ˜ í¬ê¸°: {len(processor.tokenizer)}\")\n",
    "        print(f\"   - ëª¨ë¸ í¬ê¸°: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "        \n",
    "        # 3. .pt íŒŒì¼ë¡œ ì €ì¥í•  ë°ì´í„° ì¤€ë¹„\n",
    "        save_data = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_config': model.config.to_dict(),\n",
    "            'tokenizer': processor.tokenizer,\n",
    "            'feature_extractor': processor.feature_extractor,\n",
    "            'processor_config': {\n",
    "                'tokenizer_class': processor.tokenizer.__class__.__name__,\n",
    "                'feature_extractor_class': processor.feature_extractor.__class__.__name__,\n",
    "            },\n",
    "            'training_info': {\n",
    "                'model_type': 'whisper_pronunciation_finetuned',\n",
    "                'base_model': 'openai/whisper-small',\n",
    "                'task': 'pronunciation_transcription'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 4. .pt íŒŒì¼ë¡œ ì €ì¥\n",
    "        print(f\"\\nğŸ’¾ .pt íŒŒì¼ë¡œ ì €ì¥ ì¤‘: {output_pt_file}\")\n",
    "        torch.save(save_data, output_pt_file)\n",
    "        \n",
    "        # 5. ì €ì¥ëœ íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "        file_size = os.path.getsize(output_pt_file) / (1024 * 1024)  # MB\n",
    "        print(f\"âœ… ì €ì¥ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "        \n",
    "        # 6. ê²€ì¦ì„ ìœ„í•œ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "        print(f\"\\nğŸ” ì €ì¥ëœ íŒŒì¼ ê²€ì¦ ì¤‘...\")\n",
    "        loaded_data = torch.load(output_pt_file, map_location='cpu')\n",
    "        \n",
    "        print(\"âœ… ê²€ì¦ ì™„ë£Œ! í¬í•¨ëœ ë°ì´í„°:\")\n",
    "        for key in loaded_data.keys():\n",
    "            print(f\"   - {key}\")\n",
    "        \n",
    "        return output_pt_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_pt_model(pt_file_path):\n",
    "    \"\"\"ì €ì¥ëœ .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ”„ .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë”©: {pt_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # .pt íŒŒì¼ ë¡œë“œ\n",
    "        checkpoint = torch.load(pt_file_path, map_location='cpu')\n",
    "        \n",
    "        # ëª¨ë¸ ìƒì„±\n",
    "        from transformers import WhisperConfig\n",
    "        config = WhisperConfig.from_dict(checkpoint['model_config'])\n",
    "        model = WhisperForConditionalGeneration(config)\n",
    "        \n",
    "        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # í”„ë¡œì„¸ì„œ ë³µì›\n",
    "        tokenizer = checkpoint['tokenizer']\n",
    "        feature_extractor = checkpoint['feature_extractor']\n",
    "        processor = WhisperProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "        \n",
    "        print(\"âœ… .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        \n",
    "        return model, processor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ .pt íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def test_pt_model():\n",
    "    \"\"\"ë³€í™˜ëœ .pt ëª¨ë¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª ë³€í™˜ëœ .pt ëª¨ë¸ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pt_file = \"whisper_pronunciation_model.pt\"\n",
    "    \n",
    "    if not os.path.exists(pt_file):\n",
    "        print(f\"âŒ .pt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pt_file}\")\n",
    "        return\n",
    "    \n",
    "    # .pt íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_pt_model(pt_file)\n",
    "    \n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì´ë™\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"ğŸ”¥ GPUë¡œ ëª¨ë¸ ì´ë™ ì™„ë£Œ\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)\n",
    "    print(\"ğŸ” ë”ë¯¸ ë°ì´í„°ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸...\")\n",
    "    \n",
    "    try:\n",
    "        # ë”ë¯¸ ì˜¤ë””ì˜¤ ì…ë ¥ ìƒì„±\n",
    "        import numpy as np\n",
    "        dummy_audio = np.random.randn(16000).astype(np.float32)  # 1ì´ˆ ë”ë¯¸ ì˜¤ë””ì˜¤\n",
    "        \n",
    "        # íŠ¹ì§• ì¶”ì¶œ\n",
    "        input_features = processor(\n",
    "            dummy_audio,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "        \n",
    "        # ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_features,\n",
    "                max_length=50,\n",
    "                num_beams=1,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        result = processor.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        print(f\"âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "        print(f\"ğŸ“ ë”ë¯¸ ê²°ê³¼: {result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ Whisper ëª¨ë¸ .pt ë³€í™˜ ë„êµ¬\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. Transformers ëª¨ë¸ì„ .ptë¡œ ë³€í™˜\n",
    "    pt_file = convert_transformers_to_pt()\n",
    "    \n",
    "    if pt_file:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        # 2. ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "        test_pt_model()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ‰ ë³€í™˜ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“ ì‚¬ìš©í•  íŒŒì¼: {pt_file}\")\n",
    "        print(\"ğŸ’¡ ì´ì œ ë¡œì»¬ì—ì„œ ì´ .pt íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”!\")\n",
    "    else:\n",
    "        print(\"âŒ ë³€í™˜ ì‹¤íŒ¨!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b8c581-276b-4292-a155-8b468a94f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ë””ì½”ë”© íŒŒë¼ë¯¸í„° ìµœì í™” í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: whisper_pronunciation_finetuned\n",
      "ğŸ”¥ GPU ì‚¬ìš© ì¤‘\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸµ PCM íŒŒì¼ ì²˜ë¦¬ ì¤‘: 000025.wav\n",
      "   ğŸ“Š PCM ë°ì´í„° ê¸¸ì´: 193515 ìƒ˜í”Œ\n",
      "   ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: 12.09ì´ˆ\n",
      "   ğŸ“Š ì˜¤ë””ì˜¤ ë²”ìœ„: [-0.246, 1.000]\n",
      "\n",
      "ğŸ§ª ë‹¤ì–‘í•œ ë””ì½”ë”© ì „ëµ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ ë°˜ë³µ ë°©ì§€ ê°•í™”\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼ (ê¸¸ì´: 166):\n",
      "    ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ê·¸ ì•„ë“¤ê»˜ì„œ ë§‰ ë„ëŸ¬ì§€ë©´ì„œ ì•„ì˜ˆ í•™ê½ˆë¥¼ í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ë¹„í–‰ê¸°êµ¬ê°€ ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ì¢€ ë” ì¡°ì•„í•˜ëŠ” ê±´ì§€ ëª¨ë¥´ê²“ë– ë¼ê³  ìƒë‹™ë‹ˆë‹¤ë¼ê³  í•˜ë”ë¼ê³  í•´ì„œ ê·¸ë•Œ í•œ ë²ˆì¯”ë©” ì•ˆ í•¸ëŠ”ë°\n",
      "ğŸ” ë¶„ì„:\n",
      "   - ë°˜ë³µ íŒ¨í„´: âœ… ì—†ìŒ\n",
      "   - ê¹¨ì§„ ë¬¸ì: âœ… ì—†ìŒ\n",
      "\n",
      "2ï¸âƒ£ ë¹” ì„œì¹˜ + ë°˜ë³µ ë°©ì§€\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼ (ê¸¸ì´: 60):\n",
      "    ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ .\n",
      "ğŸ” ë¶„ì„:\n",
      "   - ë°˜ë³µ íŒ¨í„´: âœ… ì—†ìŒ\n",
      "   - ê¹¨ì§„ ë¬¸ì: âœ… ì—†ìŒ\n",
      "\n",
      "3ï¸âƒ£ ìƒ˜í”Œë§ ê¸°ë°˜\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼ (ê¸¸ì´: 61):\n",
      "    ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê²Œì´ë¸”ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ëŒ€ë¥¼ ì­‰ í‚¤ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ë§¤ë„¤ ì• ì°©ì„ í•˜ì§€ìš”?\n",
      "ğŸ” ë¶„ì„:\n",
      "   - ë°˜ë³µ íŒ¨í„´: âœ… ì—†ìŒ\n",
      "   - ê¹¨ì§„ ë¬¸ì: âœ… ì—†ìŒ\n",
      "\n",
      "4ï¸âƒ£ ë³´ìˆ˜ì  ì„¤ì •\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼ (ê¸¸ì´: 154):\n",
      "    ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ê·¸ ì•„ë“¤ê»˜ì„œ ë§‰ ë„ëŸ¬ì§€ë©´ì„œ ì•„ì˜ˆ í•™ê½ˆë¥¼ í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ë¹„í–‰ê¸°êµ¬ê°€ ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ì¢€ ë” ì¡°ì•„í•˜ëŠ” ê±´ì§€ ëª¨ë¥´ê²“ë– ë¼ê³  ìƒë‹™ë‹ˆë‹¤ë¼ê³  í•˜ë”ë¼ê³  í•´ì„œ ê·¸ë•Œ\n",
      "ğŸ” ë¶„ì„:\n",
      "   - ë°˜ë³µ íŒ¨í„´: âœ… ì—†ìŒ\n",
      "   - ê¹¨ì§„ ë¬¸ì: âœ… ì—†ìŒ\n",
      "\n",
      "5ï¸âƒ£ ê¸¸ì´ ì œí•œ + ì¡°ê¸° ì¢…ë£Œ\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼ (ê¸¸ì´: 60):\n",
      "    ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ .\n",
      "ğŸ” ë¶„ì„:\n",
      "   - ë°˜ë³µ íŒ¨í„´: âœ… ì—†ìŒ\n",
      "   - ê¹¨ì§„ ë¬¸ì: âœ… ì—†ìŒ\n",
      "\n",
      "ğŸ† ìµœì  ê²°ê³¼ ì„ ì •\n",
      "================================================================================\n",
      "ğŸ“Š ê²°ê³¼ ìˆœìœ„:\n",
      "   1. 1ï¸âƒ£ ë°˜ë³µ ë°©ì§€ ê°•í™” (ì ìˆ˜: 0)\n",
      "      ğŸ“  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ê·¸ ì•„ë“¤ê»˜ì„œ ë§‰ ë„ëŸ¬ì§€ë©´ì„œ ì•„ì˜ˆ í•™ê½ˆë¥¼ í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ...\n",
      "\n",
      "   2. 2ï¸âƒ£ ë¹” ì„œì¹˜ + ë°˜ë³µ ë°©ì§€ (ì ìˆ˜: 0)\n",
      "      ğŸ“  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ ....\n",
      "\n",
      "   3. 3ï¸âƒ£ ìƒ˜í”Œë§ ê¸°ë°˜ (ì ìˆ˜: 0)\n",
      "      ğŸ“  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê²Œì´ë¸”ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ëŒ€ë¥¼ ì­‰ í‚¤ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ë§¤ë„¤ ì• ì°©ì„ í•˜ì§€ìš”?...\n",
      "\n",
      "ğŸ¥‡ ìµœê³  ê²°ê³¼: 1ï¸âƒ£ ë°˜ë³µ ë°©ì§€ ê°•í™”\n",
      "ğŸ“ ì „ì²´ ê²°ê³¼:  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ê·¸ ì•„ë“¤ê»˜ì„œ ë§‰ ë„ëŸ¬ì§€ë©´ì„œ ì•„ì˜ˆ í•™ê½ˆë¥¼ í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ë¹„í–‰ê¸°êµ¬ê°€ ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ì¢€ ë” ì¡°ì•„í•˜ëŠ” ê±´ì§€ ëª¨ë¥´ê²“ë– ë¼ê³  ìƒë‹™ë‹ˆë‹¤ë¼ê³  í•˜ë”ë¼ê³  í•´ì„œ ê·¸ë•Œ í•œ ë²ˆì¯”ë©” ì•ˆ í•¸ëŠ”ë°\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ìµœì  ë””ì½”ë”© ì„¤ì •ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ğŸ’¡ ì´ ì„¤ì •ì„ ì‹¤ì œ ì¶”ë¡ ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "def load_trained_model(model_path=\"whisper_pronunciation_finetuned\"):\n",
    "    \"\"\"ì €ì¥ëœ ë°œìŒ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "    print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "        processor = WhisperProcessor.from_pretrained(model_path)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            print(\"ğŸ”¥ GPU ì‚¬ìš© ì¤‘\")\n",
    "        else:\n",
    "            print(\"ğŸ’» CPU ì‚¬ìš© ì¤‘\")\n",
    "            \n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        return model, processor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_pcm_file(pcm_file_path, sample_rate=16000):\n",
    "    \"\"\"PCM íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ numpy ë°°ì—´ë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        with open(pcm_file_path, 'rb') as f:\n",
    "            pcm_data = f.read()\n",
    "        \n",
    "        np_pcm = np.frombuffer(pcm_data, dtype=np.int16)\n",
    "        \n",
    "        # ì‚¬ìš©ì ì „ì²˜ë¦¬ ë°©ì‹ ì ìš©\n",
    "        normalized = np_pcm / np.max(np.abs(np_pcm))\n",
    "        \n",
    "        print(f\"   ğŸ“Š PCM ë°ì´í„° ê¸¸ì´: {len(normalized)} ìƒ˜í”Œ\")\n",
    "        print(f\"   ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {len(normalized)/sample_rate:.2f}ì´ˆ\")\n",
    "        print(f\"   ğŸ“Š ì˜¤ë””ì˜¤ ë²”ìœ„: [{normalized.min():.3f}, {normalized.max():.3f}]\")\n",
    "        \n",
    "        return normalized.astype(np.float32)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PCM íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_different_decoding_strategies(model, processor, audio):\n",
    "    \"\"\"ë‹¤ì–‘í•œ ë””ì½”ë”© ì „ëµ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª ë‹¤ì–‘í•œ ë””ì½”ë”© ì „ëµ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì…ë ¥ íŠ¹ì§• ì¶”ì¶œ\n",
    "    input_features = processor(\n",
    "        audio, \n",
    "        sampling_rate=16000, \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_features = input_features.cuda()\n",
    "    \n",
    "    strategies = [\n",
    "        {\n",
    "            \"name\": \"1ï¸âƒ£ ë°˜ë³µ ë°©ì§€ ê°•í™”\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 200,  # ê¸¸ì´ ì¤„ì„\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 2.0,  # ğŸ¯ ë°˜ë³µ í˜ë„í‹° ê°•í™”\n",
    "                \"no_repeat_ngram_size\": 3,  # ğŸ¯ 3-gram ë°˜ë³µ ë°©ì§€\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"2ï¸âƒ£ ë¹” ì„œì¹˜ + ë°˜ë³µ ë°©ì§€\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 150,\n",
    "                \"num_beams\": 3,  # ğŸ¯ ë¹” ì„œì¹˜ ì‚¬ìš©\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 1.5,\n",
    "                \"no_repeat_ngram_size\": 2,\n",
    "                \"early_stopping\": True,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"3ï¸âƒ£ ìƒ˜í”Œë§ ê¸°ë°˜\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 150,\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": True,  # ğŸ¯ ìƒ˜í”Œë§ í™œì„±í™”\n",
    "                \"temperature\": 0.7,  # ğŸ¯ ì°½ì˜ì„± ì¡°ì ˆ\n",
    "                \"top_p\": 0.9,       # ğŸ¯ ìƒìœ„ 90% í† í°ë§Œ ì‚¬ìš©\n",
    "                \"repetition_penalty\": 1.3,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"4ï¸âƒ£ ë³´ìˆ˜ì  ì„¤ì •\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 100,  # ğŸ¯ ë§¤ìš° ì§§ê²Œ\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 3.0,  # ğŸ¯ ë§¤ìš° ê°•í•œ ë°˜ë³µ í˜ë„í‹°\n",
    "                \"no_repeat_ngram_size\": 2,\n",
    "                \"pad_token_id\": processor.tokenizer.eos_token_id,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"5ï¸âƒ£ ê¸¸ì´ ì œí•œ + ì¡°ê¸° ì¢…ë£Œ\",\n",
    "            \"params\": {\n",
    "                \"max_new_tokens\": 50,  # ğŸ¯ ìƒˆ í† í° ìˆ˜ ì œí•œ\n",
    "                \"num_beams\": 2,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 2.5,\n",
    "                \"no_repeat_ngram_size\": 4,\n",
    "                \"early_stopping\": True,\n",
    "                \"eos_token_id\": processor.tokenizer.eos_token_id,\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n{strategy['name']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                predicted_ids = model.generate(\n",
    "                    input_features,\n",
    "                    **strategy['params']\n",
    "                )\n",
    "            \n",
    "            transcription = processor.tokenizer.batch_decode(\n",
    "                predicted_ids, \n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            # ê²°ê³¼ ë¶„ì„\n",
    "            result_length = len(transcription)\n",
    "            has_repetition = check_repetition(transcription)\n",
    "            has_broken_chars = check_broken_chars(transcription)\n",
    "            \n",
    "            print(f\"ğŸ“ ê²°ê³¼ (ê¸¸ì´: {result_length}):\")\n",
    "            print(f\"   {transcription[:200]}{'...' if len(transcription) > 200 else ''}\")\n",
    "            print(f\"ğŸ” ë¶„ì„:\")\n",
    "            print(f\"   - ë°˜ë³µ íŒ¨í„´: {'âŒ ìˆìŒ' if has_repetition else 'âœ… ì—†ìŒ'}\")\n",
    "            print(f\"   - ê¹¨ì§„ ë¬¸ì: {'âŒ ìˆìŒ' if has_broken_chars else 'âœ… ì—†ìŒ'}\")\n",
    "            \n",
    "            results.append({\n",
    "                'strategy': strategy['name'],\n",
    "                'result': transcription,\n",
    "                'length': result_length,\n",
    "                'has_repetition': has_repetition,\n",
    "                'has_broken_chars': has_broken_chars\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì „ëµ ì‹¤íŒ¨: {e}\")\n",
    "            results.append({\n",
    "                'strategy': strategy['name'],\n",
    "                'result': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def check_repetition(text):\n",
    "    \"\"\"ë°˜ë³µ íŒ¨í„´ ê°ì§€\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) < 6:\n",
    "        return False\n",
    "    \n",
    "    # ì—°ì†ëœ 3ê°œ ë‹¨ì–´ê°€ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸\n",
    "    for i in range(len(words) - 5):\n",
    "        if words[i:i+3] == words[i+3:i+6]:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def check_broken_chars(text):\n",
    "    \"\"\"ê¹¨ì§„ ë¬¸ì ê°ì§€\"\"\"\n",
    "    broken_patterns = ['ï¿½', 'ë§¨ï¿½', 'ê¹¨ï¿½', 'ë€¨ï¿½']\n",
    "    return any(pattern in text for pattern in broken_patterns)\n",
    "\n",
    "def find_best_result(results):\n",
    "    \"\"\"ìµœì  ê²°ê³¼ ì°¾ê¸°\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ† ìµœì  ê²°ê³¼ ì„ ì •\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    valid_results = [r for r in results if r.get('result') and not r.get('error')]\n",
    "    \n",
    "    if not valid_results:\n",
    "        print(\"âŒ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    # ì ìˆ˜ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    for result in valid_results:\n",
    "        score = 0\n",
    "        \n",
    "        # ë°˜ë³µ íŒ¨í„´ í˜ë„í‹°\n",
    "        if result['has_repetition']:\n",
    "            score += 100\n",
    "            \n",
    "        # ê¹¨ì§„ ë¬¸ì í˜ë„í‹°  \n",
    "        if result['has_broken_chars']:\n",
    "            score += 50\n",
    "            \n",
    "        # ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì§§ìœ¼ë©´ í˜ë„í‹°\n",
    "        if result['length'] > 300:\n",
    "            score += 30\n",
    "        elif result['length'] < 10:\n",
    "            score += 20\n",
    "            \n",
    "        result['score'] = score\n",
    "    \n",
    "    # ì ìˆ˜ìˆœ ì •ë ¬\n",
    "    valid_results.sort(key=lambda x: x['score'])\n",
    "    \n",
    "    print(\"ğŸ“Š ê²°ê³¼ ìˆœìœ„:\")\n",
    "    for i, result in enumerate(valid_results[:3]):\n",
    "        print(f\"   {i+1}. {result['strategy']} (ì ìˆ˜: {result['score']})\")\n",
    "        print(f\"      ğŸ“ {result['result'][:100]}...\")\n",
    "        print()\n",
    "    \n",
    "    best = valid_results[0]\n",
    "    print(f\"ğŸ¥‡ ìµœê³  ê²°ê³¼: {best['strategy']}\")\n",
    "    print(f\"ğŸ“ ì „ì²´ ê²°ê³¼: {best['result']}\")\n",
    "    \n",
    "    return best\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ í•¨ìˆ˜ - ë””ì½”ë”© íŒŒë¼ë¯¸í„° ìµœì í™”\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¯ ë””ì½”ë”© íŒŒë¼ë¯¸í„° ìµœì í™” í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # PCM íŒŒì¼ ê²½ë¡œ\n",
    "    pcm_file = \"000025.wav\"\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(pcm_file):\n",
    "        print(f\"âŒ PCM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pcm_file}\")\n",
    "        return\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_trained_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # PCM íŒŒì¼ ë¡œë“œ\n",
    "    print(f\"ğŸµ PCM íŒŒì¼ ì²˜ë¦¬ ì¤‘: {pcm_file}\")\n",
    "    audio = load_pcm_file(pcm_file)\n",
    "    if audio is None:\n",
    "        return\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ë””ì½”ë”© ì „ëµ í…ŒìŠ¤íŠ¸\n",
    "    results = test_different_decoding_strategies(model, processor, audio)\n",
    "    \n",
    "    # ìµœì  ê²°ê³¼ ì„ ì •\n",
    "    best_result = find_best_result(results)\n",
    "    \n",
    "    if best_result:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ìµœì  ë””ì½”ë”© ì„¤ì •ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ì´ ì„¤ì •ì„ ì‹¤ì œ ì¶”ë¡ ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68ee05df-b2d3-416e-8aea-4e10a0a387ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ› ìŒì„± ì•ë¶€ë¶„ ëˆ„ë½ ë¬¸ì œ ë””ë²„ê¹…\n",
      "================================================================================\n",
      "ğŸ” PCM íŒŒì¼ ìƒì„¸ ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“Š ì›ë³¸ PCM ì •ë³´:\n",
      "   - íŒŒì¼ í¬ê¸°: 387030 bytes\n",
      "   - ìƒ˜í”Œ ìˆ˜: 193515\n",
      "   - ê¸¸ì´: 12.09ì´ˆ\n",
      "   - ë°ì´í„° ë²”ìœ„: [-7886, 32000]\n",
      "\n",
      "ğŸ“Š ì²« 5ì´ˆ ë¶„ì„:\n",
      "   - ìƒ˜í”Œ ìˆ˜: 80000\n",
      "   - í‰ê·  ì ˆëŒ“ê°’: 1062.83\n",
      "   - ìµœëŒ€ ì ˆëŒ“ê°’: 32000\n",
      "   - 0ì´ ì•„ë‹Œ ìƒ˜í”Œ ë¹„ìœ¨: 97.9%\n",
      "\n",
      "ğŸ“Š ì •ê·œí™” í›„ ì²« 5ì´ˆ:\n",
      "   - ë²”ìœ„: [-0.246, 1.000]\n",
      "   - í‰ê·  ì ˆëŒ“ê°’: 0.033\n",
      "\n",
      "ğŸ“Š ì‹œê°„ëŒ€ë³„ ìŒì„± í™œë™ (1ì´ˆ ë‹¨ìœ„):\n",
      "    0ì´ˆ: ì—ë„ˆì§€=0.0355 ğŸ”Š\n",
      "    1ì´ˆ: ì—ë„ˆì§€=0.0400 ğŸ”Š\n",
      "    2ì´ˆ: ì—ë„ˆì§€=0.0283 ğŸ”Š\n",
      "    3ì´ˆ: ì—ë„ˆì§€=0.0299 ğŸ”Š\n",
      "    4ì´ˆ: ì—ë„ˆì§€=0.0325 ğŸ”Š\n",
      "    5ì´ˆ: ì—ë„ˆì§€=0.0355 ğŸ”Š\n",
      "    6ì´ˆ: ì—ë„ˆì§€=0.0318 ğŸ”Š\n",
      "    7ì´ˆ: ì—ë„ˆì§€=0.0284 ğŸ”Š\n",
      "    8ì´ˆ: ì—ë„ˆì§€=0.0326 ğŸ”Š\n",
      "    9ì´ˆ: ì—ë„ˆì§€=0.0256 ğŸ”Š\n",
      "\n",
      "ğŸ” Whisper ì…ë ¥ íŠ¹ì„± ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“Š ì…ë ¥ íŠ¹ì„± ì •ë³´:\n",
      "   - íŠ¹ì„± í¬ê¸°: torch.Size([1, 80, 3000])\n",
      "   - ë°ì´í„° íƒ€ì…: torch.float32\n",
      "   - ê°’ ë²”ìœ„: [-0.860, 1.140]\n",
      "   ì²­í¬ 1 (0~30ì´ˆ): torch.Size([1, 80, 3000])\n",
      "\n",
      "ğŸ” ê¸°ë³¸ Whisper vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ\n",
      "============================================================\n",
      "ğŸ”„ ê¸°ë³¸ Whisper í…ŒìŠ¤íŠ¸...\n",
      "âœ… ê¸°ë³¸ Whisper ê²°ê³¼:\n",
      "   ğŸ“  ì•„ì´ë“¤ í¬ëŠ” ê±¸ ì´ë ‡ê²Œ ê³„ì ˆ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ë¯¸êµ­ì—. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì„ ì—†ì´ ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“¤ì„ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ ì²˜ìŒì—ëŠ” ì• ì°©ì„ í•˜ì£ .\n",
      "\n",
      "ğŸ”„ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸...\n",
      "âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ê²°ê³¼:\n",
      "   ğŸ“  ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ . ê·¸ë˜ì„œ ê·¸ ì•„ë“¤ê»˜ì„œ ë§‰ ë„ëŸ¬ì§€ë©´ì„œ ì•„ì˜ˆ í•™ê½ˆë¥¼ í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ë¹„í–‰ê¸°êµ¬ê°€ ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ì¢€ ë” ì¡°ì•„í•˜ëŠ” ê±´ì§€ ëª¨ë¥´ê²“ë– ë¼ê³  ìƒë‹™ë‹ˆë‹¤ë¼ê³  í•˜ë”ë¼ê³  í•´ì„œ ê·¸ë•Œ í•œ ë²ˆì¯”ë©” ì•ˆ í•¸ëŠ”ë°\n",
      "\n",
      "ğŸ” 5ì´ˆ êµ¬ê°„ë³„ ë¶„ì„\n",
      "============================================================\n",
      "\n",
      "ğŸ“ êµ¬ê°„ 0~5ì´ˆ:\n",
      "   ì—ë„ˆì§€: 0.0332\n",
      "   ê²°ê³¼:  ë¯¸êµ­ì—.\n",
      "\n",
      "ğŸ“ êµ¬ê°„ 5~10ì´ˆ:\n",
      "   ì—ë„ˆì§€: 0.0308\n",
      "   ê²°ê³¼:  ê·¸ëŸ° ê°œì…ì„ ì—†ì´ ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“¤ì„ ì­‰ í‚¤ëŠ” ê±¸ ë³´ë‹ˆê¹Œ\n",
      "\n",
      "ğŸ“ êµ¬ê°„ 10~15ì´ˆ:\n",
      "   ì—ë„ˆì§€: 0.0145\n",
      "   ê²°ê³¼:  ë¶€ëª¨í•œí…Œ ë§¨ ì²˜ìŒì—ëŠ” ì• ì°©ì„ í•˜ì£ ?\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‹ ë””ë²„ê¹… ê²°ê³¼ ìš”ì•½\n",
      "================================================================================\n",
      "ğŸ” í™•ì¸í•´ì•¼ í•  í¬ì¸íŠ¸:\n",
      "1. ì²« 5ì´ˆ ì—ë„ˆì§€ê°€ ì¶©ë¶„í•œê°€?\n",
      "2. ê¸°ë³¸ Whisperë„ ì•ë¶€ë¶„ì„ ë†“ì¹˜ëŠ”ê°€?\n",
      "3. êµ¬ê°„ë³„ ë¶„ì„ì—ì„œ ì²« êµ¬ê°„ ê²°ê³¼ëŠ”?\n",
      "4. íŒŒì¸íŠœë‹ ëª¨ë¸ê³¼ ê¸°ë³¸ ëª¨ë¸ì˜ ì°¨ì´ëŠ”?\n",
      "\n",
      "ğŸ’¡ ê¸°ë³¸ Whisper ì²« ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "ğŸ’¡ íŒŒì¸íŠœë‹ ëª¨ë¸ ì²« ë¶€ë¶„ ì¸ì‹: âŒ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "def load_and_analyze_pcm(pcm_file_path):\n",
    "    \"\"\"PCM íŒŒì¼ ë¡œë“œí•˜ê³  ìƒì„¸ ë¶„ì„\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” PCM íŒŒì¼ ìƒì„¸ ë¶„ì„\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # PCM íŒŒì¼ ë¡œë“œ\n",
    "        with open(pcm_file_path, 'rb') as f:\n",
    "            pcm_data = f.read()\n",
    "        \n",
    "        # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "        np_pcm = np.frombuffer(pcm_data, dtype=np.int16)\n",
    "        \n",
    "        print(f\"ğŸ“Š ì›ë³¸ PCM ì •ë³´:\")\n",
    "        print(f\"   - íŒŒì¼ í¬ê¸°: {len(pcm_data)} bytes\")\n",
    "        print(f\"   - ìƒ˜í”Œ ìˆ˜: {len(np_pcm)}\")\n",
    "        print(f\"   - ê¸¸ì´: {len(np_pcm)/16000:.2f}ì´ˆ\")\n",
    "        print(f\"   - ë°ì´í„° ë²”ìœ„: [{np_pcm.min()}, {np_pcm.max()}]\")\n",
    "        \n",
    "        # ì•ë¶€ë¶„ ë¶„ì„ (ì²« 5ì´ˆ)\n",
    "        first_5_sec = np_pcm[:16000*5]  # ì²« 5ì´ˆ\n",
    "        print(f\"\\nğŸ“Š ì²« 5ì´ˆ ë¶„ì„:\")\n",
    "        print(f\"   - ìƒ˜í”Œ ìˆ˜: {len(first_5_sec)}\")\n",
    "        print(f\"   - í‰ê·  ì ˆëŒ“ê°’: {np.mean(np.abs(first_5_sec)):.2f}\")\n",
    "        print(f\"   - ìµœëŒ€ ì ˆëŒ“ê°’: {np.max(np.abs(first_5_sec))}\")\n",
    "        print(f\"   - 0ì´ ì•„ë‹Œ ìƒ˜í”Œ ë¹„ìœ¨: {np.count_nonzero(first_5_sec)/len(first_5_sec)*100:.1f}%\")\n",
    "        \n",
    "        # ì •ê·œí™” (ì‚¬ìš©ì ë°©ì‹)\n",
    "        normalized = np_pcm / np.max(np.abs(np_pcm))\n",
    "        first_5_sec_norm = normalized[:16000*5]\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ì •ê·œí™” í›„ ì²« 5ì´ˆ:\")\n",
    "        print(f\"   - ë²”ìœ„: [{first_5_sec_norm.min():.3f}, {first_5_sec_norm.max():.3f}]\")\n",
    "        print(f\"   - í‰ê·  ì ˆëŒ“ê°’: {np.mean(np.abs(first_5_sec_norm)):.3f}\")\n",
    "        \n",
    "        # ì‹œê°„ëŒ€ë³„ ìŒì„± í™œë™ ë¶„ì„\n",
    "        print(f\"\\nğŸ“Š ì‹œê°„ëŒ€ë³„ ìŒì„± í™œë™ (1ì´ˆ ë‹¨ìœ„):\")\n",
    "        for i in range(min(10, int(len(normalized)/16000))):  # ì²« 10ì´ˆ\n",
    "            segment = normalized[i*16000:(i+1)*16000]\n",
    "            energy = np.mean(np.abs(segment))\n",
    "            print(f\"   {i:2d}ì´ˆ: ì—ë„ˆì§€={energy:.4f} {'ğŸ”Š' if energy > 0.01 else 'ğŸ”‡'}\")\n",
    "        \n",
    "        return normalized, np_pcm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PCM ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def test_whisper_input_features(audio_array):\n",
    "    \"\"\"Whisper ì…ë ¥ íŠ¹ì„± ë¶„ì„\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ” Whisper ì…ë ¥ íŠ¹ì„± ë¶„ì„\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ë³¸ Whisper processorë¡œ íŠ¹ì„± ì¶”ì¶œ\n",
    "        processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "        \n",
    "        # ì „ì²´ ì˜¤ë””ì˜¤\n",
    "        input_features = processor.feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        print(f\"ğŸ“Š ì…ë ¥ íŠ¹ì„± ì •ë³´:\")\n",
    "        print(f\"   - íŠ¹ì„± í¬ê¸°: {input_features.shape}\")\n",
    "        print(f\"   - ë°ì´í„° íƒ€ì…: {input_features.dtype}\")\n",
    "        print(f\"   - ê°’ ë²”ìœ„: [{input_features.min():.3f}, {input_features.max():.3f}]\")\n",
    "        \n",
    "        # 30ì´ˆì”© ë¶„í•  ì²˜ë¦¬ (Whisper ê¸°ë³¸ ë°©ì‹)\n",
    "        chunk_size = 30 * 16000  # 30ì´ˆ\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(audio_array), chunk_size):\n",
    "            chunk = audio_array[i:i+chunk_size]\n",
    "            if len(chunk) < chunk_size:\n",
    "                # ë§ˆì§€ë§‰ ì²­í¬ëŠ” íŒ¨ë”©\n",
    "                padded_chunk = np.zeros(chunk_size, dtype=np.float32)\n",
    "                padded_chunk[:len(chunk)] = chunk\n",
    "                chunk = padded_chunk\n",
    "            \n",
    "            chunk_features = processor.feature_extractor(\n",
    "                chunk,\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\"\n",
    "            ).input_features\n",
    "            \n",
    "            chunks.append(chunk_features)\n",
    "            \n",
    "            # ì²« 3ê°œ ì²­í¬ë§Œ ë¶„ì„\n",
    "            if len(chunks) <= 3:\n",
    "                print(f\"   ì²­í¬ {len(chunks)} ({i//16000}~{(i+chunk_size)//16000}ì´ˆ): {chunk_features.shape}\")\n",
    "        \n",
    "        return input_features, chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì…ë ¥ íŠ¹ì„± ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def compare_basic_vs_finetuned(audio_array):\n",
    "    \"\"\"ê¸°ë³¸ Whisper vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ” ê¸°ë³¸ Whisper vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. ê¸°ë³¸ Whisper í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        print(\"ğŸ”„ ê¸°ë³¸ Whisper í…ŒìŠ¤íŠ¸...\")\n",
    "        basic_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "        basic_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            basic_model = basic_model.cuda()\n",
    "        \n",
    "        input_features = basic_processor(\n",
    "            audio_array,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predicted_ids = basic_model.generate(\n",
    "                input_features,\n",
    "                language=\"ko\",\n",
    "                task=\"transcribe\",\n",
    "                max_length=500  # ê¸¸ê²Œ ì„¤ì •\n",
    "            )\n",
    "        \n",
    "        basic_result = basic_processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        results['basic'] = basic_result\n",
    "        print(f\"âœ… ê¸°ë³¸ Whisper ê²°ê³¼:\")\n",
    "        print(f\"   ğŸ“ {basic_result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê¸°ë³¸ Whisper í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        results['basic'] = None\n",
    "    \n",
    "    # 2. íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ìˆë‹¤ë©´)\n",
    "    finetuned_path = \"whisper_pronunciation_finetuned\"\n",
    "    if os.path.exists(finetuned_path):\n",
    "        try:\n",
    "            print(f\"\\nğŸ”„ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸...\")\n",
    "            finetuned_model = WhisperForConditionalGeneration.from_pretrained(finetuned_path)\n",
    "            finetuned_processor = WhisperProcessor.from_pretrained(finetuned_path)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                finetuned_model = finetuned_model.cuda()\n",
    "            \n",
    "            input_features = finetuned_processor(\n",
    "                audio_array,\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\"\n",
    "            ).input_features\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input_features = input_features.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_ids = finetuned_model.generate(\n",
    "                    input_features,\n",
    "                    max_length=500,\n",
    "                    repetition_penalty=2.0,\n",
    "                    no_repeat_ngram_size=3\n",
    "                )\n",
    "            \n",
    "            finetuned_result = finetuned_processor.tokenizer.batch_decode(\n",
    "                predicted_ids,\n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            results['finetuned'] = finetuned_result\n",
    "            print(f\"âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ê²°ê³¼:\")\n",
    "            print(f\"   ğŸ“ {finetuned_result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "            results['finetuned'] = None\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  íŒŒì¸íŠœë‹ ëª¨ë¸ ì—†ìŒ: {finetuned_path}\")\n",
    "        results['finetuned'] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_audio_segments(audio_array, segment_length=5):\n",
    "    \"\"\"ì˜¤ë””ì˜¤ë¥¼ êµ¬ê°„ë³„ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ” {segment_length}ì´ˆ êµ¬ê°„ë³„ ë¶„ì„\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        basic_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "        basic_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            basic_model = basic_model.cuda()\n",
    "        \n",
    "        segment_size = segment_length * 16000\n",
    "        \n",
    "        for i in range(0, min(len(audio_array), 30*16000), segment_size):  # ìµœëŒ€ 30ì´ˆê¹Œì§€ë§Œ\n",
    "            segment = audio_array[i:i+segment_size]\n",
    "            \n",
    "            # ë„ˆë¬´ ì§§ì€ êµ¬ê°„ì€ íŒ¨ë”©\n",
    "            if len(segment) < segment_size:\n",
    "                padded_segment = np.zeros(segment_size, dtype=np.float32)\n",
    "                padded_segment[:len(segment)] = segment\n",
    "                segment = padded_segment\n",
    "            \n",
    "            print(f\"\\nğŸ“ êµ¬ê°„ {i//16000}~{(i+segment_size)//16000}ì´ˆ:\")\n",
    "            print(f\"   ì—ë„ˆì§€: {np.mean(np.abs(segment)):.4f}\")\n",
    "            \n",
    "            try:\n",
    "                input_features = basic_processor(\n",
    "                    segment,\n",
    "                    sampling_rate=16000,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).input_features\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    input_features = input_features.cuda()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    predicted_ids = basic_model.generate(\n",
    "                        input_features,\n",
    "                        language=\"ko\",\n",
    "                        task=\"transcribe\",\n",
    "                        max_length=100\n",
    "                    )\n",
    "                \n",
    "                result = basic_processor.tokenizer.batch_decode(\n",
    "                    predicted_ids,\n",
    "                    skip_special_tokens=True\n",
    "                )[0]\n",
    "                \n",
    "                print(f\"   ê²°ê³¼: {result}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ êµ¬ê°„ë³„ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ë””ë²„ê¹… í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ› ìŒì„± ì•ë¶€ë¶„ ëˆ„ë½ ë¬¸ì œ ë””ë²„ê¹…\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    pcm_file = \"000025.wav\"\n",
    "    \n",
    "    if not os.path.exists(pcm_file):\n",
    "        print(f\"âŒ PCM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pcm_file}\")\n",
    "        return\n",
    "    \n",
    "    # 1. PCM íŒŒì¼ ìƒì„¸ ë¶„ì„\n",
    "    audio_array, raw_pcm = load_and_analyze_pcm(pcm_file)\n",
    "    \n",
    "    if audio_array is None:\n",
    "        return\n",
    "    \n",
    "    # 2. Whisper ì…ë ¥ íŠ¹ì„± ë¶„ì„\n",
    "    input_features, chunks = test_whisper_input_features(audio_array)\n",
    "    \n",
    "    # 3. ê¸°ë³¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ\n",
    "    comparison_results = compare_basic_vs_finetuned(audio_array)\n",
    "    \n",
    "    # 4. êµ¬ê°„ë³„ ë¶„ì„\n",
    "    analyze_audio_segments(audio_array, segment_length=5)\n",
    "    \n",
    "    # 5. ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“‹ ë””ë²„ê¹… ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"ğŸ” í™•ì¸í•´ì•¼ í•  í¬ì¸íŠ¸:\")\n",
    "    print(\"1. ì²« 5ì´ˆ ì—ë„ˆì§€ê°€ ì¶©ë¶„í•œê°€?\")\n",
    "    print(\"2. ê¸°ë³¸ Whisperë„ ì•ë¶€ë¶„ì„ ë†“ì¹˜ëŠ”ê°€?\")\n",
    "    print(\"3. êµ¬ê°„ë³„ ë¶„ì„ì—ì„œ ì²« êµ¬ê°„ ê²°ê³¼ëŠ”?\")\n",
    "    print(\"4. íŒŒì¸íŠœë‹ ëª¨ë¸ê³¼ ê¸°ë³¸ ëª¨ë¸ì˜ ì°¨ì´ëŠ”?\")\n",
    "    \n",
    "    if comparison_results.get('basic'):\n",
    "        basic_starts_with_target = \"ì•„ì´ë“¤\" in comparison_results['basic'][:20]\n",
    "        print(f\"\\nğŸ’¡ ê¸°ë³¸ Whisper ì²« ë¶€ë¶„ ì¸ì‹: {'âœ…' if basic_starts_with_target else 'âŒ'}\")\n",
    "    \n",
    "    if comparison_results.get('finetuned'):\n",
    "        finetuned_starts_with_target = \"ì•„ì´ë“¤\" in comparison_results['finetuned'][:20]\n",
    "        print(f\"ğŸ’¡ íŒŒì¸íŠœë‹ ëª¨ë¸ ì²« ë¶€ë¶„ ì¸ì‹: {'âœ…' if finetuned_starts_with_target else 'âŒ'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ece781f-f934-4210-8303-a1ccd1ba79b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ íŒŒì¸íŠœë‹ ëª¨ë¸ ì•ë¶€ë¶„ ëˆ„ë½ í•´ê²°\n",
      "================================================================================\n",
      "ğŸ”¥ GPU ì‚¬ìš© ì¤‘\n",
      "âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "ğŸµ PCM íŒŒì¼ ë¡œë“œ ì¤‘...\n",
      "   ğŸ”‡ ì•ë¶€ë¶„ì— 0.1ì´ˆ ë¬´ìŒ ì¶”ê°€\n",
      "   ğŸ”Š ì•ë¶€ë¶„ 3.0ì´ˆ ë³¼ë¥¨ 1.5ë°° ì¦í­\n",
      "   ğŸ“Š ì „ì²˜ë¦¬ í›„ ê¸¸ì´: 12.19ì´ˆ\n",
      "ğŸ§ª ì•ë¶€ë¶„ ëˆ„ë½ í•´ê²°ì„ ìœ„í•œ ë””ì½”ë”© í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ ì–¸ì–´/íƒœìŠ¤í¬ ê°•ì œ ì§€ì •\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì£¼ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆì— ì°©ì„ í•˜ì£ ?\n",
      "ğŸ” ì•ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "\n",
      "2ï¸âƒ£ ì‹œì‘ í† í° ê°•ì œ ì§€ì •\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì£¼ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆì— ì°©ì„ í•˜ì£ ?\n",
      "ğŸ” ì•ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "\n",
      "3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë””ì½”ë”©\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼: ì•„ì´ë“¤ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš” ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ \n",
      "ğŸ” ì•ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "\n",
      "4ï¸âƒ£ ë¹” ì„œì¹˜ + ê¸¸ì´ í˜ë„í‹°\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ì´ë ‡ê²Œ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš” ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ë­ ê°œì…ì´ ì—…ì”¨ ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í‚¤ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ .\n",
      "ğŸ” ì•ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "\n",
      "5ï¸âƒ£ ì˜¨ë„ ìƒ˜í”Œë§\n",
      "------------------------------------------------------------\n",
      "ğŸ“ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±¸ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ í‚¤ìš°ê³  ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ ?\n",
      "ğŸ” ì•ë¶€ë¶„ ì¸ì‹: âœ…\n",
      "\n",
      "ğŸ”„ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "ğŸ“Š ì²« ì²­í¬: 10.0ì´ˆ\n",
      "ğŸ“ ì²« ì²­í¬ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ.\n",
      "ğŸ“Š ë‚˜ë¨¸ì§€ ì²­í¬: 2.2ì´ˆ\n",
      "ğŸ“ ë‚˜ë¨¸ì§€ ì²­í¬ ê²°ê³¼:  ë¶€ëª¨í•œí…Œ ë§¨ì²˜ë§¨ì— ì• ì°©ì„ í•˜ì£ ?\n",
      "ğŸ“ ì „ì²´ ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ.  ë¶€ëª¨í•œí…Œ ë§¨ì²˜ë§¨ì— ì• ì°©ì„ í•˜ì£ ?\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š í•´ê²° ë°©ë²• í‰ê°€\n",
      "================================================================================\n",
      "âœ… ì•ë¶€ë¶„ ì¸ì‹ ì„±ê³µí•œ ë°©ë²•ë“¤:\n",
      "   - 1ï¸âƒ£ ì–¸ì–´/íƒœìŠ¤í¬ ê°•ì œ ì§€ì •\n",
      "     ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì£¼ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆì— ì°©ì„ í•˜ì£ ?...\n",
      "   - 2ï¸âƒ£ ì‹œì‘ í† í° ê°•ì œ ì§€ì •\n",
      "     ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì£¼ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆì— ì°©ì„ í•˜ì£ ?...\n",
      "   - 3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë””ì½”ë”©\n",
      "     ê²°ê³¼: ì•„ì´ë“¤ëŠ” ê±°ë¥¼ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš” ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ì¨ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í¬ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ ...\n",
      "   - 4ï¸âƒ£ ë¹” ì„œì¹˜ + ê¸¸ì´ í˜ë„í‹°\n",
      "     ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±°ë¥¼ ì´ë ‡ê²Œ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš” ë¯¸êµ­ì— ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê·¸ëŸ° ë­ ê°œì…ì´ ì—…ì”¨ ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ ì­‰ í‚¤ëŠ” ê±¸ ë³´ë‹ˆê¹Œ ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„...\n",
      "   - 5ï¸âƒ£ ì˜¨ë„ ìƒ˜í”Œë§\n",
      "     ê²°ê³¼:  ì•„ì´ë“¤ í¬ëŠ” ê±¸ ê³„ì ¤ ì—°êµ¬ì†Œë¼ê³  ë˜ ìˆê±°ë“ ìš”. ê±°ê¸°ì„œ ì•„ë¬´ëŸ° ê°œì…ì´ ì—…ìŒ” ê·¸ëƒ¥ ì­‰ ê´€ì°°ë§Œ ìˆ˜ì²œ ëª…ì˜ ì•„ì´ë“œë¥¼ í‚¤ìš°ê³  ë¶€ëª¨í•œí…Œ ë§¨ì²˜ ë©´í—ˆ ì• ì°©ì„ í•˜ì£ ?...\n",
      "\n",
      "âœ… ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì•ë¶€ë¶„ ì¸ì‹ ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "def load_finetuned_model():\n",
    "    \"\"\"íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    model_path = \"whisper_pronunciation_finetuned\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ ëª¨ë¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "        processor = WhisperProcessor.from_pretrained(model_path)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            print(\"ğŸ”¥ GPU ì‚¬ìš© ì¤‘\")\n",
    "        \n",
    "        print(\"âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        return model, processor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_pcm_with_preprocessing(pcm_file_path, add_silence=True, amplify_start=True):\n",
    "    \"\"\"PCM íŒŒì¼ ë¡œë“œ + ì „ì²˜ë¦¬ ì˜µì…˜\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(pcm_file_path, 'rb') as f:\n",
    "            pcm_data = f.read()\n",
    "        \n",
    "        np_pcm = np.frombuffer(pcm_data, dtype=np.int16)\n",
    "        normalized = np_pcm / np.max(np.abs(np_pcm))\n",
    "        \n",
    "        # ì˜µì…˜ 1: ì•ë¶€ë¶„ì— ì§§ì€ ë¬´ìŒ ì¶”ê°€\n",
    "        if add_silence:\n",
    "            silence_duration = 0.1  # 0.1ì´ˆ\n",
    "            silence_samples = int(16000 * silence_duration)\n",
    "            silence = np.zeros(silence_samples, dtype=np.float32)\n",
    "            normalized = np.concatenate([silence, normalized])\n",
    "            print(f\"   ğŸ”‡ ì•ë¶€ë¶„ì— {silence_duration}ì´ˆ ë¬´ìŒ ì¶”ê°€\")\n",
    "        \n",
    "        # ì˜µì…˜ 2: ì•ë¶€ë¶„ ë³¼ë¥¨ ì¦í­\n",
    "        if amplify_start:\n",
    "            start_duration = 3.0  # ì²« 3ì´ˆ\n",
    "            start_samples = int(16000 * start_duration)\n",
    "            if len(normalized) > start_samples:\n",
    "                amplification = 1.5  # 1.5ë°° ì¦í­\n",
    "                normalized[:start_samples] *= amplification\n",
    "                # í´ë¦¬í•‘ ë°©ì§€\n",
    "                normalized = np.clip(normalized, -1.0, 1.0)\n",
    "                print(f\"   ğŸ”Š ì•ë¶€ë¶„ {start_duration}ì´ˆ ë³¼ë¥¨ {amplification}ë°° ì¦í­\")\n",
    "        \n",
    "        return normalized.astype(np.float32)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PCM ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_different_decoding_approaches(model, processor, audio):\n",
    "    \"\"\"ë‹¤ì–‘í•œ ë””ì½”ë”© ì ‘ê·¼ë²• í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª ì•ë¶€ë¶„ ëˆ„ë½ í•´ê²°ì„ ìœ„í•œ ë””ì½”ë”© í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    input_features = processor(\n",
    "        audio, \n",
    "        sampling_rate=16000, \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_features = input_features.cuda()\n",
    "    \n",
    "    approaches = [\n",
    "        {\n",
    "            \"name\": \"1ï¸âƒ£ ì–¸ì–´/íƒœìŠ¤í¬ ê°•ì œ ì§€ì •\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 500,\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 2.0,\n",
    "                \"no_repeat_ngram_size\": 3,\n",
    "                \"language\": \"ko\",\n",
    "                \"task\": \"transcribe\"\n",
    "            },\n",
    "            \"use_forced_ids\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"2ï¸âƒ£ ì‹œì‘ í† í° ê°•ì œ ì§€ì •\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 500,\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 2.0,\n",
    "                \"no_repeat_ngram_size\": 3,\n",
    "                \"decoder_start_token_id\": processor.tokenizer.convert_tokens_to_ids(\"<|startoftranscript|>\")\n",
    "            },\n",
    "            \"use_forced_ids\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë””ì½”ë”©\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 500,\n",
    "                \"num_beams\": 2,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 2.0,\n",
    "                \"no_repeat_ngram_size\": 3,\n",
    "            },\n",
    "            \"use_prompt\": True,\n",
    "            \"prompt_text\": \"ì•„ì´ë“¤\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"4ï¸âƒ£ ë¹” ì„œì¹˜ + ê¸¸ì´ í˜ë„í‹°\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 500,\n",
    "                \"num_beams\": 3,\n",
    "                \"do_sample\": False,\n",
    "                \"repetition_penalty\": 1.8,\n",
    "                \"no_repeat_ngram_size\": 3,\n",
    "                \"length_penalty\": 0.8,  # ì§§ì€ ê²°ê³¼ ì„ í˜¸ë„ ë‚®ì¶¤\n",
    "                \"early_stopping\": False\n",
    "            },\n",
    "            \"use_forced_ids\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"5ï¸âƒ£ ì˜¨ë„ ìƒ˜í”Œë§\",\n",
    "            \"params\": {\n",
    "                \"max_length\": 500,\n",
    "                \"num_beams\": 1,\n",
    "                \"do_sample\": True,\n",
    "                \"temperature\": 0.3,  # ë‚®ì€ ì˜¨ë„ë¡œ ë³´ìˆ˜ì  ìƒì„±\n",
    "                \"repetition_penalty\": 2.0,\n",
    "                \"no_repeat_ngram_size\": 3,\n",
    "            },\n",
    "            \"use_forced_ids\": False\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for approach in approaches:\n",
    "        print(f\"\\n{approach['name']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            params = approach['params'].copy()\n",
    "            \n",
    "            # ê°•ì œ ë””ì½”ë” ID ì‚¬ìš©\n",
    "            if approach.get('use_forced_ids'):\n",
    "                forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
    "                    language=\"ko\", \n",
    "                    task=\"transcribe\"\n",
    "                )\n",
    "                params['forced_decoder_ids'] = forced_decoder_ids\n",
    "            \n",
    "            # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë””ì½”ë”©\n",
    "            elif approach.get('use_prompt'):\n",
    "                prompt_text = approach['prompt_text']\n",
    "                prompt_ids = processor.tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "                if torch.cuda.is_available():\n",
    "                    prompt_ids = prompt_ids.cuda()\n",
    "                params['decoder_input_ids'] = prompt_ids\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_ids = model.generate(\n",
    "                    input_features,\n",
    "                    **params\n",
    "                )\n",
    "            \n",
    "            transcription = processor.tokenizer.batch_decode(\n",
    "                predicted_ids, \n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            # ì•ë¶€ë¶„ ì¸ì‹ ì—¬ë¶€ í™•ì¸\n",
    "            has_beginning = any(word in transcription[:50] for word in [\"ì•„ì´ë“¤\", \"í¬ëŠ”\", \"ê³„ì ˆ\"])\n",
    "            \n",
    "            print(f\"ğŸ“ ê²°ê³¼: {transcription}\")\n",
    "            print(f\"ğŸ” ì•ë¶€ë¶„ ì¸ì‹: {'âœ…' if has_beginning else 'âŒ'}\")\n",
    "            \n",
    "            results.append({\n",
    "                'approach': approach['name'],\n",
    "                'result': transcription,\n",
    "                'has_beginning': has_beginning,\n",
    "                'length': len(transcription)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "            results.append({\n",
    "                'approach': approach['name'],\n",
    "                'result': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_chunked_processing(model, processor, audio):\n",
    "    \"\"\"ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì•ë¶€ë¶„ ê°•ì œ ì¸ì‹\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ”„ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # ì²« 10ì´ˆë§Œ ë”°ë¡œ ì²˜ë¦¬\n",
    "        chunk_duration = 10  # ì´ˆ\n",
    "        chunk_samples = chunk_duration * 16000\n",
    "        \n",
    "        if len(audio) > chunk_samples:\n",
    "            first_chunk = audio[:chunk_samples]\n",
    "            remaining_chunk = audio[chunk_samples:]\n",
    "        else:\n",
    "            first_chunk = audio\n",
    "            remaining_chunk = None\n",
    "        \n",
    "        print(f\"ğŸ“Š ì²« ì²­í¬: {len(first_chunk)/16000:.1f}ì´ˆ\")\n",
    "        \n",
    "        # ì²« ì²­í¬ ì²˜ë¦¬\n",
    "        input_features = processor(\n",
    "            first_chunk,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_features = input_features.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                max_length=300,\n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.0,\n",
    "                no_repeat_ngram_size=3,\n",
    "                language=\"ko\",\n",
    "                task=\"transcribe\"\n",
    "            )\n",
    "        \n",
    "        first_result = processor.tokenizer.batch_decode(\n",
    "            predicted_ids,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        print(f\"ğŸ“ ì²« ì²­í¬ ê²°ê³¼: {first_result}\")\n",
    "        \n",
    "        # ë‚˜ë¨¸ì§€ ì²­í¬ë„ ì²˜ë¦¬ (ìˆë‹¤ë©´)\n",
    "        full_result = first_result\n",
    "        \n",
    "        if remaining_chunk is not None and len(remaining_chunk) > 16000:  # 1ì´ˆ ì´ìƒ\n",
    "            print(f\"ğŸ“Š ë‚˜ë¨¸ì§€ ì²­í¬: {len(remaining_chunk)/16000:.1f}ì´ˆ\")\n",
    "            \n",
    "            input_features = processor(\n",
    "                remaining_chunk,\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\"\n",
    "            ).input_features\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input_features = input_features.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_ids = model.generate(\n",
    "                    input_features,\n",
    "                    max_length=300,\n",
    "                    num_beams=2,\n",
    "                    repetition_penalty=2.0,\n",
    "                    no_repeat_ngram_size=3\n",
    "                )\n",
    "            \n",
    "            remaining_result = processor.tokenizer.batch_decode(\n",
    "                predicted_ids,\n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "            \n",
    "            print(f\"ğŸ“ ë‚˜ë¨¸ì§€ ì²­í¬ ê²°ê³¼: {remaining_result}\")\n",
    "            full_result = first_result + \" \" + remaining_result\n",
    "        \n",
    "        print(f\"ğŸ“ ì „ì²´ ê²°ê³¼: {full_result}\")\n",
    "        return full_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ íŒŒì¸íŠœë‹ ëª¨ë¸ ì•ë¶€ë¶„ ëˆ„ë½ í•´ê²°\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, processor = load_finetuned_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    # PCM íŒŒì¼ ë¡œë“œ (ì „ì²˜ë¦¬ ì˜µì…˜ ì ìš©)\n",
    "    pcm_file = \"000025.wav\"\n",
    "    \n",
    "    print(\"\\nğŸµ PCM íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
    "    audio = load_pcm_with_preprocessing(\n",
    "        pcm_file, \n",
    "        add_silence=True,    # ì•ë¶€ë¶„ ë¬´ìŒ ì¶”ê°€\n",
    "        amplify_start=True   # ì•ë¶€ë¶„ ë³¼ë¥¨ ì¦í­\n",
    "    )\n",
    "    \n",
    "    if audio is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"   ğŸ“Š ì „ì²˜ë¦¬ í›„ ê¸¸ì´: {len(audio)/16000:.2f}ì´ˆ\")\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ë””ì½”ë”© ì ‘ê·¼ë²• í…ŒìŠ¤íŠ¸\n",
    "    results = test_different_decoding_approaches(model, processor, audio)\n",
    "    \n",
    "    # ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "    chunked_result = test_chunked_processing(model, processor, audio)\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š í•´ê²° ë°©ë²• í‰ê°€\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    successful_approaches = [r for r in results if r.get('has_beginning')]\n",
    "    \n",
    "    if successful_approaches:\n",
    "        print(\"âœ… ì•ë¶€ë¶„ ì¸ì‹ ì„±ê³µí•œ ë°©ë²•ë“¤:\")\n",
    "        for approach in successful_approaches:\n",
    "            print(f\"   - {approach['approach']}\")\n",
    "            print(f\"     ê²°ê³¼: {approach['result'][:100]}...\")\n",
    "    else:\n",
    "        print(\"âŒ ëª¨ë“  ë°©ë²•ì´ ì•ë¶€ë¶„ ì¸ì‹ ì‹¤íŒ¨\")\n",
    "        print(\"ğŸ’¡ ì¶”ì²œ: ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë‚˜ ëª¨ë¸ ì¬í•™ìŠµ ê³ ë ¤\")\n",
    "    \n",
    "    if chunked_result and \"ì•„ì´ë“¤\" in chunked_result[:50]:\n",
    "        print(\"\\nâœ… ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì•ë¶€ë¶„ ì¸ì‹ ì„±ê³µ!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacc37a-a1ab-42ee-8ff7-13f3897704e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
