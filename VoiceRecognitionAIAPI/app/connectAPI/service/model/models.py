import os
import torch.nn as nn
import numpy as np
import torch
# import jiwer : label í…ìŠ¤íŠ¸ê°€ ìˆì„ ê²½ìš° í™œìš©
from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig
from typing import Any, Text


class sttmodel:
    def __init__(self):
        super(sttmodel, self).__init__()
        self.model = None
        self.processor = None
        self.device = None
        self.transcription = None
        self.sr = 16000
        self.is_finetuned_model = False

    def inference_stt(self, data):
        audio_array = data
        input_features = self.processor.feature_extractor(
            audio_array,
            sampling_rate=self.sr,
            return_tensors="pt"
        ).input_features
        # ì…ë ¥ íŠ¹ì„±ì„ ëª¨ë¸ê³¼ ë™ì¼í•œ ì¥ì¹˜ë¡œ ì´ë™
        input_features = input_features.to(self.device)

        with torch.no_grad():
            if self.is_finetuned_model:
                # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ - í•œêµ­ì–´ ê°•ì œ ì§€ì •
                predicted_ids = self.model.generate(
                    input_features,
                    max_length=200,
                    repetition_penalty=2.0,
                    no_repeat_ngram_size=3,
                    num_beams=1,
                    do_sample=False,
                    forced_decoder_ids=[[1, 50259], [2, 50264], [3, 50359]]  # í•œêµ­ì–´ transcribe ê°•ì œ
                )
            else:
                # ê¸°ë³¸ Whisper ëª¨ë¸
                predicted_ids = self.model.generate(
                    input_features,
                    max_length=448,
                    num_beams=1,
                    do_sample=False
                )

        # ì˜ˆì¸¡ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©
        transcription = self.processor.tokenizer.batch_decode(
            predicted_ids,
            skip_special_tokens=True
        )[0]

        return transcription

    def initialize_model(self):
        self.processor = WhisperProcessor.from_pretrained("openai/whisper-small")
        self.model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")

        # ê¸°ë³¸ ëª¨ë¸ë„ generation config ì •ë¦¬
        if hasattr(self.model, 'generation_config'):
            if hasattr(self.model.generation_config, 'forced_decoder_ids'):
                self.model.generation_config.forced_decoder_ids = None
            if hasattr(self.model.generation_config, 'suppress_tokens'):
                self.model.generation_config.suppress_tokens = None
            print("ğŸ”§ ê¸°ë³¸ ëª¨ë¸ generation config ì •ë¦¬ ì™„ë£Œ")

        if self.device is not None:
            self.model.to(self.device)

    def check_cuda(self, ):
        if torch.cuda.is_available():
            self.device = torch.device("cuda:0")
            print("GPU ì‚¬ìš©")
        else:
            self.device = torch.device("cpu")
            print("CPU ì‚¬ìš©")

    def _safe_load_checkpoint(self, model_file):
        """
        PyTorch ë²„ì „ì— ë”°ë¼ ì•ˆì „í•˜ê²Œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œ
        """
        try:
            # PyTorch 2.6+ ëŒ€ì‘: weights_only=Falseë¡œ ëª…ì‹œì  ì„¤ì •
            print("ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì¤‘...")
            checkpoint = torch.load(model_file, map_location=self.device, weights_only=False)
            return checkpoint

        except TypeError:
            # ì´ì „ PyTorch ë²„ì „ì—ì„œëŠ” weights_only íŒŒë¼ë¯¸í„°ê°€ ì—†ìŒ
            print("ğŸ”„ ì´ì „ PyTorch ë²„ì „ìœ¼ë¡œ ë¡œë”© ì¤‘...")
            checkpoint = torch.load(model_file, map_location=self.device)
            return checkpoint

        except Exception as e:
            print(f"âš ï¸ ì²« ë²ˆì§¸ ë¡œë”© ì‹œë„ ì‹¤íŒ¨: {str(e)}")

            # ì•ˆì „í•œ ê¸€ë¡œë²Œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
            try:
                from transformers.models.whisper.tokenization_whisper import WhisperTokenizer
                from transformers.models.whisper.feature_extraction_whisper import WhisperFeatureExtractor

                # ì•ˆì „í•œ ê¸€ë¡œë²Œë¡œ ë“±ë¡
                safe_globals = [WhisperTokenizer, WhisperFeatureExtractor]

                # PyTorch ë²„ì „ì— ë”°ë¥¸ ì²˜ë¦¬
                if hasattr(torch.serialization, 'add_safe_globals'):
                    torch.serialization.add_safe_globals(safe_globals)
                    checkpoint = torch.load(model_file, map_location=self.device)
                else:
                    # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
                    with torch.serialization.safe_globals(safe_globals):
                        checkpoint = torch.load(model_file, map_location=self.device)

                print("âœ… ì•ˆì „í•œ ê¸€ë¡œë²Œ ì„¤ì •ìœ¼ë¡œ ë¡œë”© ì„±ê³µ")
                return checkpoint

            except Exception as retry_error:
                print(f"âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {str(retry_error)}")
                return None

    def create_compatible_processor(self, checkpoint):
        """
        ë²„ì „ í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ í”„ë¡œì„¸ì„œ ìƒì„±
        """
        try:
            stored_tokenizer = checkpoint['tokenizer']

            # í† í¬ë‚˜ì´ì € í˜¸í™˜ì„± í™•ì¸
            if not hasattr(stored_tokenizer, 'all_special_ids'):
                print("âš ï¸ ì €ì¥ëœ í† í¬ë‚˜ì´ì € í˜¸í™˜ì„± ë¬¸ì œ - ìƒˆë¡œ ìƒì„±")
                raise AttributeError("Missing all_special_ids attribute")

            # FeatureExtractor í˜¸í™˜ì„± í™•ì¸
            stored_feature_extractor = checkpoint['feature_extractor']
            required_attrs = ['dither', 'chunk_length', 'feature_size']
            missing_attrs = [attr for attr in required_attrs if not hasattr(stored_feature_extractor, attr)]

            if missing_attrs:
                print(f"âš ï¸ FeatureExtractor í˜¸í™˜ì„± ë¬¸ì œ - ëˆ„ë½ëœ ì†ì„±: {missing_attrs}")
                raise AttributeError(f"Missing attributes: {missing_attrs}")

            # ë‘˜ ë‹¤ í˜¸í™˜ëœë‹¤ë©´ ì‚¬ìš©
            processor = WhisperProcessor(feature_extractor=stored_feature_extractor, tokenizer=stored_tokenizer)
            print("âœ… ì €ì¥ëœ í”„ë¡œì„¸ì„œ ì‚¬ìš©")
            return processor

        except (AttributeError, KeyError, Exception) as e:
            print(f"âš ï¸ ì €ì¥ëœ í”„ë¡œì„¸ì„œ ì‚¬ìš© ë¶ˆê°€: {str(e)}")
            print("ğŸ”„ ìƒˆë¡œìš´ í”„ë¡œì„¸ì„œë¡œ ëŒ€ì²´")

            # ì™„ì „íˆ ìƒˆë¡œìš´ í”„ë¡œì„¸ì„œ ìƒì„±í•˜ë˜, í•œêµ­ì–´ë¡œ ê°•ì œ ì„¤ì •
            from transformers import WhisperProcessor
            new_processor = WhisperProcessor.from_pretrained("openai/whisper-small")

            # í•œêµ­ì–´ í† í° ID ì„¤ì •
            korean_token_id = 50264  # í•œêµ­ì–´ í† í° ID
            transcribe_token_id = 50359  # transcribe íƒœìŠ¤í¬ í† í° ID

            print("âœ… ìƒˆë¡œìš´ í”„ë¡œì„¸ì„œ ìƒì„± ì™„ë£Œ (í•œêµ­ì–´ ì„¤ì •)")
            return new_processor

    def load_pt(self, pt_file: Any):
        try:
            model_file = pt_file
            print(f"ëª¨ë¸ íŒŒì¼ ë¡œë”© ì‹œë„: {model_file}")

            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(model_file):
                print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_file}")
                return False

            # PyTorch 2.6+ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = self._safe_load_checkpoint(model_file)
            if checkpoint is None:
                return False

            if 'model_state_dict' in checkpoint:
                # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í˜•ì‹ (convert_to_pt.pyë¡œ ìƒì„±ëœ íŒŒì¼)
                config = WhisperConfig.from_dict(checkpoint['model_config'])
                self.model = WhisperForConditionalGeneration(config)
                self.model.load_state_dict(checkpoint['model_state_dict'])

                # í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ í”„ë¡œì„¸ì„œ ìƒì„±
                self.processor = self.create_compatible_processor(checkpoint)

                # generation config í˜¸í™˜ì„± ìˆ˜ì •
                if hasattr(self.model, 'generation_config'):
                    # forced_decoder_ids ì œê±°
                    if hasattr(self.model.generation_config, 'forced_decoder_ids'):
                        self.model.generation_config.forced_decoder_ids = None
                        print("ğŸ”§ forced_decoder_ids ì œê±°ë¨")

                    # ê¸°íƒ€ ì¶©ëŒ ê°€ëŠ¥í•œ ì„¤ì •ë“¤ë„ ì •ë¦¬
                    if hasattr(self.model.generation_config, 'suppress_tokens'):
                        self.model.generation_config.suppress_tokens = None
                        print("ğŸ”§ suppress_tokens ì œê±°ë¨")

                    print("âœ… Generation config í˜¸í™˜ì„± ìˆ˜ì • ì™„ë£Œ")

                self.is_finetuned_model = True
                print("âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                # ê¸°ì¡´ ë°©ì‹ (ë‹¨ìˆœ state_dict)
                state_dict = checkpoint
                self.model.load_state_dict(state_dict)
                self.is_finetuned_model = True
                print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")

            self.model.to(self.device)
            return True

        except Exception as e:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—ëŸ¬ : {str(e)}")
            return False

    def get_model_path(self):
        """
        í™˜ê²½ì— ë”°ë¼ ëª¨ë¸ ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •
        """
        # í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ ê²½ë¡œ ì§€ì • (ë„ì»¤ì—ì„œ ìœ ìš©)
        if 'MODEL_PATH' in os.environ:
            return os.environ['MODEL_PATH']

        # í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
        current_file_dir = os.path.dirname(os.path.abspath(__file__))

        # ê°€ëŠ¥í•œ ê²½ë¡œë“¤ì„ ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ì‹œë„
        possible_paths = [
            # í˜„ì¬ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì˜ model í´ë”
            os.path.join(current_file_dir, "model"),
            # ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ model í´ë”
            os.path.join(os.path.dirname(current_file_dir), "model"),
            # service í´ë” ë‚´ì˜ model í´ë”
            os.path.join(current_file_dir, "service", "model"),
            # ì ˆëŒ€ ê²½ë¡œ (ê°œë°œ í™˜ê²½ìš©)
            "/Users/yongmin/Desktop/voicelearning/VoiceRecognitionAIAPI/app/connectAPI/service/model",
            # ë„ì»¤ í™˜ê²½ìš© ê²½ë¡œ
            "/app/app/connectAPI/service/model"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                print(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {path}")
                return path

        print("âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    def find_pt(self, model_dir=None):
        """
        pt íŒŒì¼ì„ ì°¾ì•„ì„œ ë¡œë“œ
        """
        if model_dir is None:
            model_dir = self.get_model_path()

        if model_dir is None:
            print("âš ï¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return False

        found = False
        print(f"ğŸ” ëª¨ë¸ íŒŒì¼ íƒìƒ‰ ì¤‘: {model_dir}")

        if os.path.exists(model_dir):
            # íŠ¹ì • íŒŒì¼ëª…ìœ¼ë¡œ ë¨¼ì € ì‹œë„
            specific_file = os.path.join(model_dir, "whisper_pronunciation_model.pt")
            if os.path.exists(specific_file):
                print(f"ğŸ¯ íŠ¹ì • ëª¨ë¸ íŒŒì¼ ë°œê²¬: {specific_file}")
                if self.load_pt(specific_file):
                    return True

            # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .pt íŒŒì¼ íƒìƒ‰
            for root, _, files in os.walk(model_dir):
                for file in files:
                    if file.endswith(".pt"):
                        full_path = os.path.join(root, file)
                        print(f"ğŸ“„ ëª¨ë¸ íŒŒì¼ ë°œê²¬: {full_path}")
                        if self.load_pt(full_path):
                            found = True
                            break
                if found:
                    break
        else:
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_dir}")

        if not found:
            print("âš ï¸ pt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        return found

    def stt_model(self, test_file):
        self.model.eval()

        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ íƒ€ì… ì¶œë ¥
        if self.is_finetuned_model:
            print("ğŸ¯ íŒŒì¸íŠœë‹ëœ ë°œìŒ ëª¨ë¸ ì‚¬ìš© ì¤‘ (ë°˜ë³µ ë°©ì§€ ì„¤ì • ì ìš©)")
        else:
            print("ğŸ”¸ ê¸°ë³¸ Whisper ëª¨ë¸ ì‚¬ìš© ì¤‘")

        self.transcription = self.inference_stt(test_file)

    def start_stt(self, test_file: np.ndarray) -> Any:
        print("ğŸš€ STT ëª¨ë¸ ì‹œì‘")
        self.check_cuda()
        self.initialize_model()
        self.find_pt()  # ì¸ì ì—†ì´ í˜¸ì¶œí•˜ë©´ ìë™ìœ¼ë¡œ ê²½ë¡œ íƒìƒ‰
        self.stt_model(test_file)
        return self.transcription